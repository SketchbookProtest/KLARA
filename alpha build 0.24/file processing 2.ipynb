{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c3aee3eb-0151-40b6-b2f0-c89f598ffb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dba75ec7-d938-4363-a149-cf55b195c389",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1726f6c5-0b63-4184-ab57-21fad4577fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza, re, benepar, psutil, gc, json, csv, time, string\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from textstat import textstat\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_infix_regex\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import Tree\n",
    "from textblob import Word\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import LogLocator, LogFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7ee7f15-f969-4fe0-83d2-6584568b66b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memcheck():\n",
    "    gc.collect()\n",
    "    memory_info = psutil.virtual_memory()\n",
    "\n",
    "    # Display the memory information in GB\n",
    "    total_memory = memory_info.total / (1024 ** 3)\n",
    "    available_memory = memory_info.available / (1024 ** 3)\n",
    "    used_memory = memory_info.used / (1024 ** 3)\n",
    "\n",
    "    print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "    print(f\"Available Memory: {available_memory:.2f} GB\")\n",
    "    print(f\"Used Memory: {used_memory:.2f} GB\")\n",
    "\n",
    "def time_taken(start_time, end_time):\n",
    "    time_taken = end_time - start_time\n",
    "    hours, remainder = divmod(time_taken.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f\"Time Taken: {hours} hours, {minutes} minutes, {seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3533b1ab-e0f3-4845-8d3d-908237a704d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 18:12:22 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee751f3a7dd04437bb531e497c8fa2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 18:12:22 INFO: Downloaded file to C:\\Users\\Roland\\stanza_resources\\resources.json\n",
      "2024-09-12 18:12:23 INFO: Loading these models for language: en (English):\n",
      "=========================================\n",
      "| Processor | Package                   |\n",
      "-----------------------------------------\n",
      "| tokenize  | combined                  |\n",
      "| mwt       | combined                  |\n",
      "| pos       | combined_charlm           |\n",
      "| lemma     | combined_nocharlm         |\n",
      "| depparse  | combined_charlm           |\n",
      "| sentiment | sstplus_charlm            |\n",
      "| ner       | ontonotes-ww-multi_charlm |\n",
      "=========================================\n",
      "\n",
      "2024-09-12 18:12:23 INFO: Using device: cpu\n",
      "2024-09-12 18:12:23 INFO: Loading: tokenize\n",
      "2024-09-12 18:12:25 INFO: Loading: mwt\n",
      "2024-09-12 18:12:25 INFO: Loading: pos\n",
      "2024-09-12 18:12:26 INFO: Loading: lemma\n",
      "2024-09-12 18:12:26 INFO: Loading: depparse\n",
      "2024-09-12 18:12:26 INFO: Loading: sentiment\n",
      "2024-09-12 18:12:27 INFO: Loading: ner\n",
      "2024-09-12 18:12:27 INFO: Done loading processors!\n",
      "2024-09-12 18:12:27 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd505b1154b41a299948f277aaecf1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 18:12:27 INFO: Downloaded file to C:\\Users\\Roland\\stanza_resources\\resources.json\n",
      "2024-09-12 18:12:27 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-09-12 18:12:27 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| mwt       | combined |\n",
      "========================\n",
      "\n",
      "2024-09-12 18:12:27 INFO: Using device: cpu\n",
      "2024-09-12 18:12:27 INFO: Loading: tokenize\n",
      "2024-09-12 18:12:27 INFO: Loading: mwt\n",
      "2024-09-12 18:12:27 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp_stanza = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse,sentiment,ner')\n",
    "nlp_tokens = stanza.Pipeline(lang='en', processors='tokenize', use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adafa575-fef2-47a8-ad4b-690d3cdc77a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_spacy = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Add the benepar parser to the pipeline\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained('t5-small', clean_up_tokenization_spaces=True)  \n",
    "# default is currently True but will change to False\n",
    "\n",
    "#nlp_spacy.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24cd98d-fecd-47ae-934f-11ab9a1d0ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Roland/Documents/AI/stylometry/Kazuo Ishiguro - The Remains of the Day.txt\n"
     ]
    }
   ],
   "source": [
    "source_texts= list()\n",
    "source_texts.append(\"Kazuo Ishiguro - Never Let Me Go.txt\")\n",
    "source_texts.append(\"Kazuo Ishiguro - The Remains of the Day\")\n",
    "source_texts.append(\"Kazuo Ishiguro - A Pale View of Hills-Knopf Doubleday Publishing Group (1990)\")\n",
    "source_texts.append(\"Kazuo-Ishiguro-When-We-Were-Orphans-Alfred-A.-Knopf_Vintage-_2001_\")\n",
    "source_texts.append(\"The Buried Giant (Kazuo Ishiguro) (Z-Library)-1\")\n",
    "source_texts.append(\"Kazuo Ishiguro - The Unconsoled-Vintage (1996)\")\n",
    "directory_path = \"C:/Users/Roland/Documents/AI/stylometry/\"\n",
    "file_path = directory_path+source_texts[1]+\".txt\"\n",
    "print (file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b70941-aa90-4c56-a8e1-d9f1dde577c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Roland/Documents/AI/stylometry/Kazuo Ishiguro - The Remains of the Day\n"
     ]
    }
   ],
   "source": [
    "file_path = file_path[:-4]\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5473c7a-4af2-425a-abcd-23df003f90cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Roland/Documents/AI/stylometry/Kazuo Ishiguro - The Remains of the Day - edited 1.txt\n"
     ]
    }
   ],
   "source": [
    "file_path = file_path + \" - edited 1.txt\"\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3be5dd1-b1c4-484d-a3f9-75d0dcd7b937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423412\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    text = file.read()\n",
    "print (len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "882d4aa6-951a-4b76-891f-280108318805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Roland/Documents/AI/stylometry/Kazuo Ishiguro - The Remains of the Day - edited 2.txt\n"
     ]
    }
   ],
   "source": [
    "save_path = file_path[:-5]\n",
    "save_path = save_path + \"2.txt\"\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b653cf8b-a906-4623-b609-48bf62f1e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the text with stanza \n",
    "\n",
    "# Record the start time\n",
    "start_time = datetime.now()\n",
    "print(f\"Starting processing at: {start_time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "memcheck()\n",
    "doc_stanza = nlp_stanza(text)\n",
    "memcheck()\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f\"Completed parsing at: {end_time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "# Print the time taken in hours, minutes, and seconds\n",
    "hours, remainder = divmod(time_taken.seconds, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print(f\"Time Taken: {hours} hours, {minutes} minutes, {seconds} seconds\")\n",
    "\n",
    "print(f\"\\ndoc_stanza has {len(doc_stanza.sentences)} sentences.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3679f96e-a99d-4162-b101-a74ea76f2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_text_in_context(text, words, window = 75):\n",
    "#Finds the first occurrence of each word in target text and displays it\n",
    "    \n",
    "    for word in words:\n",
    "        ind = text.find(word)\n",
    "        if ind == -1:\n",
    "            print (f\"{word} not found in text\")\n",
    "        else:\n",
    "            display_text = text[ind-window:ind+window+1]\n",
    "            display_text = display_text.replace(\"\\n\", \" \")\n",
    "            display_text = display_text.replace(\"\\t\", \" \")\n",
    "            print(display_text)\n",
    "\n",
    "def display_words_in_context(text_words, words, repeat = False, window = 2):\n",
    "# Finds the first occurrence of each word in target list of words. Optionally finds every subsequent occurrence     \n",
    "    if not repeat:\n",
    "        for word in words:\n",
    "            try:\n",
    "                index = text_words.index(word)\n",
    "                #print(f\"The index of '{word}' is: {ind}\")\n",
    "                display_text = ' '.join(text_words[index - window:index])\n",
    "                display_text = display_text + \" [\" + word + \"] \"\n",
    "                display_text = display_text + ' '.join(text_words[index + 1 : index + window + 1])\n",
    "                print(display_text)\n",
    "            except ValueError:\n",
    "                print(f\"'{word}' not found in the text.\")\n",
    "    else:\n",
    "        for word in words:\n",
    "            indices = [index for index, value in enumerate(text_words) if value == word]\n",
    "            if len(indices) == 0:\n",
    "                print(f\"'{word}' not found in the text.\")\n",
    "            else:\n",
    "                for index in indices:\n",
    "                    display_text = ' '.join(text_words[index - window:index])\n",
    "                    display_text = display_text + \" [\" + word + \"] \"\n",
    "                    display_text = display_text + ' '.join(text_words[index + 1 : index + window + 1])\n",
    "                    print(display_text)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "169f2aaf-8823-4555-86c9-7ea1bcdcc146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def where_is(word):\n",
    "    # finds if spell checker has flagged a word.  Must run spell checker first.\n",
    "    if (word in spell_set_1): \n",
    "        print (\"In spell set 1\")\n",
    "    if (word in blob_set_1):\n",
    "        print (\"In blob set 1\")\n",
    "    if (word in spell_set_1) or (word in blob_set_1):\n",
    "        display_words_in_context(test_words_1, [word], False, 6)\n",
    "    if (word in spell_set_2): \n",
    "        print (\"In spell set 2\")\n",
    "    if (word in blob_set_2):\n",
    "        print (\"In blob  set 2\")\n",
    "    if (word in spell_set_2) or (word in blob_set_2):\n",
    "        display_words_in_context(test_words_2, [word], False, 6)\n",
    "    if (word in spell_set_3): \n",
    "        print (\"In spell set 3\")\n",
    "    if (word in blob_set_3):\n",
    "        print (\"In blob set 3\")\n",
    "    if (word in spell_set_1) or (word in blob_set_3):\n",
    "        display_words_in_context(test_words_3, [word], False, 6)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29278a47-903b-4cda-9983-e1625d9ce6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hyphenated_words(text):\n",
    "    # Use regex to find words that are hyphenated across lines\n",
    "    # Match sequences where a hyphen is at the end of a line, followed by a newline, and then continued with a word\n",
    "    hyphenated_words = re.findall(r\"(\\w+)-\\n(\\w+)\", text)\n",
    "\n",
    "    for first_part, second_part in hyphenated_words:\n",
    "        print(f\"Found broken word: {first_part}-{second_part}\")\n",
    "    print(f\"{len(hyphenated_words)} hyphenated words found, text length is: {len(text)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db25ec42-fd25-4ccb-8473-aee451fffdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_hyphenated_words(text, show_changes = False):\n",
    "    # This regular expression captures words separated by a hyphen, with letters on both sides.\n",
    "    pattern = r'(\\b\\w+)-(\\w+\\b)'\n",
    "    \n",
    "    # Function to handle replacement and printing\n",
    "    def replacement(match):\n",
    "        # Original hyphenated word\n",
    "        original_word = match.group(0)\n",
    "        # Replacement word (with space instead of hyphen)\n",
    "        altered_word = match.group(1) + \" \" + match.group(2)\n",
    "        \n",
    "        # Print the hyphenated word that was altered\n",
    "        if show_changes: print(f\"Altered: {original_word} -> {altered_word}\")\n",
    "        \n",
    "        return altered_word\n",
    "\n",
    "    # Replace hyphenated words and call the replacement function\n",
    "    result = re.sub(pattern, replacement, text)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7cf453-faef-4e39-a15a-0e90509de19c",
   "metadata": {},
   "source": [
    "Prepare words for spell checking.\n",
    "\n",
    "The first set has punctuation removed\n",
    "\n",
    "The second set has punctuation removed after replacing hyphenated words with spaces\n",
    "\n",
    "The third set is also made lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "865e6cc2-e337-46a9-a4de-df1665fc9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words_1 = text.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "unhyphenated = replace_hyphenated_words(text)\n",
    "test_words_2 = unhyphenated.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "test_words_3 = unhyphenated.translate(str.maketrans('', '', string.punctuation)).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d62cea13-8b4e-4666-8ede-a0706b934a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 414 394\n"
     ]
    }
   ],
   "source": [
    "# Use spellchecker to validate words\n",
    "# Initialize spell checker\n",
    "spell = SpellChecker()\n",
    "\n",
    "\n",
    "# Find words not in the dictionary\n",
    "spell_set_1 = {word for word in test_words_1 if word not in spell}\n",
    "spell_set_2 = {word for word in test_words_2 if word not in spell}\n",
    "spell_set_3 = {word for word in test_words_3 if word not in spell}\n",
    "\n",
    "print(len(spell_set_1), len(spell_set_2), len(spell_set_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98cf4990-da40-4c90-a739-04d89d0cec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors found with punctuation removed only: 500\n",
      "errors found with punctuation removed after replacing hyphens: 414\n",
      "errors found with case lowered too:  394\n",
      "errors eliminated by removing hyphens:  102\n",
      "errors introduced by removing hyphens:  16\n",
      "errors eliminated by lowering case:  246\n",
      "errors introduced by lowering case:  226\n"
     ]
    }
   ],
   "source": [
    "print(f\"errors found with punctuation removed only: {len(spell_set_1)}\")\n",
    "print(f\"errors found with punctuation removed after replacing hyphens: {len(spell_set_2)}\")\n",
    "print(f\"errors found with case lowered too:  {len(spell_set_3)}\")     \n",
    "print(f\"errors eliminated by removing hyphens:  {len(spell_set_1 - spell_set_2)}\")\n",
    "print(f\"errors introduced by removing hyphens:  {len(spell_set_2 - spell_set_1)}\")\n",
    "print(f\"errors eliminated by lowering case:  {len(spell_set_2 - spell_set_3)}\")\n",
    "print(f\"errors introduced by lowering case:  {len(spell_set_3 - spell_set_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d1166d1-ae38-4e6d-b8e9-e68e847c6496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longue inwaiting Karl Heinz loverStevens pre ordinated sheetings martialling co ofhand empting Semitic vident humouredness un\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oddities = list(spell_set_2 - spell_set_1)\n",
    "print (' '.join(oddities))\n",
    "print(\"\\n\")\n",
    "# display_words_in_context(test_words_2, oddities, True, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e51945-72f1-4f3c-a7db-92110899501e",
   "metadata": {},
   "source": [
    "Select the ones that could be errors and find them in the original text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d559e4c-2a65-4d8f-b94a-1eb6b7b27861",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_oddities = [\"team of ladies\", \"sleights-of-hand\", \"re a nature-lover\", \"have been self-vident\"]\n",
    "#These should appear in the comprehensive search later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca179134-20fe-428d-a3fe-98abfe94d0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " been the great contrast in their backgrounds - bringing with them a large team of ladies-in-waiting and footmen, as well as a great many trunks. Then \n",
      "ts' designed to bring that extra bit out of staff, as well as the various 'sleights-of-hand' - the equivalent of a conjuror's - by which a butler could\n",
      "ct of my arrival and held out his glass.  \"I think it's admirable that you're a nature-lover,Stevens,\" he said, as I served him. \"And I dare say it's a\n",
      "ess of someone of your age and standing addressing him as 'William' should have been self-vident to you.\"  \"Mr Stevens, I may not have been a housekeep\n"
     ]
    }
   ],
   "source": [
    "display_text_in_context(text, selected_oddities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838f3c39-6375-4ddb-95cc-33ba96de9da1",
   "metadata": {},
   "source": [
    "Select the errors and add them to the replacements dictionary.  The rest of the oddities are not spelling errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88e447ed-757e-4368-b492-582e9a893dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_set_2_lowered = {word.lower() for word in spell_set_2}\n",
    "len(spell_set_2_lowered - spell_set_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c346be2-8deb-4457-ad08-57674caa52aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8820a237-0ea5-4b39-9f57-b77d0797fa72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01f5233c-d9c5-496d-a04c-a5b5bc0ed421",
   "metadata": {},
   "source": [
    "Check words that are picked out by spell checker when made lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "332081c8-f0e0-4e6a-8117-29413363c2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semitic granchester farradays britannica celts charleville reggie societys thornley eden yorkshire crosby saltash hardacres frau hertfordshire italian overath muggeridge versailles tavistock paris christmas hayes herr ritz simpson helston oswald chinaman american thatll taunton whittaker taylor attachã© loughborough compton belgians martha moscombe cornwall semitism mursden darlington dave james roosevelt charles symonss boer tj1e clementss ribbentrop ifi pennsylvania tory george bremann dr reginalds wakefields dorset blair lewiss britain churchill dupont ohnothing davidson frenchmen dickenson taylors catherines southampton mosleys imvery morgan karl ploughmans england carlisles catherine barnets jones saltman redding ruhr exeter morgans hitlers seamus mortimer bridewood eleanor rhineland wilkinson italians belgian englishman sunday ribbentrops mortimers giffen halifax bremanns bernard englishmen morphy europe wer dorothy harrys britons trevor silverss giffens nazis barnet johnson carolyn frenchman austin iarrived chalmers jamess ican benn camberley stevens americans stanbury ketteridge kenton william allshot daniels infact mrs nellie ive londons chinamen wakefield ok heinz mauvis jewry humphreys dh rayne wetherby agnes bentley mr donalds neighbourss clements darlingtons hitler iii scotland meredith brigid laval victorian keynes edward mosley germans boston maynard kentons georges sydney british carlisle september devon london davids oxfordshire brigoon symons loverstevens thornton englands chainbers david dorchester winston leslie benns campbell henderson olympic lisa lloyd richard rolands branbury sarah salisbury karlheinz wakeling jewish joness lindsay berkshire im nuremberg april farraday leonard swiss farradayscircle duponts charless andrews herman alice astor thursday reginald jews williams\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case_oddities = list(spell_set_3 - spell_set_2)\n",
    "print (' '.join(case_oddities))\n",
    "print(\"\\n\")\n",
    "# display_words_in_context(test_words_3, case_oddities, False, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af28b1d-e513-447f-9e84-05dfc47b8c49",
   "metadata": {},
   "source": [
    "Check words that picked out by spell checker with the original case but passed when made lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18c7a5b1-a102-4812-836c-c600d525cf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davids Hitlers Hitler Victorian Isnt Hayes Eden Ritz Dorchester Allshot Thursday Reginalds Rayne Charleville Exeter Gentlemans Martha Granchester tJ1e Clementss Ohnothing Wakefields Boer Keynes Eleanor Infact Belgian Mustnt Muggeridge Frenchmen Bentley Duponts Versailles Mauvis Dignitys Jewish Ribbentrop Kenton KarlHeinz Astor Semitic Mr Mosleys Dorothy Dh Reggie Moscombe Barnet Giffens Helston Karl Mursden loverStevens Richard Mortimer James Taylors Salisbury Thatll Herman attachÃ© Belgians Winston Daniels Trevor Morgan September Englands Heinz Nazis Christmas Cornwall Carlisle Thornley Branbury Oswald OK Tory Ruhr Andrews Youre Farradayscircle Lloyd Charles Taunton Ive Darlington Dr Saltash Mortimers Couldnt William Wetherby Barnets Overath Americans Symons Laval Pennsylvania Semitism British Kentons Mrs Whittaker Frenchman Youd Alice Dickenson Britons Silverss Nellie Oxfordshire Seamus Chalmers Neighbourss Catherine Youve Dont London Churchill Leonard Benn Edward Chinaman Farraday Societys Loughborough Wilkinson Stanbury Celts April Devon Carolyn Redding Youll Thats Havent Germans Theyre Meredith Im Lewiss American ifI Todays Darlingtons Imvery Jewry England Campbell Bremanns Catherines Europe Bridewood Donalds Crosby Arent Austin Nuremberg Frau Wakeling Weve Camberley Bremann Simpson Compton Johnson Italians Blair Sunday Herr Hertfordshire Sydney Chinamen Harrys George Maynard Rolands David Symonss Mosley Joness Yorkshire Britain Ribbentrops Bernard Englishman Tavistock Englishmen Jones Saltman Giffen Humphreys Wer Neighbours Iarrived Dorset Whos Southampton Davidson Roosevelt Boston Britannica Halifax Rhineland Olympic Lindsay Farradays Dave Taylor Leslie Stevens Henderson Ican Charless Berkshire Thornton Morgans Williams Chainbers Ploughmans Theres Morphy Carlisles Ketteridge Lisa Benns III Sarah Italian Brigoon Dupont Reginald Londons Hardacres Agnes Clements Swiss Wakefield Paris Co Jamess Georges Jews Brigid Scotland\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_case_oddities = list(spell_set_2 - spell_set_3)\n",
    "print (' '.join(inverse_case_oddities))\n",
    "print(\"\\n\")\n",
    "# display_words_in_context(test_words_2, inverse_case_oddities, False, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1faabab-b81d-4c9b-af5f-c0ed087f9c6c",
   "metadata": {},
   "source": [
    "Run text blob, an alternative spell checker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32fb85e6-96cf-4714-aefc-90762318eb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing at: 00:59:21\n",
      "Completed processing at: 01:17:36\n",
      "Time Taken: 0 hours, 18 minutes, 14 seconds\n",
      "1301 1201 905\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(f\"Starting processing at: {start_time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "\n",
    "\n",
    "# Find invalid words\n",
    "blob_set_1 = set()\n",
    "for word in test_words_1:\n",
    "    result = Word(word).spellcheck()\n",
    "    if result[0][1] < 1.0 or result[0][0] != word:\n",
    "        blob_set_1.add(word)\n",
    "\n",
    "blob_set_2 = set()\n",
    "for word in test_words_2:\n",
    "    result = Word(word).spellcheck()\n",
    "    if result[0][1] < 1.0 or result[0][0] != word:\n",
    "        blob_set_2.add(word)\n",
    "\n",
    "blob_set_3 = set()\n",
    "for word in test_words_3:\n",
    "    result = Word(word).spellcheck()\n",
    "    if result[0][1] < 1.0 or result[0][0] != word:\n",
    "        blob_set_3.add(word)\n",
    "        \n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f\"Completed processing at: {end_time.strftime('%H:%M:%S')}\")\n",
    "time_taken(start_time, end_time)\n",
    "\n",
    "print(len(blob_set_1), len(blob_set_2), len(blob_set_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8762d370-98fe-4d9d-8acb-5e9e5c9397aa",
   "metadata": {},
   "source": [
    "Now look at how many each spell checker finds that the other didn't find:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02d5ca3f-ce13-48b3-9d4b-fb3c41532bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spell / blob 1 have: 500 / 1301\n",
      "spell / blob 2 have: 414 / 1201\n",
      "spell / blob 3 have: 394 / 905\n",
      "spell unique / blob unique 1 have: 106 / 907\n",
      "spell unique / blob unique 2 have: 111 / 898\n",
      "spell unique / blob unique 3 have: 128 / 639\n"
     ]
    }
   ],
   "source": [
    "spell_only_1 = spell_set_1 - blob_set_1\n",
    "spell_only_2 = spell_set_2 - blob_set_2\n",
    "spell_only_3 = spell_set_3 - blob_set_3\n",
    "\n",
    "blob_only_1 = blob_set_1 - spell_set_1\n",
    "blob_only_2 = blob_set_2 - spell_set_2\n",
    "blob_only_3 = blob_set_3 - spell_set_3\n",
    "\n",
    "both_3 = spell_set_3 & blob_set_3\n",
    "either_3 = spell_set_3 | blob_set_3 # this is an OR symbol\n",
    "\n",
    "print(f\"spell / blob 1 have: {len(spell_set_1)} / {len(blob_set_1)}\")\n",
    "print(f\"spell / blob 2 have: {len(spell_set_2)} / {len(blob_set_2)}\")\n",
    "print(f\"spell / blob 3 have: {len(spell_set_3)} / {len(blob_set_3)}\")\n",
    "print(f\"spell unique / blob unique 1 have: {len(spell_only_1)} / {len(blob_only_1)}\")\n",
    "print(f\"spell unique / blob unique 2 have: {len(spell_only_2)} / {len(blob_only_2)}\")\n",
    "print(f\"spell unique / blob unique 3 have: {len(spell_only_3)} / {len(blob_only_3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6d56e8c-ea9c-4b9f-b94b-fb070adac2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_words_in_context(test_words_1, spell_only_1, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39ebeb79-bc0e-4edf-8928-bf048c82ac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleights inwaiting Heinz martialling jacketed tiles pep matching ups newt slated chock longue hog bores sheeted Semitic humouredness mating Karl loverStevens ofhand sheetings vident\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blob_oddities = list(blob_set_2 - blob_set_1)\n",
    "print (' '.join(blob_oddities))\n",
    "print(\"\\n\")\n",
    "# display_words_in_context(test_words_2, oddities, True, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "b3d8b220-e1de-4784-88f8-9060ffda4132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spell_only_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cee446b7-3e9d-43cd-b0f6-7ed4e242c21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arec simplyaccepting semitic gotto theres granchester thatsall farradays isnt donttake shouldnt celts charleville youve andthe reggie dignitys societys thornley saltash everyones crosby hardacres theyll frau hertfordshire overath muggeridge tavistock itinvolved leant ritz neednt hed helston savour oswald chinaman thatll weve taunton whittaker attachã© loughborough floutings compton manoeuvres istrue whos wasnt moscombe sheetings banterings semitism mursden tosit enamoured wouldnt symonss tj1e youre clementss ifi ribbentrop inwaiting aint seehe reginalds wakefields bremann batmans allhis dorset lto distinguishedand blair lewiss dupont specia1 ohnothing davidson ill1terest dickenson taylors catherines het mosleys villagesir imvery ploughmans carlisles barnets loc saltman lotyou verypleased gentlemans didnt pres redding docrucially ruhr exeter morgans avery hitlers seamus bridewood breadknives eleanor unburdensome friendsand rhineland wilkinson scepticism ribbentrops couldnt anothers anysuch civvy bremanns bernard mortimers giffen anybodys morphy wer splendours harrys britons trevor martialling silverss giffens arent nazis barnet carolyn canonly thevery thats iarrived chalmers jamess ican falconing startseeing benn camberley ketteridge stanbury kenton womans oclock allshot contemplatin8 daniels infact ot nellie ive longue hasnt londons chinamen wakefield 0f roas heinz mustnt mauvis jewry humphreys congenia1 agre ladys humouredness annexe rayne ofthe dh wetherby owardst bentley gentlemens itsrather colouring analysed donalds ofhand neighbourss youd clements darlingtons confidentia1 hitler analysing manoeuvring theyve cansee brigid laval victorian keynes mosley youll maynard theyre kentons werent carlisle sceptical devon prise davids armoury brigoon symons everythings loverstevens thornton todays englands canbe chainbers whod manservants inflexions dorchester blackshirts manoeuvred benns henderson olympic im countrys rolands branbury salisbury karlheinz wakeling lookingback somebodys joness lindsay thelikes nuremberg farraday shant beyondsuch leonard unassaulted doesnt citys farradayscircle duponts itll unrevealing havent charless herman vident reinstitute al1 reginald latters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(' '.join(word for word in both_3))\n",
    "# display_words_in_context(test_words_2, spell_only_2 - spell_only_1, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a5d6e9f0-c4c1-4ec3-bc7f-617d8a803e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0f', 'agre', 'al1', 'allhis', 'allshot', 'andthe', 'anysuch', 'arec', 'avery', 'bethat', 'beyondsuch', 'canbe', 'canonly', 'cansee', 'carryon', 'chainbers', 'civvy', 'confidentia1', 'contemplatin8', 'dh', 'distinguishedand', 'docrucially', 'donttake', 'ell', 'farradayscircle', 'friendsand', 'gotto', 'het', 'iarrived', 'ican', 'ifi', 'ill1terest', 'imvery', 'infact', 'inwaiting', 'istrue', 'itinvolved', 'itsrather', 'loc', 'lookingback', 'lotyou', 'loverstevens', 'lto', 'notseek', 'ofhand', 'ofthe', 'ohnothing', 'ot', 'owardst', 'prise', 'putout', 'redding', 'roas', 'seehe', 'selfvident', 'simplyaccepting', 'startseeing', 'thatsall', 'thelikes', 'thevery', 'ting', 'tj1e', 'tosit', 'verypleased', 'villagesir', 'wer', 'witha']\n"
     ]
    }
   ],
   "source": [
    "errors = \"witha bethat selfvident notseek distinguishedand redding civvy ting carryon putout ell arec simplyaccepting gotto thatsall donttake andthe itinvolved istrue tosit tj1e ifi inwaiting seehe allhis lto ohnothing ill1terest het villagesir imvery loc lotyou verypleased docrucially avery friendsand anysuch wer thevery iarrived ican startseeing canonly allshot contemplatin8 infact ot 0f roas agre ofthe dh owardst itsrather ofhand confidentia1 cansee prise loverstevens canbe chainbers lookingback thelikes beyondsuch farradayscircle al1\"\n",
    "errors = errors.split()\n",
    "errors = sorted(errors)\n",
    "print (errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "03e1fe36-5eda-4f7c-935a-74be091c28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = ['0f', 'agre', 'al1', 'allhis', 'andthe', 'anysuch', 'arec', 'avery', 'be-that', 'beyondsuch', 'canbe', 'canonly', 'cansee', 'carryon', 'Chainbers', 'confidentia1', 'contemplatin8', 'Dh', \"'distinguished',and\", 'docrucially', \"don'ttake\", 'T ell', \"Farraday'scircle\", 'friendsand', 'gotto', 'het', 'Iarrived', 'Ican', \"if'-I\", 'ill1terest', \"I'mvery\", 'Infact', 'istrue', 'it,involved', \"it'srather\", 'loc ked', 'lookingback', 'lot,you', 'lover,Stevens', 'lto', 'not-seek', 'ofthe', 'Oh,nothing', 'ot', 'owardst', 'putout', 'roas ting', 'seehe', 'self-vident', 'simplyaccepting', 'startseeing', \"that'sall\", 'thelikes', 'thevery', 'tJ1e', 'tosit', 'verypleased', 'village,sir', 'wer', 'with-a']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e946ebd0-75f3-4083-a3a9-7bc4838484e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = ['of', 'agree', 'all', 'all his', 'and the', 'any such', 'care', 'a very', 'be that', 'beyond such', 'can be', 'can only', 'can see', 'carry on', 'Chambers', 'confidential', 'contemplating', 'Oh', \"'distinguished', and\", 'do crucially', \"don't take\", 'Tell', 'Farradays Circle', 'friends and', 'got to', 'the', 'I arrived', 'I can', 'if I', 'interest', \"I'm very\", 'In fact', 'is true', 'it involved', \"its rather\", 'locked', 'looking back', 'lot, you', 'lover, Stevens', 'to', 'not seek', 'of the', 'Oh, nothing', 'to', 'towards', 'put out', 'roasting', 'see he', 'self-evident', 'simply accepting', 'start seeing', \"that's all\", 'the likes', 'the very', 'the', 'to sit', 'very pleased', 'village, sir', 'were', 'with a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "67eb6328-63c2-4fdb-a2aa-035c0c21aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for error, correction in zip(errors, corrections):\n",
    "    if error == correction:\n",
    "        display_words_in_context(test_words_3, [error], False, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "04b90b91-cb83-4a82-8cfd-7530e5b1e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in errors:\n",
    "    if word not in text:\n",
    "        display_words_in_context(test_words_3, [word], False, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7319fa11-3b46-49b0-aa44-fd3cb74b62ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tly, sir, I don't know what else you could do at this hour. The wife would never forgive me if'-I were to let you away into the night.\"  Thus it was th\n"
     ]
    }
   ],
   "source": [
    "display_text_in_context(text, [\"never forgive me\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "81bdd1cb-bb9b-46b8-ad5a-0f59c55dd11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([word in blob_set_3 for word in errors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "cc2b3ecf-0cb8-4c0f-a405-964c1627d40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In blob set 1\n",
      "certain matter weve been debating T [ell] me do you suppose the debt\n",
      "In blob  set 2\n",
      "certain matter weve been debating T [ell] me do you suppose the debt\n",
      "In blob set 3\n",
      "certain matter weve been debating t [ell] me do you suppose the debt\n"
     ]
    }
   ],
   "source": [
    "where_is(\"ell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "13d72464-2574-40df-9f36-ffb4b7a10957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "really think you should take a break. I'll foot the bill for the gas. You fellows, you're always locked up in these big Houses helping out, how do you \n"
     ]
    }
   ],
   "source": [
    "display_text_in_context(text,[\"ell\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "3472945e-1b91-4232-b84f-b0475f868997",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {error: correction for error, correction in zip (errors, corrections)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d5ee09f4-ed5a-4c5f-b4af-69068856abdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with a\n"
     ]
    }
   ],
   "source": [
    "print(replacements[\"with-a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "5eec50fa-f189-4614-9c82-7ae26dfffef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ups newt tiles sheeted sleights pep mating slated hog jacketed bores chock matching\n",
      "and the turn [ups] of my trousers\n",
      "as falconing or [newt] mating attributes none\n",
      "other than roof [tiles] and guttering The\n",
      "would be dust [sheeted] leaving all the\n",
      "as the various [sleights] ofhand the equivalent\n",
      "a military style [pep] talk impressing upon\n",
      "falconing or newt [mating] attributes none of\n",
      "clusters of dark [slated] roofs here and\n",
      "understand So much [hog] wash has been\n",
      "many stern dark [jacketed] gentlemen sometimes sitting\n",
      "permit the twelve [bores] to be used\n",
      "his foot is [chock] full of notes\n",
      "filled with ill [matching] armchairs and occasional\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(word for word in (blob_only_2 - blob_only_1)))\n",
    "display_words_in_context(test_words_2, blob_only_2 - blob_only_1, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "96ce6245-245f-4485-a247-9c51944a1c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "martha boston austin alice darlington morgan thursday james leslie boer mr italians mortimer englishmen campbell georges andrews southampton stevens london david meredith europe williams frenchmen berkshire william halifax british swiss scotland hayes jewish dr mrs christmas iii britannica roosevelt paris astor american frenchman germans sydney sunday versailles englishman johnson taylor belgians simpson herr dorothy eden agnes jones sarah britain ok lisa lloyd karl catherine winston yorkshire tory churchill italian cornwall pennsylvania oxfordshire americans jews richard september england belgian charles april edward dave george\n",
      "to speak to [martha] or dorothy or\n",
      "mr farraday amidst [boston] society they paid\n",
      "formidable mrs eleanor [austin] at that time\n",
      "in mind of [alice] white do you\n",
      "me away from [darlington] hall for as\n",
      "to me as [morgan] sir trevor morgan\n",
      "off again on [thursday] miss kenton on\n",
      "butler to sir [james] chambers and mr\n",
      "wireless his names [leslie] mandrake i just\n",
      "attack on civilian [boer] settlements overwhelming evidence\n",
      "the comfort of [mr] farradays ford an\n",
      "also belgians french [italians] swiss they were\n",
      "attic room mrs [mortimer] the cook was\n",
      "difference with you [englishmen] mr lewis said\n",
      "to mr john [campbell] with his well\n",
      "then with mr [georges] conference ending yet\n",
      "outside its george [andrews] just happened to\n",
      "her aunt in [southampton] otherwise following my\n",
      "said you realize [stevens] i dont expect\n",
      "if repeated in [london] would end in\n",
      "me by mr [david] charles of the\n",
      "grey colour dr [meredith] had already been\n",
      "the whole course [europe] is taking in\n",
      "are no other [williams] in this house\n",
      "with some disgust [frenchmen] really i mean\n",
      "sunshine towards the [berkshire] border i continued\n",
      "to someone named [william] is that so\n",
      "talking of lord [halifax] as things turned\n",
      "region of the [british] isles i heartily\n",
      "belgians french italians [swiss] they were diplomats\n",
      "distinguished persons from [scotland] it is true\n",
      "attempt of the [hayes] society to devise\n",
      "lordship never allowed [jewish] people to enter\n",
      "oddly grey colour [dr] meredith had already\n",
      "prevent all but [mrs] clements leaving for\n",
      "one discounts the [christmas] cards but let\n",
      "glance through volume [iii] of mrs symonss\n",
      "set of the [britannica] it was a\n",
      "supposes even president [roosevelt] look at him\n",
      "separate trips to [paris] within the space\n",
      "i recall lady [astor] remarking not without\n",
      "instance of an [american] gentlemans unfamiliarity with\n",
      "certain extremely illustrious [frenchman] i will merely\n",
      "only britons and [germans] but also belgians\n",
      "valet to mr [sydney] dickenson and there\n",
      "shamed silence that [sunday] afternoon many years\n",
      "been done at [versailles] and that it\n",
      "to be an [englishman] of course you\n",
      "is from mrs [johnson] a companion of\n",
      "mr and mrs [taylor] that is to\n",
      "germans but also [belgians] french italians swiss\n",
      "i remember mr [simpson] the landlord of\n",
      "his friendship with [herr] karl heinz bremann\n",
      "to martha or [dorothy] or any members\n",
      "likes of mr [eden] and lord halifax\n",
      "hire rosemary and [agnes] on mrs clementss\n",
      "smith and mr [jones] since they are\n",
      "ears ruth and [sarah] have been members\n",
      "of ours great [britain] and there may\n",
      "his past employers [ok] stevens so you\n",
      "the housemaid called [lisa] that is to\n",
      "that time mr [lloyd] george had called\n",
      "friendship with herr [karl] heinz bremann herr\n",
      "was the war [catherine] grew up and\n",
      "about having met [winston] churchill and so\n",
      "belly laugh and [yorkshire] charm made him\n",
      "sound true blue [tory] truth is hes\n",
      "ever met mr [churchill] mr churchill he\n",
      "the afternoon an [italian] gentleman arrived accompanied\n",
      "kentons departure to [cornwall] in 1936 myself\n",
      "mr lewiss native [pennsylvania] back to the\n",
      "house in allshot [oxfordshire] clearly the story\n",
      "very highly placed [americans] and it seems\n",
      "we cannot have [jews] on the staff\n",
      "it was sir [richard] fox a colleague\n",
      "between august and [september] having made this\n",
      "finest countryside of [england] to the west\n",
      "i heard the [belgian] clergyman exclaim that\n",
      "by mr david [charles] of the charles\n",
      "that incident last [april] relating to the\n",
      "1932 by sir [edward] blair practically brand\n",
      "myself sir but [dave] thornton passed it\n",
      "time mr lloyd [george] had called for\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(word for word in (spell_only_3 - spell_only_2 - spell_only_1)))\n",
    "display_words_in_context(test_words_3, spell_only_3 - spell_only_2 - spell_only_1, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "80a20f68-d116-4d08-8742-47a8861c7269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viscount continentals silvers mandrake bolsheviks hmm fascists nil bolshevik spencer cardinals grahams rosemary\n",
      "the portrait of [viscount] wetherby when my\n",
      "this is true [continentals] are unable to\n",
      "of mr john [silvers] the industrialist where\n",
      "his names leslie [mandrake] i just wondered\n",
      "french and the [bolsheviks] im very sorry\n",
      "a comic figure [hmm] thats taking it\n",
      "british union of [fascists] such claims can\n",
      "to recognize the [nil] significance of silver\n",
      "the proprieties of [bolshevik] russia this provoked\n",
      "you stevens mr [spencer] here wishes a\n",
      "way from mr [cardinals] writing desk gave\n",
      "objection to mr [grahams] analogy was the\n",
      "pleased to hire [rosemary] and agnes on\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(word for word in (blob_only_3 - blob_only_2 - blob_only_1)))\n",
    "display_words_in_context(test_words_3, blob_only_3 - blob_only_2 - blob_only_1, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c5c1a-765d-4437-9779-ad2e660470f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf4cf3b-7ae6-4e23-a7a0-31697822a7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc6279f-1709-454e-ac5b-7ac43b78c086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57df1d8-6fcc-4357-9728-f5db60e255c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "a4ec8f3a-dde0-4ada-8a9a-53d314943e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "111\n",
      "128\n",
      "907\n",
      "898\n",
      "639\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "afd26866-fded-4a8d-bdad-6a0fb5331212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barnets in both\n",
      "[('Markets', 0.31543624161073824), ('Parents', 0.28859060402684567), ('Harness', 0.18120805369127516), ('Carpets', 0.087248322147651), ('Earnest', 0.06711409395973154), ('Earners', 0.053691275167785234), ('Hornets', 0.006711409395973154)]\n",
      "[('markets', 0.2554347826086957), ('parents', 0.23369565217391305), ('harness', 0.14673913043478262), ('bayonets', 0.07608695652173914), ('carpets', 0.07065217391304347), ('earnest', 0.05434782608695652), ('earners', 0.043478260869565216), ('banners', 0.03260869565217391), ('barrels', 0.02717391304347826), ('barges', 0.010869565217391304), ('barest', 0.010869565217391304), ('hornets', 0.005434782608695652), ('baskets', 0.005434782608695652), ('baronet', 0.005434782608695652), ('baroness', 0.005434782608695652), ('barns', 0.005434782608695652), ('bargees', 0.005434782608695652), ('badness', 0.005434782608695652)]\n",
      "\n",
      "\n",
      "TONIGHT in 2 but not in 3\n",
      "[('TONIGHT', 0.0)]\n",
      "\n",
      "\n",
      "Carlisle in both\n",
      "[('Carlisle', 0.0)]\n",
      "[('carlyle', 1.0)]\n",
      "\n",
      "\n",
      "Sit in 2 but not in 3\n",
      "[('It', 0.9689739635307992), ('Sit', 0.008074027034382654), ('Lit', 0.006713235961172095), ('Bit', 0.005715322507484351), ('Fit', 0.0047174090537966075), ('Hit', 0.0019051075024947837), ('Wit', 0.0013607910732105597), ('Pit', 0.0013607910732105597), ('Tit', 0.0006350358341649278), ('Kit', 0.0004535970244035199), ('Git', 9.071940488070398e-05)]\n",
      "\n",
      "\n",
      "Infact in both\n",
      "[('Fact', 0.8314285714285714), ('Intact', 0.05714285714285714), ('Infant', 0.04857142857142857), ('Enact', 0.03142857142857143), ('Infect', 0.025714285714285714), ('Enfant', 0.005714285714285714)]\n",
      "[('intact', 0.43478260869565216), ('infant', 0.3695652173913043), ('infect', 0.1956521739130435)]\n",
      "\n",
      "\n",
      "replacements in both\n",
      "[('replacement', 1.0)]\n",
      "\n",
      "\n",
      "Hard in 2 but not in 3\n",
      "[('Hard', 0.5960264900662252), ('Yard', 0.26158940397350994), ('Card', 0.09933774834437085), ('Ward', 0.04304635761589404)]\n",
      "\n",
      "\n",
      "undeniable in both\n",
      "[('undesirable', 0.7272727272727273), ('undefinable', 0.2727272727272727)]\n",
      "\n",
      "\n",
      "rapping in both\n",
      "[('tapping', 0.6666666666666666), ('wrapping', 0.25), ('sapping', 0.041666666666666664), ('mapping', 0.041666666666666664)]\n",
      "\n",
      "\n",
      "finalized in both\n",
      "[('penalized', 1.0)]\n",
      "\n",
      "\n",
      "Oswald in both\n",
      "[('Scald', 1.0)]\n",
      "[('onward', 0.6666666666666666), ('scald', 0.3333333333333333)]\n",
      "\n",
      "\n",
      "overstate in both\n",
      "[('overtake', 1.0)]\n",
      "\n",
      "\n",
      "Dickenson in both\n",
      "[('Dickinson', 1.0)]\n",
      "[('dickinson', 1.0)]\n",
      "\n",
      "\n",
      "inflexions in both\n",
      "[('inflexions', 0.0)]\n",
      "\n",
      "\n",
      "celebratory in both\n",
      "[('celebratory', 0.0)]\n",
      "\n",
      "\n",
      "Can in 2 but not in 3\n",
      "[('An', 0.5222764723832773), ('Man', 0.25205981080256334), ('Can', 0.1670735428745804), ('Ran', 0.049130302105584375), ('San', 0.003051571559353067), ('Van', 0.0028989929813854134), ('Fan', 0.0012206286237412267), ('Ban', 0.00091547146780592), ('Pan', 0.0006103143118706134), ('Dan', 0.0003051571559353067), ('Wan', 0.00015257857796765334), ('Nan', 0.00015257857796765334), ('Jan', 0.00015257857796765334)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for word in blob_set_2:\n",
    "    if word.lower() in blob_set_3:\n",
    "        print(f\"{word} in both\")\n",
    "        print(Word(word).spellcheck())\n",
    "        if word != word.lower():\n",
    "            print(Word(word.lower()).spellcheck())\n",
    "    else:\n",
    "        print (f\"{word} in 2 but not in 3\")\n",
    "        print(Word(word).spellcheck())\n",
    "    print(\"\\n\")    \n",
    "    counter = counter + 1\n",
    "    if counter > 15: break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed2fbb-f5a0-4bb1-b393-16de31da9166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da527b-568f-4896-8e01-68b7ed48a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = \"istrue canbe im tj1e overath laval itsrather wer silverss gotto thelikes ifi 0f prise ritz ofthe andthe lto lookingback al1 verypleased het thevery agre bethat seehe ot selfvident sleightsofhand cansee thatsall distinguishedand villagesir docrucially arec farradayscircle witha canonly barnets redding tosit clementss newtmating ill1terest anysuch dh lewiss donttake allhis contemplatin8 startseeing symons owardst imvery simplyaccepting selftraining wellcontented evercourteous donttake allhis lastminute civvy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0454a-fb4a-4054-94ac-24de224ee2da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b12d7a7e-1d51-498e-ab10-07a65049dc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "bad_words=[\"ohnothing\", \"iarrived\", \"friendsand\", \"allshot\"]\n",
    "for word in bad_words:\n",
    "    print(word in errors_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c92cadc7-565c-497d-8a01-72d61ed4fa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1e', \"Barnet's\", \"Clements's\", \"Farraday'scircle\", \"I'mvery\", 'Laval', \"Lewis's\", 'Overath', 'Redding', 'Ritz', \"Silvers's\", 'Symons', 'be-that', 'd-h', \"don'ttake\", \"don'ttake\", 'ever-courteous', \"it'srather\", 'last-minute', 'newt-mating', 'self-training', 'self-vident', 'sleights-of-hand', \"that'sall\", 'well-contented', 'with-a']\n"
     ]
    }
   ],
   "source": [
    "suggestions_split = suggestions.split(' ')\n",
    "suggestions_sorted = sorted(suggestions_split)\n",
    "print(suggestions_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "09427cc1-f405-4464-b6be-7fc259bd2fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0f', 'agre', 'al1', 'allhis', 'allhis', 'allshot', 'andthe', 'anysuch', 'arec', 'barnets', 'bethat', 'canbe', 'canonly', 'cansee', 'civvy', 'clementss', 'contemplatin8', 'dh', 'distinguishedand', 'docrucially', 'donttake', 'donttake', 'evercourteous', 'farradayscircle', 'friendsand', 'gotto', 'het', 'iarrived', 'ifi', 'ill1terest', 'im', 'imvery', 'istrue', 'itsrather', 'lastminute', 'laval', 'lewiss', 'lookingback', 'lto', 'newtmating', 'ofthe', 'ohnothing', 'ot', 'overath', 'owardst', 'prise', 'redding', 'ritz', 'seehe', 'selftraining', 'selfvident', 'silverss', 'simplyaccepting', 'sleightsofhand', 'startseeing', 'symons', 'thatsall', 'thelikes', 'thevery', 'tj1e', 'tosit', 'verypleased', 'villagesir', 'wellcontented', 'wer', 'witha']\n"
     ]
    }
   ],
   "source": [
    "errors_sorted = sorted(errors_split)\n",
    "print (errors_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "71d103da-705d-42d8-8f44-317d466de1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['istrue', 'canbe', 'im', 'tj1e', 'overath', 'laval', 'itsrather', 'wer', 'silverss', 'gotto', 'thelikes', 'ifi', '0f', 'prise', 'ritz', 'ofthe', 'andthe', 'lto', 'lookingback', 'al1', 'verypleased', 'het', 'thevery', 'agre', 'bethat', 'seehe', 'ot', 'selfvident', 'sleightsofhand', 'cansee', 'thatsall', 'distinguishedand', 'villagesir', 'docrucially', 'arec', 'farradayscircle', 'witha', 'canonly', 'barnets', 'redding', 'tosit', 'clementss', 'newtmating', 'ill1terest', 'anysuch', 'dh', 'lewiss', 'donttake', 'allhis', 'contemplatin8', 'startseeing', 'symons', 'owardst', 'imvery', 'simplyaccepting', 'selftraining', 'wellcontented', 'evercourteous', 'donttake', 'allhis', 'lastminute', 'civvy', 'ohnothing', 'iarrived', 'friendsand', 'allshot']\n"
     ]
    }
   ],
   "source": [
    "for word in bad_words:\n",
    "    errors_split.append(word)\n",
    "print(errors_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "65371496-ddd5-4dc9-b53e-54a08b580303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overath Laval 1e with-a it'srather Silvers's Farraday'scircle Barnet's Clements's newt-mating Lewis's don'ttake I'mvery self-training well-contented ever-courteous don'ttake last-minute Ritz Redding self-vident sleights-of-hand be-that that'sall d-h Symons\n"
     ]
    }
   ],
   "source": [
    "print(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff9a19-380e-4acc-9650-a975353dca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_split = ['istrue', 'canbe', 'im', 'tj1e', 'overath', 'laval', 'itsrather', 'wer', 'silverss', 'gotto', 'thelikes', 'ifi', '0f', 'prise', 'ritz', 'ofthe', 'andthe', 'lto', 'lookingback', 'al1', 'verypleased', 'het', 'thevery', 'agre', 'bethat', 'seehe', 'ot', 'selfvident', 'sleightsofhand', 'cansee', 'thatsall', 'distinguishedand', 'villagesir', 'docrucially', 'arec', 'farradayscircle', 'witha', 'canonly', 'barnets', 'redding', 'tosit', 'clementss', 'newtmating', 'ill1terest', 'anysuch', 'dh', 'lewiss', 'donttake', 'allhis', 'contemplatin8', 'startseeing', 'symons', 'owardst', 'imvery', 'simplyaccepting', 'selftraining', 'wellcontented', 'evercourteous', 'donttake', 'allhis', 'lastminute', 'civvy', 'ohnothing', 'iarrived', 'friendsand', 'allshot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f858ade-6194-4520-9ae3-a0230103701e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ohnothing not found\n",
      "iarrived not found\n",
      "to.\"  \"You don't understand, Stevens. Well, we're friendsand so I'll put it to you frankly. Over the\n",
      "allshot not found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for bad_word in bad_words:\n",
    "    ind = text.find(bad_word)\n",
    "    if ind == -1:\n",
    "        print(f\"{bad_word} not found\")\n",
    "    else:\n",
    "        window = text[ind-50:ind+50]\n",
    "        window = window.replace(\"\\n\", \" \")\n",
    "        window = window.replace(\"\\t\", \" \")\n",
    "        print(window)\n",
    "    #test_result = (Word(test_word).spellcheck())\n",
    "    #print(test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16a541d2-64e9-4cdf-8cfc-c1a076ff7520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of 'ell' is: 61381\n",
      "your help on a certain matter weve been debating t ell me do you suppose the debt situation regarding america\n",
      "The index of 'ting' is: 34786\n",
      "apron the room was dominated by the smell of roas ting dr meredith rose and said my condolences stevens he\n"
     ]
    }
   ],
   "source": [
    "test_words = text.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
    "bad_words=[\"ohnothing\", \"iarrived\", \"friendsand\", \"allshot\"]\n",
    "bad_words = [\"ell\", \"ting\"]\n",
    "for bad_word in bad_words:\n",
    "    try:\n",
    "        ind = test_words.index(bad_word)\n",
    "        print(f\"The index of '{bad_word}' is: {ind}\")\n",
    "        print(' '.join(test_words[ind - 10:ind + 10]))\n",
    "    except ValueError:\n",
    "        print(f\"'{item_to_find}' not found in the list.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39b0c707-02c7-4573-b08d-bba3262278ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "farsighted undeniable rapping celebratory topnotch contexts vouch residency overawed breakages professionalized vowel illuminates bolting impractical nostalgic judgements replenishing snobbish unprepared poplar remotely teapots equanimity unforgettable nuance fulcrum positioned aforementioned idealism ripple scholarly whats hogwash chump flimsy signpost pandemonium unburden starkness dependable duplicitous surreptitious finery tablecloth pleasantries bereavement thawed misspelt wallpaper eased leaven diners advertises indisputable wended awesome gent chillier endlessly daunting imaginable tensions hmm camaraderie indelible nonsensical fracas stoked drunks seeping bungling throwaway humbling overtired disruptive generational platter grandchild sightseeing pessimistic hedgerows endearing complicit mans vendetta fluke largeness confusions demonstrativeness staffing breakfasted carryon infuriatingly pecking pastries outmoded relented woken alarmist focusing encyclopedias frogmarched silvers shes discernment spotting stepladder encroaching poplars eyeing footbridge motored ell desks mantelshelf diner broth smallness neglectful heretical dedication oversee respectfulness resonated unimaginable explicate flaked surpass vintage impersonations whiling objectively perfected missus critically sulkily seagulls usefully furthering mistreat debating idealistic banqueting unambiguously imputing steeple irrelevance skills compounded applauded emptily rota brewed farmland convivial specializing pronouncements sympathizes unswerving enthuse timer laundry mystique pervading figuratively fifties obscuring accusingly cradled reentered avoidable bereft pronouncement motoring gesturing driveways pantomime nostalgia scheduled aspire columnist titled solemnness ked bulrushes hankie deteriorates amateurism fascists badman briefcase ting chockfull manipulating consorted adjoin bookshelf spelt retrace acquaintanceship ignition trends analyses achieving monocle afflicting drunker sullied terming backbone inappropriateness prerequisite dependability drizzle tiring underestimating preoccupying attributable sloped breathtaking mystified cockerel nil mindless waterfalls hedgerow swings chauffeur steadied bothered digressing preoccupy knowhow bartender sunlit ludicrously kernel hes priorities aunts pointless teapot cornerstone farfetched besetting reminisce toasted unhurried underwent intransigent obsessions untidily promenading disembark chefs alarmingly teas dammit excellently butlers mops subterfuge floorboards rhododendron broach impromptu putout defeatist intuitively hates hardworking speculate shamed fop radiator woefully facets documented perusing cower greyed unsettling modicum confessing discreetly bemoan assigning unsure dispelling thickets disembarkation propensity electrification alcove sensed weightier racy tragically tiredly hub eulogizing ensconced ensured larder reminiscing glimpsed failings downpour noises spoilt abating bygone driveway discomforting humanly professionalism biased geezer investigating posh chambermaids liaising puzzles heres promontory cruelties recollecting conciseness antisemitism verged surfaced bypass icings trickster spencer summerhouse teen gestured pertinent canyons trays bemused guv presumed begs balconies weakest mediocre cue downs embarking repercussions cant mannered minstrel bestowing ludicrousness attentiveness eulogized deterioration valeting switching jackpot needlework grumbles flagstones accommodating witnessing highwayman farmyard ploy workloads climbs remuneration bakery bareness defensively soapbox moorland vexes trespassing contemplating tidily polishing earful broadminded culpable evocative exaggerating niggle outnumbering playwright foulest harshest\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(blob_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f62b8c3c-6402-404f-8e3a-267bacf42033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n"
     ]
    }
   ],
   "source": [
    "both = spell_set & blob_set\n",
    "print(len(both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "de333e45-7126-47bb-9447-b42f1ece6de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valetbutler twentyeight wellregarded midmorning chalmers wellwritten istrue benn tj1e wellbuilt theyve muggeridge manoeuvred ploughmans bridewood hardbacked inflexions blair bridgeposts canbe thats youre midconversation ribbentrop oakpanelled oswald shant infact unrevealing farradays fortynine exeter itsrather maynard manoeuvring compton overath wer theres dinnerwaiting laval avery underservants salisbury peptalks beyondsuch brigoon jewry itll militarystyle forwardlooking bentley reggie thirtythree longdistance hardacres ruhr davids rayne middleaged silverss dustsheeted silverpolishing everpresent blackshirts humphreys bremann hasnt saltman halflight aint attachã© dustsheetings faroff notseek wakefield firstclass trevor im savour helston fulltime twentythree womans thirtyfive latters selfevident davidson weve gotto mosley highflown manservants darkslated chinamen hitlers thelikes streethawkers 0f ifi thornton goodsized wetherby keynes civvy hed taylors carolyn kenton whitehaired selfrespect lto lookingback wakeling ofthe andthe prise ritz wellloved rolands wellknown verypleased ladiesinwaiting harrys wakefields ribbentrops enamoured al1 olympic wideranging thatll het thevery agre fiftyfour chinaman illtreated secondfloor wasnt whod likeminded seehe wellmeaning nuremberg kentons halfmile bethat analysed bellylaugh camberley ivycovered ot twelvebores selfvident roundbacked evervisible neardarkness cansee theyll eleanor ladyfriend sleightsofhand reginalds loc lowhanging tavistock ive mursden didnt groundfloor giffen pleasureseekers ican ladys nearempty morgans ketteridge thatsall benns distinguishedand firstfloor villagesir couldnt thatchroofed barnets isnt courtmartialling youve karlheinz docrucially arec timberfronted farradayscircle witha canonly redding tosit pres underbutler seventytwo carlisles clementss underbutlers newtmating midthirties floutings youd branbury ill1terest arent breadknives midsentence leant anysuch loughborough darkjacketed armoury chaiselongue dh illmatching midfifties celts oldfashioned selfevidently frau evergrowing lewiss annexe carttrack saltash evercourteous donttake allhis rhineland lastminute contemplatin8 semitism natureloverstevens mauvis selfconscious whos herman neverending thirtyfour mosleys nellie dorchester rooftiles symonss youll clements falconing crosby chainbers nazis imvery owardst simplyaccepting goodhumouredness selftraining charleville wellcontented stanbury taunton highcalibre roas brigid bathchair startseeing symons\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(word for word in both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "79f25e8a-925c-417d-a81f-bd1ca37c6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_errors = \"istrue canbe im tj1e overath laval itsrather wer silverss gotto thelikes ifi 0f prise ritz ofthe andthe lto lookingback al1 verypleased het thevery agre bethat seehe ot selfvident sleightsofhand cansee thatsall distinguishedand villagesir docrucially arec farradayscircle witha canonly barnets redding tosit clementss newtmating ill1terest anysuch dh lewiss donttake allhis contemplatin8 startseeing symons owardst imvery simplyaccepting selftraining wellcontented evercourteous donttake allhis lastminute civvy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "61b9ea58-49af-4e8f-9be7-779830d8eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_errors_split = set(original_errors.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a546bee2-8dbc-4329-b1bb-892c2e7bc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "missed = {word for word in original_errors_split if word not in errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9c805622-08b7-4460-ba37-84e56269439b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('clementss', True), ('laval', True), ('silverss', True), ('wellcontented', False), ('newtmating', False), ('distinguishedand', True), ('lewiss', True), ('bethat', False), ('overath', True), ('symons', True), ('ritz', True), ('witha', False), ('lastminute', False), ('barnets', True), ('im', True), ('selftraining', False), ('redding', True), ('sleightsofhand', False), ('selfvident', False), ('evercourteous', False), ('civvy', True)]\n"
     ]
    }
   ],
   "source": [
    "print ([(word, word in blob_set_3) for word in missed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8aab8b65-c34e-4b31-9649-038e934bfe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('clementss', True), ('laval', True), ('silverss', True), ('wellcontented', False), ('newtmating', False), ('distinguishedand', True), ('lewiss', True), ('bethat', False), ('overath', True), ('symons', True), ('ritz', True), ('witha', False), ('lastminute', False), ('barnets', True), ('im', True), ('selftraining', False), ('redding', True), ('sleightsofhand', False), ('selfvident', False), ('evercourteous', False), ('civvy', True)]\n"
     ]
    }
   ],
   "source": [
    "print ([(word, word in both_3) for word in missed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dd97c339-224d-428e-a557-ec3b9d6be1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('clementss', True), ('laval', True), ('silverss', True), ('wellcontented', False), ('newtmating', False), ('distinguishedand', True), ('lewiss', True), ('bethat', False), ('overath', True), ('symons', True), ('ritz', True), ('witha', False), ('lastminute', False), ('barnets', True), ('im', True), ('selftraining', False), ('redding', True), ('sleightsofhand', False), ('selfvident', False), ('evercourteous', False), ('civvy', True)]\n"
     ]
    }
   ],
   "source": [
    "print ([(word, word in spell_set_3) for word in missed])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "836ab175-8e0c-45ad-9513-1d67321fe30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tj1e\n",
      "distinguishedand\n",
      "villagesir\n"
     ]
    }
   ],
   "source": [
    "for word in errors_split:\n",
    "    if word not in text:\n",
    "        if word not in cleaned_suggestions:\n",
    "            print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7bcdea9a-50b8-49a3-846a-597e6c2e4800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In spell set 1\n",
      "In blob set 1\n",
      "businessmen or the newly rich as [distinguishedand] in my opinion this piece of\n",
      "In spell set 2\n",
      "In blob  set 2\n",
      "businessmen or the newly rich as [distinguishedand] in my opinion this piece of\n",
      "In spell set 3\n",
      "In blob set 3\n",
      "businessmen or the newly rich as [distinguishedand] in my opinion this piece of\n"
     ]
    }
   ],
   "source": [
    "where_is(\"distinguishedand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "57fbc744-436d-42d4-af84-d7197cadbb92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blob_only' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m([word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m blob_set_3 \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m blob_only])\n",
      "Cell \u001b[1;32mIn[110], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m([word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m blob_set_3 \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mblob_only\u001b[49m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'blob_only' is not defined"
     ]
    }
   ],
   "source": [
    "print([word for word in blob_set_3 if word not in blob_only])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c655e006-5bfb-4dbf-808d-141d92766b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions = \"Overath Laval 1e with-a it'srather Silvers's Farraday'scircle Barnet's Clements's newt-mating Lewis's don'ttake I'mvery self-training well-contented ever-courteous don'ttake last-minute Ritz Redding self-vident sleights-of-hand be-that that'sall d-h Symons\"\n",
    "cleaned_suggestions = suggestions.translate(str.maketrans('', '', string.punctuation)).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bb8efe08-4c67-4fc7-9d9f-b34d928f9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in suggestions.split(' '):\n",
    "    if word not in text:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e8498acb-31a9-4857-b72c-f83224304ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in errors_split:\n",
    "    if word not in cleaned_suggestions:`\n",
    "        if word not in test_words:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0946ef07-9113-43ca-8aaf-d9a743a9b3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" prise \" in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce07e4-5c13-4648-8f81-b3401fc9beb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
