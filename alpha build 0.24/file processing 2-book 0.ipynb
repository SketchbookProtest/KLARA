{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1726f6c5-0b63-4184-ab57-21fad4577fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza, re, benepar, psutil, gc, json, csv, time, string, os\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from textstat import textstat\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_infix_regex\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import Tree\n",
    "from textblob import Word\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import LogLocator, LogFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ee7f15-f969-4fe0-83d2-6584568b66b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memcheck():\n",
    "    gc.collect()\n",
    "    memory_info = psutil.virtual_memory()\n",
    "\n",
    "    # Display the memory information in GB\n",
    "    total_memory = memory_info.total / (1024 ** 3)\n",
    "    available_memory = memory_info.available / (1024 ** 3)\n",
    "    used_memory = memory_info.used / (1024 ** 3)\n",
    "\n",
    "    print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "    print(f\"Available Memory: {available_memory:.2f} GB\")\n",
    "    print(f\"Used Memory: {used_memory:.2f} GB\")\n",
    "\n",
    "def time_taken(start_time, end_time):\n",
    "    time_taken = end_time - start_time\n",
    "    hours, remainder = divmod(time_taken.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f\"Time Taken: {hours} hours, {minutes} minutes, {seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3679f96e-a99d-4162-b101-a74ea76f2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_text_in_context(text, words, window = 75):\n",
    "#Finds the first occurrence of each word in target text and displays it\n",
    "    \n",
    "    for word in words:\n",
    "        ind = text.find(word)\n",
    "        if ind == -1:\n",
    "            print (f\"{word} not found in text\")\n",
    "        else:\n",
    "            display_text = text[ind-window:ind+window+1]\n",
    "            display_text = display_text.replace(\"\\n\", \" \")\n",
    "            display_text = display_text.replace(\"\\t\", \" \")\n",
    "            display_text = display_text.replace(\"  \", \" \")\n",
    "            print(display_text)\n",
    "\n",
    "def display_words_in_context(text_words, words, repeat = False, window = 2):\n",
    "# Finds the first occurrence of each word in target list of words. Optionally finds every subsequent occurrence     \n",
    "    if not repeat:\n",
    "        for word in words:\n",
    "            try:\n",
    "                #print(\"trying \", word)\n",
    "                index = text_words.index(word)\n",
    "                #print(f\"The index of '{word}' is: {index}\")\n",
    "                display_text = ' '.join(text_words[index - window:index])\n",
    "                display_text = display_text + \" [\" + word + \"] \"\n",
    "                display_text = display_text + ' '.join(text_words[index + 1 : index + window + 1])\n",
    "                print(display_text)\n",
    "            except ValueError:\n",
    "                print(f\"'{word}' not found in the text.\")\n",
    "    else:\n",
    "        for word in words:\n",
    "            indices = [index for index, value in enumerate(text_words) if value == word]\n",
    "            if len(indices) == 0:\n",
    "                print(f\"'{word}' not found in the text.\")\n",
    "            else:\n",
    "                for index in indices:\n",
    "                    display_text = ' '.join(text_words[index - window:index])\n",
    "                    display_text = display_text + \" [\" + word + \"] \"\n",
    "                    display_text = display_text + ' '.join(text_words[index + 1 : index + window + 1])\n",
    "                    print(display_text)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "169f2aaf-8823-4555-86c9-7ea1bcdcc146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def where_is(word):\n",
    "    # finds if spell checker has flagged a word.  Must run spell checker first.\n",
    "    if (word in spell_set_0): \n",
    "        print (\"In spell set 0\")\n",
    "    if (word in blob_set_0):\n",
    "        print (\"In blob set 0\")\n",
    "    if (word in spell_set_0) or (word in blob_set_0):\n",
    "        display_words_in_context(test_words_0, [word], False, 6)\n",
    "    if (word in spell_set_1): \n",
    "        print (\"In spell set 1\")\n",
    "    if (word in blob_set_1):\n",
    "        print (\"In blob set 1\")\n",
    "    if (word in spell_set_1) or (word in blob_set_1):\n",
    "        display_words_in_context(test_words_1, [word], False, 6)\n",
    "    if (word in spell_set_2): \n",
    "        print (\"In spell set 2\")\n",
    "    if (word in blob_set_2):\n",
    "        print (\"In blob  set 2\")\n",
    "    if (word in spell_set_2) or (word in blob_set_2):\n",
    "        display_words_in_context(test_words_2, [word], False, 6)\n",
    "    if (word in spell_set_3): \n",
    "        print (\"In spell set 3\")\n",
    "    if (word in blob_set_3):\n",
    "        print (\"In blob set 3\")\n",
    "    if (word in spell_set_3) or (word in blob_set_3):\n",
    "        display_words_in_context(test_words_3, [word], False, 6)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29278a47-903b-4cda-9983-e1625d9ce6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hyphenated_words(text):\n",
    "    # Use regex to find words that are hyphenated across lines\n",
    "    # Match sequences where a hyphen is at the end of a line, followed by a newline, and then continued with a word\n",
    "    hyphenated_words = re.findall(r\"(\\w+)-\\n(\\w+)\", text)\n",
    "\n",
    "    for first_part, second_part in hyphenated_words:\n",
    "        print(f\"Found broken word: {first_part}-{second_part}\")\n",
    "    print(f\"{len(hyphenated_words)} hyphenated words found, text length is: {len(text)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db25ec42-fd25-4ccb-8473-aee451fffdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_hyphenated_words(text, show_changes = False):\n",
    "    # This regular expression captures words separated by a hyphen, with letters on both sides.\n",
    "    pattern = r'(\\b\\w+)-(\\w+\\b)'\n",
    "\n",
    "    # Function to handle replacement and printing\n",
    "    def replacement(match):\n",
    "        # Original hyphenated word\n",
    "        original_word = match.group(0)\n",
    "        # Replacement word (with space instead of hyphen)\n",
    "        altered_word = match.group(1) + \" \" + match.group(2)\n",
    "        \n",
    "        # Print the hyphenated word that was altered\n",
    "        if show_changes: print(f\"Altered: {original_word} -> {altered_word}\")\n",
    "\n",
    "        return altered_word\n",
    "\n",
    "    # Replace hyphenated words and call the replacement function\n",
    "    result = re.sub(pattern, replacement, text)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13696b61-ffef-4f5e-ab17-a09304167d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_hyphenated_words_alt(text, silent = True):\n",
    "    # Find words that have a hyphen between them\n",
    "    hyphenated_words = re.findall(r'\\b\\w+-\\w+\\b', text)\n",
    "    counter = 0\n",
    "    # Replace each hyphenated word with a space between words instead of the hyphen\n",
    "    for word in hyphenated_words:\n",
    "        new_word = word.replace('-', ' ')\n",
    "        text = text.replace(word, new_word)\n",
    "        counter += 1\n",
    "        if not silent: print(f\"Replaced '{word}' with '{new_word}'\")\n",
    "    print(counter)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81a11d44-ef56-4efc-86ac-7f0a72db3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_oddities(text):\n",
    "    # Run this after creating oddities, use the text BEFORE hyphens were removed\n",
    "    hyphenated_words = re.findall(r'\\b\\w+-\\w+\\b', text)\n",
    "        \n",
    "    for word in hyphenated_words:\n",
    "        new_word = word.replace('-', ' ')\n",
    "        new_word_split = new_word.split(' ')\n",
    "        #print(word, new_word)\n",
    "        if new_word_split[0] in oddities or new_word_split[1] in oddities:\n",
    "            print (word, new_word)\n",
    "            display_text_in_context(text, [word], window = 40)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5965411e-d962-4c42-855b-73d75866f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an Example Text with DOUBLE SPACES.\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text, make_lower = True):\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Convert to lowercase\n",
    "    if make_lower:\n",
    "        text = text.lower()\n",
    "    # Strip any leading or trailing spaces\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "tt = \"This  is   an Example  Text with    DOUBLE  SPACES.\"\n",
    "cleaned_text = clean_text(tt, False)\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d37bee5d-a418-4f70-b285-0f1f16bda66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice bum', 'age': '30 years', 'city': 'New York duds'}\n"
     ]
    }
   ],
   "source": [
    "def list_to_dict(alternating_list):\n",
    "    # Use dictionary comprehension with list slicing to group pairs\n",
    "    return {alternating_list[i]: alternating_list[i+1]+ \" \" + alternating_list[i+2] for i in range(0, len(alternating_list), 3)}\n",
    "\n",
    "# Example usage\n",
    "alternating_list = ['name', 'Alice', 'bum', 'age', '30', 'years', 'city', 'New York', 'duds']\n",
    "dictionary = list_to_dict(alternating_list)\n",
    "print(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92cf6efe-a206-42c1-9967-9f885df962b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find and replace specified strings in a text\n",
    "def replace_strings_with_context(text, replacements, window=10, silent = False):\n",
    "    \"\"\"\n",
    "    Replaces specified strings within a text and prints the context around each replacement.\n",
    "    \n",
    "    Parameters:\n",
    "    - text: The original string where replacements are done.\n",
    "    - replacements: A dictionary where keys are the substrings to find, and values are their replacements.\n",
    "    - window: Number of characters to show before and after the replaced string for context.\n",
    "    \n",
    "    Returns:\n",
    "    - A modified string with the replacements applied.\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    for old, new in replacements.items():\n",
    "        index = text.find(old)\n",
    "        while index != -1:\n",
    "            # Extract context around the found string\n",
    "            start = max(index - window, 0)\n",
    "            end = min(index + len(old) + window, len(text))\n",
    "            before = text[start:index]\n",
    "            after = text[index + len(old):end]\n",
    "            before = before.replace(\"\\n\", \" \")\n",
    "            before = before.replace(\"\\t\", \" \")\n",
    "            after = after.replace(\"\\n\", \" \")\n",
    "            after = after.replace(\"\\t\", \" \")\n",
    "\n",
    "            # Print before, replaced, and after strings\n",
    "            if not silent:\n",
    "                print(f\"Before: {before}[{old}]{after}\")\n",
    "                print(f\"After:  {before}[{new}]{after}\\n\")\n",
    "\n",
    "            # Replace the string in the text\n",
    "            text = text[:index] + new + text[index + len(old):]\n",
    "            counter += 1\n",
    "            \n",
    "            # Find the next occurrence of the old string\n",
    "            index = text.find(old, index + len(new))\n",
    "\n",
    "    print(f\"made {counter} changes\")\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50579c19-2c46-4d18-aa7c-10daefa8ef78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856f4cb-87fc-4706-a057-4cc6a718824e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b24cd98d-fecd-47ae-934f-11ab9a1d0ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Roland/Documents/AI/stylometry/Kazuo Ishiguro - The Remains of the Day.txt\n"
     ]
    }
   ],
   "source": [
    "source_texts= list()\n",
    "source_texts.append(\"Kazuo Ishiguro - Never Let Me Go\")\n",
    "source_texts.append(\"Kazuo Ishiguro - The Remains of the Day\")\n",
    "source_texts.append(\"Kazuo Ishiguro - A Pale View of Hills-Knopf Doubleday Publishing Group (1990)\")\n",
    "source_texts.append(\"Kazuo-Ishiguro-When-We-Were-Orphans-Alfred-A.-Knopf_Vintage-_2001_\")\n",
    "source_texts.append(\"The Buried Giant (Kazuo Ishiguro) (Z-Library)-1\")\n",
    "source_texts.append(\"Kazuo Ishiguro - The Unconsoled-Vintage (1996)\")\n",
    "directory_path = \"C:/Users/Roland/Documents/AI/stylometry/\"\n",
    "file_path = directory_path+source_texts[1]+\".txt\"\n",
    "print (file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51fa129b-3e6e-4e91-9156-dfd21c74b804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n",
      "[\"aren't\", 'are', 'not', \"can't\", 'can', 'not', \"couldn't\", 'could', 'not', \"didn't\", 'did', 'not', \"doesn't\", 'does', 'not', \"don't\", 'do', 'not', \"hadn't\", 'had', 'not', \"hasn't\", 'has', 'not', \"haven't\", 'have', 'not', \"isn't\", 'is', 'not', \"mightn't\", 'might', 'not', \"mustn't\", 'must', 'not', \"needn't\", 'need', 'not', \"shan't\", 'shall', 'not', \"shouldn't\", 'should', 'not', \"wasn't\", 'was', 'not', \"weren't\", 'were', 'not', \"won't\", 'will', 'not', \"wouldn't\", 'would', 'not', \"i'd\", 'i', 'would', \"you'd\", 'you', 'would', \"he'd\", 'he', 'would', \"she'd\", 'she', 'would', \"it'd\", 'it', 'would', \"we'd\", 'we', 'would', \"they'd\", 'they', 'would', \"who'd\", 'who', 'would', \"there'd\", 'there', 'would', \"that'd\", 'that', 'would', \"i'll\", 'i', 'will', \"you'll\", 'you', 'will', \"he'll\", 'he', 'will', \"she'll\", 'she', 'will', \"it'll\", 'it', 'will', \"we'll\", 'we', 'will', \"they'll\", 'they', 'will', \"who'll\", 'who', 'will', \"that'll\", 'that', 'will', \"what'll\", 'what', 'will', \"i've\", 'i', 'have', \"you've\", 'you', 'have', \"he's\", 'he', 'has', \"she's\", 'she', 'has', \"we've\", 'we', 'have', \"they've\", 'they', 'have', \"who's\", 'who', 'has', \"who've\", 'who', 'have', \"i'm\", 'i', 'am', \"you're\", 'you', 'are', \"he's\", 'he', 'is', \"she's\", 'she', 'is', \"it's\", 'it', 'is', \"we're\", 'we', 'are', \"they're\", 'they', 'are', \"who's\", 'who', 'is', \"there's\", 'there', 'is', \"there're\", 'there', 'are', \"that's\", 'that', 'is', \"Aren't\", 'Are', 'not', \"Can't\", 'Can', 'not', \"Couldn't\", 'Could', 'not', \"Didn't\", 'Did', 'not', \"Doesn't\", 'Does', 'not', \"Don't\", 'Do', 'not', \"Hadn't\", 'Had', 'not', \"Hasn't\", 'Has', 'not', \"Haven't\", 'Have', 'not', \"Isn't\", 'Is', 'not', \"Mightn't\", 'Might', 'not', \"Mustn't\", 'Must', 'not', \"Needn't\", 'Need', 'not', \"Shan't\", 'Shall', 'not', \"Shouldn't\", 'Should', 'not', \"Wasn't\", 'was', 'not', \"Weren't\", 'Were', 'not', \"Won't\", 'Will', 'not', \"Wouldn't\", 'Would', 'not', \"I'd\", 'I', 'would', \"You'd\", 'You', 'would', \"He'd\", 'He', 'would', \"She'd\", 'She', 'would', \"It'd\", 'It', 'would', \"We'd\", 'We', 'would', \"They'd\", 'They', 'would', \"Who'd\", 'Who', 'would', \"There'd\", 'There', 'would', \"That'd\", 'That', 'would', \"I'll\", 'I', 'will', \"You'll\", 'You', 'will', \"He'll\", 'He', 'will', \"She'll\", 'She', 'will', \"It'll\", 'It', 'will', \"We'll\", 'We', 'will', \"They'll\", 'They', 'will', \"Who'll\", 'Who', 'will', \"That'll\", 'That', 'will', \"What'll\", 'What', 'will', \"I've\", 'I', 'have', \"You've\", 'You', 'have', \"He's\", 'He', 'has', \"She's\", 'She', 'has', \"We've\", 'We', 'have', \"They've\", 'They', 'have', \"Who's\", 'Who', 'has', \"Who've\", 'Who', 'have', \"I'm\", 'I', 'am', \"You're\", 'You', 'are', \"He's\", 'He', 'is', \"She's\", 'She', 'is', \"It's\", 'It', 'is', \"We're\", 'We', 'are', \"They're\", 'They', 'are', \"Who's\", 'Who', 'is', \"There's\", 'There', 'is', \"There're\", 'There', 'are', \"That's\", 'That', 'is']\n"
     ]
    }
   ],
   "source": [
    "contractions = \"Aren't\tAre not Can't\tCan not Couldn't\tCould not Didn't\tDid not Doesn't\tDoes not Don't\tDo not Hadn't\tHad not Hasn't\tHas not Haven't\tHave not Isn't\tIs not Mightn't\tMight not Mustn't\tMust not Needn't\tNeed not Shan't\tShall not Shouldn't\tShould not Wasn't was not Weren't\tWere not Won't\tWill not Wouldn't\tWould not\"\n",
    "contractions = contractions + \" I'd\tI would You'd\tYou would He'd\tHe would She'd\tShe would It'd\tIt would We'd\tWe would They'd\tThey would Who'd\tWho would There'd There would That'd That would\" \n",
    "contractions = contractions + \" I'll\tI will You'll\tYou will He'll\tHe will She'll\tShe will It'll\tIt will We'll\tWe will They'll\tThey will Who'll\tWho will That'll That will What'll What will\"\n",
    "contractions = contractions + \" I've\tI have You've\tYou have He's\tHe has She's\tShe has We've\tWe have They've\tThey have Who's\tWho has Who've Who have\"\n",
    "contractions = contractions + \" I'm\tI am You're\tYou are He's\tHe is She's\tShe is It's\tIt is We're\tWe are They're\tThey are Who's\tWho is There's There is There're There are That's That is\"\n",
    "contractions = clean_text(contractions, True) + \" \" + clean_text(contractions, False)\n",
    "contractions = contractions.split(' ')\n",
    "print(len(contractions))\n",
    "print(contractions)\n",
    "contractions = list_to_dict(contractions)\n",
    "contractions[\"can't\"] = \"cannot\"\n",
    "contractions[\"Can't\"] = \"Cannot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54491884-5fbf-4bd9-be7e-d96b0d983432",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in contractions.items():\n",
    "    if \" \" in key or value[0] == \" \" or value[-1] == \" \": print(key, \": \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0b70941-aa90-4c56-a8e1-d9f1dde577c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file not found at  C:/Users/Roland/Documents/AI/stylometry/Kazuo Ishiguro - Never Let Me Go edited_2.txt\n",
      "file found at  C:/Users/Roland/Documents/AI/stylometry/Kazuo Ishiguro - Never Let Me Go edited_1.txt\n"
     ]
    }
   ],
   "source": [
    "text_choice = 0\n",
    "\n",
    "\n",
    "file_path = directory_path+source_texts[text_choice]+\" edited_2.txt\"\n",
    "if os.path.isfile(file_path):\n",
    "    print (\"file found at \", file_path)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "else:\n",
    "    print(\"file not found at \", file_path)\n",
    "    file_path = directory_path+source_texts[text_choice]+\" edited_1.txt\"\n",
    "    if os.path.isfile(file_path):\n",
    "        print (\"file found at \", file_path)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "    else:\n",
    "        print(\"file not found at \", file_path)\n",
    "        file_path = directory_path+source_texts[text_choice]+\" edited.txt\"\n",
    "        if os.path.isfile(file_path):\n",
    "            print (\"file found at \", file_path)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "        else:\n",
    "            print(\"file not found at \", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3be5dd1-b1c4-484d-a3f9-75d0dcd7b937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514835\n",
      "made 3516 changes\n",
      "521967\n"
     ]
    }
   ],
   "source": [
    "print (len(text))\n",
    "text_1 = replace_strings_with_context(text, contractions, window=10, silent = True)\n",
    "print(len(text_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "973d797f-474a-4f01-861b-2089918fa692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545\n"
     ]
    }
   ],
   "source": [
    "unhyphenated_alt = replace_hyphenated_words_alt(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "865e6cc2-e337-46a9-a4de-df1665fc9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words_0 = text_1.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "test_words_1 = text_1.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
    "unhyphenated = replace_hyphenated_words(text_1)\n",
    "test_words_2 = unhyphenated.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "test_words_3 = unhyphenated.translate(str.maketrans('', '', string.punctuation)).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0c8ad72-9191-4388-ac0d-dd6f75b540ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing at: 03:18:12\n",
      "Completed processing at: 03:40:34\n",
      "Time Taken: 0 hours, 22 minutes, 21 seconds\n",
      "1526 1290 1097 860\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(f\"Starting processing at: {start_time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "# Find invalid words\n",
    "blob_set_0 = set()\n",
    "for word in test_words_0:\n",
    "    result = Word(word).spellcheck()\n",
    "    if result[0][1] < 1.0 or result[0][0] != word:\n",
    "        blob_set_0.add(word)\n",
    "\n",
    "blob_set_1 = set()\n",
    "for word in test_words_1:\n",
    "    result = Word(word).spellcheck()\n",
    "    if result[0][1] < 1.0 or result[0][0] != word:\n",
    "        blob_set_1.add(word)\n",
    "\n",
    "blob_set_2 = set()\n",
    "for word in test_words_2:\n",
    "    result = Word(word).spellcheck()\n",
    "    if result[0][1] < 1.0 or result[0][0] != word:\n",
    "        blob_set_2.add(word)\n",
    "\n",
    "blob_set_3 = set()\n",
    "for word in test_words_3:\n",
    "    result = Word(word).spellcheck()\n",
    "    if result[0][1] < 1.0 or result[0][0] != word:\n",
    "        blob_set_3.add(word)\n",
    "        \n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f\"Completed processing at: {end_time.strftime('%H:%M:%S')}\")\n",
    "time_taken(start_time, end_time)\n",
    "\n",
    "print(len(blob_set_0), len(blob_set_1), len(blob_set_2), len(blob_set_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3edcc35e-e56c-4f2a-adb2-94b52de56b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors found in base text: 1526\n",
      "errors found with case lowered: 1290\n",
      "errors found with hyphens removed:  1097\n",
      "errors found with hyphens removed and case lowered: 860\n",
      "errors eliminated by removing hyphens:  471 or in lower case: 470\n",
      "errors introduced by removing hyphens:  42 or in lower case: 40\n",
      "errors eliminated by lowering case:  414 or without hyphens: 365\n",
      "errors introduced by lowering case:  178 or without hyphens: 128\n"
     ]
    }
   ],
   "source": [
    "print(f\"errors found in base text: {len(blob_set_0)}\")\n",
    "print(f\"errors found with case lowered: {len(blob_set_1)}\")\n",
    "print(f\"errors found with hyphens removed:  {len(blob_set_2)}\")     \n",
    "print(f\"errors found with hyphens removed and case lowered: {len(blob_set_3)}\")     \n",
    "print(f\"errors eliminated by removing hyphens:  {len(blob_set_0 - blob_set_2)} or in lower case: {len(blob_set_1 - blob_set_3)}\")\n",
    "print(f\"errors introduced by removing hyphens:  {len(blob_set_2 - blob_set_0)} or in lower case: {len(blob_set_3 - blob_set_1)}\")\n",
    "print(f\"errors eliminated by lowering case:  {len(blob_set_0 - blob_set_1)} or without hyphens: {len(blob_set_2 - blob_set_3)}\")\n",
    "print(f\"errors introduced by lowering case:  {len(blob_set_1 - blob_set_0)} or without hyphens: {len(blob_set_3 - blob_set_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c693f83-ba9e-49ed-9111-09327c773843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ex LP Matilda Open abrac assortment bashedup bric castors clones consciousmaybe cumsale dah forksstuff frogging glassed heartedly hike hitch inthe mini misted nighter nighters offs onthe ordinator pom punching scaled seater shapeI sogreat storey tenniswas theshoulder timehad tohearts tracked tête yearold àtête\n"
     ]
    }
   ],
   "source": [
    "oddities = sorted(list(blob_set_2-blob_set_0))\n",
    "print(' '.join(oddities))\n",
    "#display_words_in_context(test_words_2, oddities, window = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c07d8cf-0b65-4ca0-acaf-51d07b9dd07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "half-heartedly half heartedly\n",
      " some kind of joke, because she laughed half-heartedly, then made some quip of he\n",
      "\n",
      "\n",
      "Ex-changes Ex changes\n",
      " \"But sometimes, when I think about the Ex-changes now, a lot of it seems a bit o\n",
      "\n",
      "\n",
      "Matilda-as Matilda as\n",
      "I chatted with my friend-I think it was Matilda-as cheerfully as possible, and ha\n",
      "\n",
      "\n",
      "leap-frogging leap frogging\n",
      " watching the knight-rather than in the leap-frogging way of draughts. I did not \n",
      "\n",
      "\n",
      "pom-pom pom pom\n",
      "The zip across the top edge had a furry pom-pom to pull it. I would almost sat on\n",
      "\n",
      "\n",
      "LP-the LP the\n",
      "gewater. I suppose it was originally an LP-the recording date's 1956-but what I h\n",
      "\n",
      "\n",
      "scaled-down scaled down\n",
      "cover picture was what must have been a scaled-down version of the record sleeve.\n",
      "\n",
      "\n",
      "dah-dah dah dah\n",
      " of my voice, and I may even have gone \"dah-dah!\" as I brought it out and handed \n",
      "\n",
      "\n",
      "show-offs show offs\n",
      "ected as a couple because they were not show-offs. Some others, Sylvia B. and Rog\n",
      "\n",
      "\n",
      "one-nighter one nighter\n",
      "with you; other times it was just for a one-nighter. The atmosphere, like I say,\n",
      "\n",
      "\n",
      "assortment-old assortment old\n",
      "ere not even blankets, but a really odd assortment-old curtains, even bits of car\n",
      "\n",
      "\n",
      "one-nighters one nighters\n",
      "Anyway, the point is, I would had a few one-nighters shortly after getting to the\n",
      "\n",
      "\n",
      "one-nighters one nighters\n",
      "Anyway, the point is, I would had a few one-nighters shortly after getting to the\n",
      "\n",
      "\n",
      "one-nighters one nighters\n",
      "Anyway, the point is, I would had a few one-nighters shortly after getting to the\n",
      "\n",
      "\n",
      "misted-up misted up\n",
      "ember one morning watching, through the misted-up windows of our kitchen, two vet\n",
      "\n",
      "\n",
      "castors-and castors and\n",
      "ment, the chairs with their swivels and castors-and it was so vivid everyone let \n",
      "\n",
      "\n",
      "mini-golf mini golf\n",
      "d left the Rover in a car park beside a mini-golf course full of fluttering flags\n",
      "\n",
      "\n",
      "side-tracked side tracked\n",
      "d to me she did not want the expedition side-tracked and was reluctantly siding w\n",
      "\n",
      "\n",
      "tête-à tête à\n",
      "r at the end of it, having some sort of tête-à-tête. I was not sure what to do: I\n",
      "\n",
      "\n",
      "hitch-hike hitch hike\n",
      "said to me. \"Otherwise you will have to hitch-hike.\" Then he did a laugh. \"Come o\n",
      "\n",
      "\n",
      "bric-a bric a\n",
      "in, maybe competing for the same box of bric-a-brac in a dusty corner lit up by a\n",
      "\n",
      "\n",
      "mini-golf mini golf\n",
      "d left the Rover in a car park beside a mini-golf course full of fluttering flags\n",
      "\n",
      "\n",
      "two-seater two seater\n",
      " dragged into the middle of the floor a two-seater settee with stuffing poking ou\n",
      "\n",
      "\n",
      "scaled-down scaled down\n",
      "cover picture was what must have been a scaled-down version of the record sleeve.\n",
      "\n",
      "\n",
      "punching-on punching on\n",
      "ow of being a couple-they still did the punching-on-the-arm thing when they parte\n",
      "\n",
      "\n",
      "glassed-in glassed in\n",
      "the frame of what must have once been a glassed-in notice displaying all the bus \n",
      "\n",
      "\n",
      "two-storey two storey\n",
      "photo, except for the white bunker-like two-storey buildings in the background, o\n",
      "\n",
      "\n",
      "Open-plan Open plan\n",
      "id after a moment. \"But it reminded me. Open-plan office, smart smiling people.\" \n",
      "\n",
      "\n",
      "co-ordinator co ordinator\n",
      " by then, from the way the doctors, the co-ordinator, the nurses were behaving, t\n",
      "\n",
      "\n",
      "clones-or clones or\n",
      " ordinary human being. Before that, all clones-or students, as we preferred to ca\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_oddities(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d62cea13-8b4e-4666-8ede-a0706b934a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "724 721 310 308\n"
     ]
    }
   ],
   "source": [
    "# Use spellchecker to validate words\n",
    "# Initialize spell checker\n",
    "spell = SpellChecker()\n",
    "\n",
    "\n",
    "# Find words not in the dictionary\n",
    "spell_set_0 = {word for word in test_words_0 if word not in spell}\n",
    "spell_set_1 = {word for word in test_words_1 if word not in spell}\n",
    "spell_set_2 = {word for word in test_words_2 if word not in spell}\n",
    "spell_set_3 = {word for word in test_words_3 if word not in spell}\n",
    "\n",
    "print(len(spell_set_0), len(spell_set_1), len(spell_set_2), len(spell_set_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2314cbe5-f120-431d-bc0e-ef601f5e43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_3 = spell_set_3 & blob_set_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52d8f88b-67be-4be6-accf-ef4389554cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n"
     ]
    }
   ],
   "source": [
    "print(len(both_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba8f53-49ee-4f56-8719-3a5868b7c5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee446b7-3e9d-43cd-b0f6-7ed4e242c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(' '.join(word for word in both_3))\n",
    "# display_words_in_context(test_words_2, spell_only_2 - spell_only_1, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5d6e9f0-c4c1-4ec3-bc7f-617d8a803e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "['5s', 'abouts', 'abrac', 'alls', 'alost', 'becausethey', 'betweenthem', 'bric', 'canunzip', 'carefulwho', 'consciousmaybe', 'coupleand', 'coupleshinting', 'courseswhich', 'cumsale', 'cwho', 'definitelyhad', 'doi', 'downthey', 'dyou', 'ethe', 'expectthen', 'forksstuff', 'fromme', 'gallerys', 'howshe', 'hs', 'inthe', 'isi', 'itbut', 'itis', 'itshould', 'iwould', 'jeansruth', 'jwho', 'keffers', 'kefferss', 'kshe', 'lps', 'mag', 'moulding', 'neurone', 'onthe', 'possiblesthe', 'reallyfit', 'rway', 'saidhello', 'shapei', 'sogreat', 'sostupid', 'southshe', 'tenniswas', 'thatsnot', 'thatwe', 'theevening', 'thendo', 'therewas', 'theshoulder', 'timehad', 'toomuch', 'typesomething', 'virginmeaning', 'wasshe', 'wewere', 'whatwas', 'whoeverwas', 'youknow', 'àtête']\n"
     ]
    }
   ],
   "source": [
    "#copy and extract the ones that could be real errors, paste them back here\n",
    "errors_raw = \"ethe lps thatsnot coupleshinting shapei youknow timehad isi fromme definitelyhad carefulwho thendo neurone thatwe whoeverwas jwho wewere betweenthem coupleand canunzip wasshe toomuch howshe hs itshould gallerys downthey theshoulder keffers tenniswas becausethey kshe inthe iwould theevening consciousmaybe rway whatwas sogreat virginmeaning jeansruth forksstuff kefferss saidhello sostupid alls dyou onthe therewas moulding alost expectthen abouts cwho reallyfit typesomething possiblesthe àtête abrac courseswhich itis southshe doi bric 5s mag itbut cumsale\"\n",
    "errors_raw = errors_raw.split()\n",
    "errors_raw = sorted(errors_raw)\n",
    "print(len(errors_raw))\n",
    "print (errors_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d57016-1f5a-4d20-9802-ee8a471831ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_spell_1 = 0\n",
    "counter_spell_2 = 0\n",
    "counter_spell_3 = 0\n",
    "counter_blob_1 = 0\n",
    "counter_blob_2 = 0\n",
    "counter_blob_3 = 0\n",
    "counter_both_3 = 0\n",
    "\n",
    "for word in errors_raw:\n",
    "    if word in spell_set_1: counter_spell_1 += 1 \n",
    "    if word in spell_set_2: counter_spell_2 += 1\n",
    "    if word in spell_set_3: counter_spell_3 += 1\n",
    "    else: print(\"not in spell_3: \", word)\n",
    "    if word in blob_set_1: counter_blob_1 += 1\n",
    "    if word in blob_set_2: counter_blob_2 += 1\n",
    "    if word in blob_set_3: counter_blob_3 += 1\n",
    "    else: print(\"not in blob_3: \", word)\n",
    "    if word in both_3: counter_both_3 += 1\n",
    "    else: print(\"not in both_3: \", word)\n",
    "print (counter_spell_1, counter_spell_2, counter_spell_3)\n",
    "print (counter_blob_1, counter_blob_2, counter_blob_3)\n",
    "print(counter_both_3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b4aa277-d8bd-49f5-b316-87dbb578d997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "errors_found = (word for word in errors_raw if (\" \"+ word) in text_1)\n",
    "errors_found = sorted(errors_found)\n",
    "print(len(errors_found))\n",
    "errors_not_found = [word for word in errors_raw if word not in errors_found]\n",
    "print(len(errors_not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef951b73-7f8e-4856-945e-49017d5dfd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "errors_found_1 = (word for word in errors_not_found if word in test_words_1)\n",
    "errors_found_1 = sorted(errors_found_1)\n",
    "print(len(errors_found_1))\n",
    "errors_not_found_1 = [word for word in errors_not_found if word not in errors_found_1]\n",
    "print(len(errors_not_found_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5eefed03-a151-4e35-84a5-066438ebc5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "errors_found_2 = (word for word in errors_not_found_1 if word in test_words_2)\n",
    "errors_found_2 = sorted(errors_found_2)\n",
    "print(len(errors_found_2))\n",
    "errors_not_found_2 = [word for word in errors_not_found_1 if word not in errors_found_2]\n",
    "print(len(errors_not_found_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c54e6ab-1c25-4204-a61d-2ec247912423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5s\n",
      "ons and none of us, not even the Senior 5s, dared make a sound. There was a real\n",
      "becausethey\n",
      "ble about us having sex with each other becausethey would then want to have sex w\n",
      "betweenthem\n",
      " The idea the guardians had differences betweenthem, that never occurred to us.\" \n",
      "bric\n",
      "ut, he put the mags down on top of some bricks stacked outside the boiler hut-som\n",
      "canunzip\n",
      " it is right on the elbow like that, it canunzip. All you have to do is bend your\n",
      "carefulwho\n",
      "y and began telling us how we had to be carefulwho we had sex with. Not just beca\n",
      "coupleshinting\n",
      "of snogging and touching up, maybe; and coupleshinting they were having proper se\n",
      "definitelyhad\n",
      " that two of the girls I was closest to definitelyhad done it. Laura with Rob D.,\n",
      "doi\n",
      "o completing and so that is what he was doing: getting me to describe things to h\n",
      "fromme\n",
      "you do not do it that way! Just take it fromme, you do not do it that way! You de\n",
      "howshe\n",
      "ago. \"None of us stopped to think about howshe felt , Miss Lucy herself. We never\n",
      "itis\n",
      "ardians were not supposed to show favouritism, but there were little displays of \n",
      "itshould\n",
      " old enough,\" Tommy said. \"By that age, itshould have occurred to us. But it did \n",
      "mag\n",
      " was still sitting behind the wheel, rummaging in her briefcase. Eventually she e\n",
      "moulding\n",
      "ou had.\" Ruth had been picking at some moulding flakes of wood on the bench besi\n",
      "neurone\n",
      "friends, did not die from cancer, motor neurone disease, heart disease. So for a \n",
      "reallyfit\n",
      "y: \"But I will be all right, Miss. I am reallyfit, I know how to look after mysel\n",
      "rway\n",
      "rs and loitered just inside the main doorway. We could see out into the bright co\n",
      "saidhello\n",
      "so I did not talk with him long. I just saidhello, that I hoped he would feel bet\n",
      "sostupid\n",
      " I burst out, saying: \"Tommy, you look sostupid, laughing like that! If you want\n",
      "thatwe\n",
      " even though they knew, intellectually, thatwe could not have babies, they still \n",
      "theevening\n",
      "found out first. It was around eight in theevening, I was coming down the main st\n",
      "thendo\n",
      "ou truly wish to share this experience, thendo not!\" But around the spring of the\n",
      "therewas\n",
      "e their faces and their backs. And when therewas a useful scene, it was difficult\n",
      "toomuch\n",
      "e first with a boy I did not care about toomuch. Then later on, if I was with som\n",
      "wasshe\n",
      "ura said that what Annette really meant wasshe wanted to have sex with Mr. Chris.\n",
      "wewere\n",
      "omeone had commandeered all the easels, wewere having to work with our boards pro\n",
      "whatwas\n",
      "in those days, but it was clear by then whatwas a real proposition and what was t\n",
      "whoeverwas\n",
      "ed I was his carer. I looked about, but whoeverwas his carer was not even around.\n",
      "youknow\n",
      " Lucy at all. Not even after that time, youknow, when you saw her.\" I knew strai\n"
     ]
    }
   ],
   "source": [
    "for word in errors_found:\n",
    "    print(word)\n",
    "    display_text_in_context(text_1, [word], window = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed04105a-7a21-4efb-af5c-7d1622d6e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(errors_not_found_2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f42a310-f59c-4958-bade-448cd52686e7",
   "metadata": {},
   "source": [
    "Copy these below and adjust to guess how it would be in the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557a668-694e-4675-b828-f11584e18ee7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527abd3e-b4d9-4ff2-80ee-e2828cb6e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "suggestions = ['alost', 'coupleand', 'cwho', 'itbut', 'Iwould', 'Jeansruth', 'jwho', 'Keffers', 'Kefferss', 'kshed', 'Lauras', 'LPs', 'Metchley', 'Portway', 'shapei', 'virginmeaning', 'Wainright', 'Walkman', 'Walkmans', 'wavecrest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e5c67-6d16-4739-aa28-d1f1b6c043be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(suggestions))\n",
    "suggestions_found = (word for word in suggestions if word in text)\n",
    "suggestions_found = sorted(suggestions_found)\n",
    "print(len(suggestions_found))\n",
    "suggestions_not_found = [word for word in suggestions if word not in suggestions_found]\n",
    "print(len(suggestions_not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724b993a-7fee-4d4b-af9b-900b50500bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(suggestions_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d5566-e830-419e-8505-e53964d369c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22720c25-bb6f-4882-9115-584737dff018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69702a87-b46d-432c-8195-a2d0a2453a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b35bbcd-085f-4e77-a4ec-03437b57a68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb681ce-1a04-40a7-9974-3cb73f317363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffdbcd9-fd40-45fb-9dc5-fab5ba276b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3150d1-1dfe-473e-9324-73614bcdbef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1fe36-5eda-4f7c-935a-74be091c28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = ['0f', 'agre', 'al1', 'allhis', 'andthe', 'anysuch', 'arec', 'avery', 'be-that', 'beyondsuch', 'canbe', 'canonly', 'cansee', 'carryon', 'Chainbers', 'confidentia1', 'contemplatin8', 'Dh', \"'distinguished',and\", 'docrucially', \"don'ttake\", 'T ell', \"Farraday'scircle\", 'friendsand', 'gotto', 'het', 'Iarrived', 'Ican', \"if'-I\", 'ill1terest', \"I'mvery\", 'Infact', 'istrue', 'it,involved', \"it'srather\", 'loc ked', 'lookingback', 'lot,you', 'lover,Stevens', 'lto', 'not-seek', 'ofthe', 'Oh,nothing', 'ot', 'owardst', 'putout', 'roas ting', 'seehe', 'self-vident', 'simplyaccepting', 'startseeing', \"that'sall\", 'thelikes', 'thevery', 'tJ1e', 'tosit', 'verypleased', 'village,sir', 'wer', 'with-a']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849252c9-d58e-47e8-866e-6b76e280fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce82d10c-1a4e-4082-a4c6-d2ab2284c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"distinguishedand\" in errors_raw)\n",
    "print(\"distinguishedand\" in errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f880158-9c22-4145-ac51-934cf1c030d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_tt == errors_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e946ebd0-75f3-4083-a3a9-7bc4838484e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = ['of', 'agree', 'all', 'all his', 'and the', 'any such', 'care', 'a very', 'be that', 'beyond such', 'can be', 'can only', 'can see', 'carry on', 'Chambers', 'confidential', 'contemplating', 'Oh', \"'distinguished', and\", 'do crucially', \"don't take\", 'Tell', 'Farradays Circle', 'friends and', 'got to', 'the', 'I arrived', 'I can', 'if I', 'interest', \"I'm very\", 'In fact', 'is true', 'it involved', \"its rather\", 'locked', 'looking back', 'lot, you', 'lover, Stevens', 'to', 'not seek', 'of the', 'Oh, nothing', 'to', 'towards', 'put out', 'roasting', 'see he', 'self-evident', 'simply accepting', 'start seeing', \"that's all\", 'the likes', 'the very', 'the', 'to sit', 'very pleased', 'village, sir', 'were', 'with a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85f2e9-3c4e-42b8-bef6-115f9bde36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_1 = set(errors_tt)\n",
    "set_2 = set(errors)\n",
    "print(len(set_1), len(set_2))\n",
    "print(set_1 - set_2)\n",
    "print(set_2 - set_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675990c1-ceac-44b5-8265-475c9c1225ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_spell_1 = 0\n",
    "counter_spell_2 = 0\n",
    "counter_spell_3 = 0\n",
    "counter_blob_1 = 0\n",
    "counter_blob_2 = 0\n",
    "counter_blob_3 = 0\n",
    "\n",
    "for word in errors_tt:\n",
    "    if word in spell_set_1: counter_spell_1 += 1 \n",
    "    if word in spell_set_2: counter_spell_2 += 1\n",
    "    if word in spell_set_3: counter_spell_3 += 1\n",
    "    if word in blob_set_1: counter_blob_1 += 1\n",
    "    if word in blob_set_2: counter_blob_2 += 1\n",
    "    if word in blob_set_3: counter_blob_3 += 1\n",
    "print (counter_spell_1, counter_spell_2, counter_spell_3)\n",
    "print (counter_blob_1, counter_blob_2, counter_blob_3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585b2c0-381e-430d-ae1c-9ecd431b7eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in errors_tt:\n",
    "    if word not in blob_set_3: print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce725f-7094-4cba-9323-19ae8198fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_spell_1 = 0\n",
    "counter_spell_2 = 0\n",
    "counter_spell_3 = 0\n",
    "counter_blob_1 = 0\n",
    "counter_blob_2 = 0\n",
    "counter_blob_3 = 0\n",
    "\n",
    "for word in errors:\n",
    "    if word in spell_set_1: counter_spell_1 += 1 \n",
    "    if word in spell_set_2: counter_spell_2 += 1\n",
    "    if word in spell_set_3: counter_spell_3 += 1\n",
    "    if word in blob_set_1: counter_blob_1 += 1\n",
    "    if word in blob_set_2: counter_blob_2 += 1\n",
    "    if word in blob_set_3: counter_blob_3 += 1\n",
    "print (counter_spell_1, counter_spell_2, counter_spell_3)\n",
    "print (counter_blob_1, counter_blob_2, counter_blob_3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5700764-b25f-4aa7-a2da-a01a80437a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(errors_raw), len(errors), len(corrections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e3787-ea20-41dc-9f62-9c52bac4de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(corrections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb6328-63c2-4fdb-a2aa-035c0c21aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for error, correction in zip(errors, corrections):\n",
    "    if error == correction:\n",
    "        display_words_in_context(test_words_3, [error], False, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b90b91-cb83-4a82-8cfd-7530e5b1e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in errors:\n",
    "    if word not in text:\n",
    "        display_words_in_context(test_words_3, [word], False, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7319fa11-3b46-49b0-aa44-fd3cb74b62ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_text_in_context(text, [\"never forgive me\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bdd1cb-bb9b-46b8-ad5a-0f59c55dd11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([word in blob_set_3 for word in errors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b3ecf-0cb8-4c0f-a405-964c1627d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_is(\"bethat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862b4c56-a27d-4a8b-9e7a-818b58ea0acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"be that\" in corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e443ecc-2096-4217-8b15-74f54e935e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"allshot\" in both_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac2a16-7bd1-4897-ba5a-7577905fa458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d72464-2574-40df-9f36-ffb4b7a10957",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_text_in_context(text,[\"ell\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472945e-1b91-4232-b84f-b0475f868997",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {error: correction for error, correction in zip (errors, corrections)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee09f4-ed5a-4c5f-b4af-69068856abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(replacements[\"with-a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eec50fa-f189-4614-9c82-7ae26dfffef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(word for word in (blob_only_2 - blob_only_1)))\n",
    "display_words_in_context(test_words_2, blob_only_2 - blob_only_1, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce6245-245f-4485-a247-9c51944a1c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(word for word in (spell_only_3 - spell_only_2 - spell_only_1)))\n",
    "display_words_in_context(test_words_3, spell_only_3 - spell_only_2 - spell_only_1, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a20f68-d116-4d08-8742-47a8861c7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(word for word in (blob_only_3 - blob_only_2 - blob_only_1)))\n",
    "display_words_in_context(test_words_3, blob_only_3 - blob_only_2 - blob_only_1, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c5c1a-765d-4437-9779-ad2e660470f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf4cf3b-7ae6-4e23-a7a0-31697822a7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc6279f-1709-454e-ac5b-7ac43b78c086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57df1d8-6fcc-4357-9728-f5db60e255c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec8f3a-dde0-4ada-8a9a-53d314943e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd26866-fded-4a8d-bdad-6a0fb5331212",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for word in blob_set_2:\n",
    "    if word.lower() in blob_set_3:\n",
    "        print(f\"{word} in both\")\n",
    "        print(Word(word).spellcheck())\n",
    "        if word != word.lower():\n",
    "            print(Word(word.lower()).spellcheck())\n",
    "    else:\n",
    "        print (f\"{word} in 2 but not in 3\")\n",
    "        print(Word(word).spellcheck())\n",
    "    print(\"\\n\")    \n",
    "    counter = counter + 1\n",
    "    if counter > 15: break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed2fbb-f5a0-4bb1-b393-16de31da9166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da527b-568f-4896-8e01-68b7ed48a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = \"istrue canbe im tj1e overath laval itsrather wer silverss gotto thelikes ifi 0f prise ritz ofthe andthe lto lookingback al1 verypleased het thevery agre bethat seehe ot selfvident sleightsofhand cansee thatsall distinguishedand villagesir docrucially arec farradayscircle witha canonly barnets redding tosit clementss newtmating ill1terest anysuch dh lewiss donttake allhis contemplatin8 startseeing symons owardst imvery simplyaccepting selftraining wellcontented evercourteous donttake allhis lastminute civvy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0454a-fb4a-4054-94ac-24de224ee2da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d7a7e-1d51-498e-ab10-07a65049dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words=[\"ohnothing\", \"iarrived\", \"friendsand\", \"allshot\"]\n",
    "for word in bad_words:\n",
    "    print(word in errors_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cadc7-565c-497d-8a01-72d61ed4fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions_split = suggestions.split(' ')\n",
    "suggestions_sorted = sorted(suggestions_split)\n",
    "print(suggestions_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09427cc1-f405-4464-b6be-7fc259bd2fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_sorted = sorted(errors_split)\n",
    "print (errors_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d103da-705d-42d8-8f44-317d466de1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in bad_words:\n",
    "    errors_split.append(word)\n",
    "print(errors_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65371496-ddd5-4dc9-b53e-54a08b580303",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff9a19-380e-4acc-9650-a975353dca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_split = ['istrue', 'canbe', 'im', 'tj1e', 'overath', 'laval', 'itsrather', 'wer', 'silverss', 'gotto', 'thelikes', 'ifi', '0f', 'prise', 'ritz', 'ofthe', 'andthe', 'lto', 'lookingback', 'al1', 'verypleased', 'het', 'thevery', 'agre', 'bethat', 'seehe', 'ot', 'selfvident', 'sleightsofhand', 'cansee', 'thatsall', 'distinguishedand', 'villagesir', 'docrucially', 'arec', 'farradayscircle', 'witha', 'canonly', 'barnets', 'redding', 'tosit', 'clementss', 'newtmating', 'ill1terest', 'anysuch', 'dh', 'lewiss', 'donttake', 'allhis', 'contemplatin8', 'startseeing', 'symons', 'owardst', 'imvery', 'simplyaccepting', 'selftraining', 'wellcontented', 'evercourteous', 'donttake', 'allhis', 'lastminute', 'civvy', 'ohnothing', 'iarrived', 'friendsand', 'allshot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f858ade-6194-4520-9ae3-a0230103701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for bad_word in bad_words:\n",
    "    ind = text.find(bad_word)\n",
    "    if ind == -1:\n",
    "        print(f\"{bad_word} not found\")\n",
    "    else:\n",
    "        window = text[ind-50:ind+50]\n",
    "        window = window.replace(\"\\n\", \" \")\n",
    "        window = window.replace(\"\\t\", \" \")\n",
    "        print(window)\n",
    "    #test_result = (Word(test_word).spellcheck())\n",
    "    #print(test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a541d2-64e9-4cdf-8cfc-c1a076ff7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = text.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
    "bad_words=[\"ohnothing\", \"iarrived\", \"friendsand\", \"allshot\"]\n",
    "bad_words = [\"ell\", \"ting\"]\n",
    "for bad_word in bad_words:\n",
    "    try:\n",
    "        ind = test_words.index(bad_word)\n",
    "        print(f\"The index of '{bad_word}' is: {ind}\")\n",
    "        print(' '.join(test_words[ind - 10:ind + 10]))\n",
    "    except ValueError:\n",
    "        print(f\"'{item_to_find}' not found in the list.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b0c707-02c7-4573-b08d-bba3262278ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(blob_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b8c3c-6402-404f-8e3a-267bacf42033",
   "metadata": {},
   "outputs": [],
   "source": [
    "both = spell_set & blob_set\n",
    "print(len(both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de333e45-7126-47bb-9447-b42f1ece6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(word for word in both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f25e8a-925c-417d-a81f-bd1ca37c6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_errors = \"istrue canbe im tj1e overath laval itsrather wer silverss gotto thelikes ifi 0f prise ritz ofthe andthe lto lookingback al1 verypleased het thevery agre bethat seehe ot selfvident sleightsofhand cansee thatsall distinguishedand villagesir docrucially arec farradayscircle witha canonly barnets redding tosit clementss newtmating ill1terest anysuch dh lewiss donttake allhis contemplatin8 startseeing symons owardst imvery simplyaccepting selftraining wellcontented evercourteous donttake allhis lastminute civvy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b9ea58-49af-4e8f-9be7-779830d8eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_errors_split = set(original_errors.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a546bee2-8dbc-4329-b1bb-892c2e7bc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "missed = {word for word in original_errors_split if word not in errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c805622-08b7-4460-ba37-84e56269439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ([(word, word in blob_set_3) for word in missed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aab8b65-c34e-4b31-9649-038e934bfe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ([(word, word in both_3) for word in missed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd97c339-224d-428e-a557-ec3b9d6be1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ([(word, word in spell_set_3) for word in missed])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ab175-8e0c-45ad-9513-1d67321fe30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in errors_split:\n",
    "    if word not in text:\n",
    "        if word not in cleaned_suggestions:\n",
    "            print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcdea9a-50b8-49a3-846a-597e6c2e4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_is(\"distinguishedand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fbc744-436d-42d4-af84-d7197cadbb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([word for word in blob_set_3 if word not in blob_only])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655e006-5bfb-4dbf-808d-141d92766b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions = \"Overath Laval 1e with-a it'srather Silvers's Farraday'scircle Barnet's Clements's newt-mating Lewis's don'ttake I'mvery self-training well-contented ever-courteous don'ttake last-minute Ritz Redding self-vident sleights-of-hand be-that that'sall d-h Symons\"\n",
    "cleaned_suggestions = suggestions.translate(str.maketrans('', '', string.punctuation)).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8efe08-4c67-4fc7-9d9f-b34d928f9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in suggestions.split(' '):\n",
    "    if word not in text:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8498acb-31a9-4857-b72c-f83224304ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in errors_split:\n",
    "    if word not in cleaned_suggestions:`\n",
    "        if word not in test_words:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946ef07-9113-43ca-8aaf-d9a743a9b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" prise \" in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce07e4-5c13-4648-8f81-b3401fc9beb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
