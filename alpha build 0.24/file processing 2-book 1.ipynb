{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1726f6c5-0b63-4184-ab57-21fad4577fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza, re, benepar, psutil, gc, json, csv, time, string, os\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from textstat import textstat\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_infix_regex\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import Tree\n",
    "from textblob import Word\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import LogLocator, LogFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ee7f15-f969-4fe0-83d2-6584568b66b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memcheck():\n",
    "    gc.collect()\n",
    "    memory_info = psutil.virtual_memory()\n",
    "\n",
    "    # Display the memory information in GB\n",
    "    total_memory = memory_info.total / (1024 ** 3)\n",
    "    available_memory = memory_info.available / (1024 ** 3)\n",
    "    used_memory = memory_info.used / (1024 ** 3)\n",
    "\n",
    "    print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "    print(f\"Available Memory: {available_memory:.2f} GB\")\n",
    "    print(f\"Used Memory: {used_memory:.2f} GB\")\n",
    "\n",
    "def time_taken(start_time, end_time):\n",
    "    time_taken = end_time - start_time\n",
    "    hours, remainder = divmod(time_taken.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f\"Time Taken: {hours} hours, {minutes} minutes, {seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3679f96e-a99d-4162-b101-a74ea76f2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_text_in_context(text, words, window = 75):\n",
    "#Finds the first occurrence of each word in target text and displays it\n",
    "    \n",
    "    for word in words:\n",
    "        ind = text.find(word)\n",
    "        if ind == -1:\n",
    "            print (f\"{word} not found in text\")\n",
    "        else:\n",
    "            display_text = text[ind-window:ind+window+1]\n",
    "            display_text = display_text.replace(\"\\n\", \" \")\n",
    "            display_text = display_text.replace(\"\\t\", \" \")\n",
    "            display_text = display_text.replace(\"  \", \" \")\n",
    "            print(display_text)\n",
    "\n",
    "def display_words_in_context(text_words, words, repeat = False, window = 2):\n",
    "# Finds the first occurrence of each word in target list of words. Optionally finds every subsequent occurrence     \n",
    "    if not repeat:\n",
    "        for word in words:\n",
    "            try:\n",
    "                #print(\"trying \", word)\n",
    "                index = text_words.index(word)\n",
    "                #print(f\"The index of '{word}' is: {index}\")\n",
    "                display_text = ' '.join(text_words[index - window:index])\n",
    "                display_text = display_text + \" [\" + word + \"] \"\n",
    "                display_text = display_text + ' '.join(text_words[index + 1 : index + window + 1])\n",
    "                print(display_text)\n",
    "            except ValueError:\n",
    "                print(f\"'{word}' not found in the text.\")\n",
    "    else:\n",
    "        for word in words:\n",
    "            indices = [index for index, value in enumerate(text_words) if value == word]\n",
    "            if len(indices) == 0:\n",
    "                print(f\"'{word}' not found in the text.\")\n",
    "            else:\n",
    "                for index in indices:\n",
    "                    display_text = ' '.join(text_words[index - window:index])\n",
    "                    display_text = display_text + \" [\" + word + \"] \"\n",
    "                    display_text = display_text + ' '.join(text_words[index + 1 : index + window + 1])\n",
    "                    print(display_text)\n",
    "\n",
    "\n",
    "\n",
    "def display_word_in_text(text, word, window=30):\n",
    "    # Create regex pattern for more flexible word boundaries\n",
    "    pattern = fr\"(?<=[\\s\\-\\.'\\\"]){re.escape(word)}(?=[\\s.,!?;:'\\\"\\-])\"\n",
    "    \n",
    "    # Use re.finditer to get all matches and their positions\n",
    "    matches = [match.start() for match in re.finditer(pattern, text)]\n",
    "    \n",
    "    if matches:\n",
    "        matches = matches[:3]\n",
    "        for match in matches:\n",
    "            print(text[max(0, match - window): min(len(text), match + len(word) + window)])\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print(f\"The word '{word}' was not found.\")\n",
    "\n",
    "\n",
    "def is_word_in_text(text, word):\n",
    "    # Create regex pattern for more flexible word boundaries\n",
    "    pattern = fr\"(?<=[\\s\\-\\.'\\\"]){re.escape(word)}(?=[\\s.,!?;:'\\\"\\-])\"\n",
    "    \n",
    "    # Use re.finditer to get all matches and their positions\n",
    "    matches = [match.start() for match in re.finditer(pattern, text)]\n",
    "    return len(matches) > 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "169f2aaf-8823-4555-86c9-7ea1bcdcc146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def where_is(word):\n",
    "    # finds if spell checker has flagged a word.  Must run spell checker first.\n",
    "    if (word in spell_set_0): \n",
    "        print (\"In spell set 0\")\n",
    "    if (word in blob_set_0):\n",
    "        print (\"In blob set 0\")\n",
    "    if (word in spell_set_0) or (word in blob_set_0):\n",
    "        display_words_in_context(test_words_0, [word], False, 6)\n",
    "    if (word in spell_set_1): \n",
    "        print (\"In spell set 1\")\n",
    "    if (word in blob_set_1):\n",
    "        print (\"In blob set 1\")\n",
    "    if (word in spell_set_1) or (word in blob_set_1):\n",
    "        display_words_in_context(test_words_1, [word], False, 6)\n",
    "    if (word in spell_set_2): \n",
    "        print (\"In spell set 2\")\n",
    "    if (word in blob_set_2):\n",
    "        print (\"In blob  set 2\")\n",
    "    if (word in spell_set_2) or (word in blob_set_2):\n",
    "        display_words_in_context(test_words_2, [word], False, 6)\n",
    "    if (word in spell_set_3): \n",
    "        print (\"In spell set 3\")\n",
    "    if (word in blob_set_3):\n",
    "        print (\"In blob set 3\")\n",
    "    if (word in spell_set_3) or (word in blob_set_3):\n",
    "        display_words_in_context(test_words_3, [word], False, 6)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c5b86133-7498-4131-adda-87f9fe6736ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_which_texts(word, repeat = False):\n",
    "    if word in text_1:\n",
    "        print(\"in text_1\")\n",
    "        display_text_in_context(text_1, [word], window=40)\n",
    "    else:\n",
    "        print(\"not in text_1\")\n",
    "    \n",
    "    if word in unhyphenated:\n",
    "        print(\"in hyphenated\")\n",
    "        display_text_in_context(unhyphenated, [word], window=40)\n",
    "    else:\n",
    "        print(\"not in unhyphenated\")\n",
    "    \n",
    "    if word in test_words_0:\n",
    "        print (\"in test_words_0\")\n",
    "        display_words_in_context(test_words_0, [word], repeat, 6)\n",
    "    else:\n",
    "        print(\"not in test_words_0\")\n",
    "    \n",
    "    if word in test_words_1:\n",
    "        print (\"in test_words_1\")\n",
    "        display_words_in_context(test_words_1, [word], repeat, 6)\n",
    "    else:\n",
    "        print(\"not in test_words_1\")\n",
    "    \n",
    "    if word in test_words_2:\n",
    "        print (\"in test_words_2\")\n",
    "        display_words_in_context(test_words_2, [word], repeat, 6)\n",
    "    else:\n",
    "        print(\"not in test_words_2\")\n",
    "        \n",
    "    if word in test_words_3:\n",
    "        print (\"in test_words_3\")\n",
    "        display_words_in_context(test_words_3, [word], repeat, 6)\n",
    "    else:\n",
    "        print(\"not in test_words_3\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf51ac-1455-4808-a856-41932bc670aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab552a7-70aa-4d5d-b408-f04abcab890b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29278a47-903b-4cda-9983-e1625d9ce6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hyphenated_words(text):\n",
    "    # Use regex to find words that are hyphenated across lines\n",
    "    # Match sequences where a hyphen is at the end of a line, followed by a newline, and then continued with a word\n",
    "    hyphenated_words = re.findall(r\"(\\w+)-\\n(\\w+)\", text)\n",
    "\n",
    "    for first_part, second_part in hyphenated_words:\n",
    "        print(f\"Found broken word: {first_part}-{second_part}\")\n",
    "    print(f\"{len(hyphenated_words)} hyphenated words found, text length is: {len(text)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db25ec42-fd25-4ccb-8473-aee451fffdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_hyphenated_words(text, show_changes = False):\n",
    "    # This regular expression captures words separated by a hyphen, with letters on both sides.\n",
    "    pattern = r'(\\b\\w+)-(\\w+\\b)'\n",
    "\n",
    "    # Function to handle replacement and printing\n",
    "    def replacement(match):\n",
    "        # Original hyphenated word\n",
    "        original_word = match.group(0)\n",
    "        # Replacement word (with space instead of hyphen)\n",
    "        altered_word = match.group(1) + \" \" + match.group(2)\n",
    "        \n",
    "        # Print the hyphenated word that was altered\n",
    "        if show_changes: print(f\"Altered: {original_word} -> {altered_word}\")\n",
    "\n",
    "        return altered_word\n",
    "\n",
    "    # Replace hyphenated words and call the replacement function\n",
    "    result = re.sub(pattern, replacement, text)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13696b61-ffef-4f5e-ab17-a09304167d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_hyphenated_words_alt(text, silent = True):\n",
    "    # Find words that have a hyphen between them\n",
    "    hyphenated_words = re.findall(r'\\b\\w+-\\w+\\b', text)\n",
    "    counter = 0\n",
    "    # Replace each hyphenated word with a space between words instead of the hyphen\n",
    "    for word in hyphenated_words:\n",
    "        new_word = word.replace('-', ' ')\n",
    "        text = text.replace(word, new_word)\n",
    "        counter += 1\n",
    "        if not silent: print(f\"Replaced '{word}' with '{new_word}'\")\n",
    "    print(counter)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81a11d44-ef56-4efc-86ac-7f0a72db3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_oddities(text):\n",
    "    # Run this after creating oddities, use the text BEFORE hyphens were removed\n",
    "    hyphenated_words = re.findall(r'\\b\\w+-\\w+\\b', text)\n",
    "        \n",
    "    for word in hyphenated_words:\n",
    "        new_word = word.replace('-', ' ')\n",
    "        new_word_split = new_word.split(' ')\n",
    "        #print(word, new_word)\n",
    "        if new_word_split[0] in oddities or new_word_split[1] in oddities:\n",
    "            print (word, new_word)\n",
    "            display_text_in_context(text, [word], window = 40)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5965411e-d962-4c42-855b-73d75866f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an Example Text with DOUBLE SPACES.\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text, make_lower = True):\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Convert to lowercase\n",
    "    if make_lower:\n",
    "        text = text.lower()\n",
    "    # Strip any leading or trailing spaces\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "tt = \"This  is   an Example  Text with    DOUBLE  SPACES.\"\n",
    "cleaned_text = clean_text(tt, False)\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d37bee5d-a418-4f70-b285-0f1f16bda66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice bum', 'age': '30 years', 'city': 'New York duds'}\n"
     ]
    }
   ],
   "source": [
    "def list_to_dict(alternating_list):\n",
    "    # Use dictionary comprehension with list slicing to group pairs\n",
    "    return {alternating_list[i]: alternating_list[i+1]+ \" \" + alternating_list[i+2] for i in range(0, len(alternating_list), 3)}\n",
    "\n",
    "# Example usage\n",
    "alternating_list = ['name', 'Alice', 'bum', 'age', '30', 'years', 'city', 'New York', 'duds']\n",
    "dictionary = list_to_dict(alternating_list)\n",
    "print(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92cf6efe-a206-42c1-9967-9f885df962b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find and replace specified strings in a text\n",
    "def replace_strings_with_context(text, replacements, window=10, silent = False):\n",
    "    \"\"\"\n",
    "    Replaces specified strings within a text and prints the context around each replacement.\n",
    "    \n",
    "    Parameters:\n",
    "    - text: The original string where replacements are done.\n",
    "    - replacements: A dictionary where keys are the substrings to find, and values are their replacements.\n",
    "    - window: Number of characters to show before and after the replaced string for context.\n",
    "    \n",
    "    Returns:\n",
    "    - A modified string with the replacements applied.\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    for old, new in replacements.items():\n",
    "        index = text.find(old)\n",
    "        while index != -1:\n",
    "            # Extract context around the found string\n",
    "            start = max(index - window, 0)\n",
    "            end = min(index + len(old) + window, len(text))\n",
    "            before = text[start:index]\n",
    "            after = text[index + len(old):end]\n",
    "            before = before.replace(\"\\n\", \" \")\n",
    "            before = before.replace(\"\\t\", \" \")\n",
    "            after = after.replace(\"\\n\", \" \")\n",
    "            after = after.replace(\"\\t\", \" \")\n",
    "\n",
    "            # Print before, replaced, and after strings\n",
    "            if not silent:\n",
    "                print(f\"Before: {before}[{old}]{after}\")\n",
    "                print(f\"After:  {before}[{new}]{after}\\n\")\n",
    "\n",
    "            # Replace the string in the text\n",
    "            text = text[:index] + new + text[index + len(old):]\n",
    "            counter += 1\n",
    "            \n",
    "            # Find the next occurrence of the old string\n",
    "            index = text.find(old, index + len(new))\n",
    "\n",
    "    print(f\"made {counter} changes\")\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50579c19-2c46-4d18-aa7c-10daefa8ef78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856f4cb-87fc-4706-a057-4cc6a718824e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b24cd98d-fecd-47ae-934f-11ab9a1d0ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Roland/Documents/AI/stylometry/Kazuo Ishiguro - The Remains of the Day.txt\n"
     ]
    }
   ],
   "source": [
    "source_texts= list()\n",
    "source_texts.append(\"Kazuo Ishiguro - Never Let Me Go\")\n",
    "source_texts.append(\"Kazuo Ishiguro - The Remains of the Day\")\n",
    "source_texts.append(\"Kazuo Ishiguro - A Pale View of Hills-Knopf Doubleday Publishing Group (1990)\")\n",
    "source_texts.append(\"Kazuo-Ishiguro-When-We-Were-Orphans-Alfred-A.-Knopf_Vintage-_2001_\")\n",
    "source_texts.append(\"The Buried Giant (Kazuo Ishiguro) (Z-Library)-1\")\n",
    "source_texts.append(\"Kazuo Ishiguro - The Unconsoled-Vintage (1996)\")\n",
    "directory_path = \"C:/Users/Roland/Documents/AI/stylometry/\"\n",
    "file_path = directory_path+source_texts[1]+\".txt\"\n",
    "print (file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51fa129b-3e6e-4e91-9156-dfd21c74b804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n",
      "[\"aren't\", 'are', 'not', \"can't\", 'can', 'not', \"couldn't\", 'could', 'not', \"didn't\", 'did', 'not', \"doesn't\", 'does', 'not', \"don't\", 'do', 'not', \"hadn't\", 'had', 'not', \"hasn't\", 'has', 'not', \"haven't\", 'have', 'not', \"isn't\", 'is', 'not', \"mightn't\", 'might', 'not', \"mustn't\", 'must', 'not', \"needn't\", 'need', 'not', \"shan't\", 'shall', 'not', \"shouldn't\", 'should', 'not', \"wasn't\", 'was', 'not', \"weren't\", 'were', 'not', \"won't\", 'will', 'not', \"wouldn't\", 'would', 'not', \"i'd\", 'i', 'would', \"you'd\", 'you', 'would', \"he'd\", 'he', 'would', \"she'd\", 'she', 'would', \"it'd\", 'it', 'would', \"we'd\", 'we', 'would', \"they'd\", 'they', 'would', \"who'd\", 'who', 'would', \"there'd\", 'there', 'would', \"that'd\", 'that', 'would', \"i'll\", 'i', 'will', \"you'll\", 'you', 'will', \"he'll\", 'he', 'will', \"she'll\", 'she', 'will', \"it'll\", 'it', 'will', \"we'll\", 'we', 'will', \"they'll\", 'they', 'will', \"who'll\", 'who', 'will', \"that'll\", 'that', 'will', \"what'll\", 'what', 'will', \"i've\", 'i', 'have', \"you've\", 'you', 'have', \"he's\", 'he', 'has', \"she's\", 'she', 'has', \"we've\", 'we', 'have', \"they've\", 'they', 'have', \"who's\", 'who', 'has', \"who've\", 'who', 'have', \"i'm\", 'i', 'am', \"you're\", 'you', 'are', \"he's\", 'he', 'is', \"she's\", 'she', 'is', \"it's\", 'it', 'is', \"we're\", 'we', 'are', \"they're\", 'they', 'are', \"who's\", 'who', 'is', \"there's\", 'there', 'is', \"there're\", 'there', 'are', \"that's\", 'that', 'is', \"Aren't\", 'Are', 'not', \"Can't\", 'Can', 'not', \"Couldn't\", 'Could', 'not', \"Didn't\", 'Did', 'not', \"Doesn't\", 'Does', 'not', \"Don't\", 'Do', 'not', \"Hadn't\", 'Had', 'not', \"Hasn't\", 'Has', 'not', \"Haven't\", 'Have', 'not', \"Isn't\", 'Is', 'not', \"Mightn't\", 'Might', 'not', \"Mustn't\", 'Must', 'not', \"Needn't\", 'Need', 'not', \"Shan't\", 'Shall', 'not', \"Shouldn't\", 'Should', 'not', \"Wasn't\", 'was', 'not', \"Weren't\", 'Were', 'not', \"Won't\", 'Will', 'not', \"Wouldn't\", 'Would', 'not', \"I'd\", 'I', 'would', \"You'd\", 'You', 'would', \"He'd\", 'He', 'would', \"She'd\", 'She', 'would', \"It'd\", 'It', 'would', \"We'd\", 'We', 'would', \"They'd\", 'They', 'would', \"Who'd\", 'Who', 'would', \"There'd\", 'There', 'would', \"That'd\", 'That', 'would', \"I'll\", 'I', 'will', \"You'll\", 'You', 'will', \"He'll\", 'He', 'will', \"She'll\", 'She', 'will', \"It'll\", 'It', 'will', \"We'll\", 'We', 'will', \"They'll\", 'They', 'will', \"Who'll\", 'Who', 'will', \"That'll\", 'That', 'will', \"What'll\", 'What', 'will', \"I've\", 'I', 'have', \"You've\", 'You', 'have', \"He's\", 'He', 'has', \"She's\", 'She', 'has', \"We've\", 'We', 'have', \"They've\", 'They', 'have', \"Who's\", 'Who', 'has', \"Who've\", 'Who', 'have', \"I'm\", 'I', 'am', \"You're\", 'You', 'are', \"He's\", 'He', 'is', \"She's\", 'She', 'is', \"It's\", 'It', 'is', \"We're\", 'We', 'are', \"They're\", 'They', 'are', \"Who's\", 'Who', 'is', \"There's\", 'There', 'is', \"There're\", 'There', 'are', \"That's\", 'That', 'is']\n"
     ]
    }
   ],
   "source": [
    "contractions = \"Aren't\tAre not Can't\tCan not Couldn't\tCould not Didn't\tDid not Doesn't\tDoes not Don't\tDo not Hadn't\tHad not Hasn't\tHas not Haven't\tHave not Isn't\tIs not Mightn't\tMight not Mustn't\tMust not Needn't\tNeed not Shan't\tShall not Shouldn't\tShould not Wasn't was not Weren't\tWere not Won't\tWill not Wouldn't\tWould not\"\n",
    "contractions = contractions + \" I'd\tI would You'd\tYou would He'd\tHe would She'd\tShe would It'd\tIt would We'd\tWe would They'd\tThey would Who'd\tWho would There'd There would That'd That would\" \n",
    "contractions = contractions + \" I'll\tI will You'll\tYou will He'll\tHe will She'll\tShe will It'll\tIt will We'll\tWe will They'll\tThey will Who'll\tWho will That'll That will What'll What will\"\n",
    "contractions = contractions + \" I've\tI have You've\tYou have He's\tHe has She's\tShe has We've\tWe have They've\tThey have Who's\tWho has Who've Who have\"\n",
    "contractions = contractions + \" I'm\tI am You're\tYou are He's\tHe is She's\tShe is It's\tIt is We're\tWe are They're\tThey are Who's\tWho is There's There is There're There are That's That is\"\n",
    "contractions = clean_text(contractions, True) + \" \" + clean_text(contractions, False)\n",
    "contractions = contractions.split(' ')\n",
    "print(len(contractions))\n",
    "print(contractions)\n",
    "contractions = list_to_dict(contractions)\n",
    "contractions[\"can't\"] = \"cannot\"\n",
    "contractions[\"Can't\"] = \"Cannot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "54491884-5fbf-4bd9-be7e-d96b0d983432",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in contractions.items():\n",
    "    if \" \" in key or value[0] == \" \" or value[-1] == \" \": print(key, \": \", value)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0b70941-aa90-4c56-a8e1-d9f1dde577c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file not found at  C:/Users/Roland/Documents/AI/stylometry/Kazuo Ishiguro - The Remains of the Day edited_2.txt\n",
      "file found at  C:/Users/Roland/Documents/AI/stylometry/Kazuo Ishiguro - The Remains of the Day edited_1.txt\n"
     ]
    }
   ],
   "source": [
    "text_choice = 1\n",
    "\n",
    "\n",
    "file_path = directory_path+source_texts[text_choice]+\" edited_2.txt\"\n",
    "if os.path.isfile(file_path):\n",
    "    print (\"file found at \", file_path)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "else:\n",
    "    print(\"file not found at \", file_path)\n",
    "    file_path = directory_path+source_texts[text_choice]+\" edited_1.txt\"\n",
    "    if os.path.isfile(file_path):\n",
    "        print (\"file found at \", file_path)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "    else:\n",
    "        print(\"file not found at \", file_path)\n",
    "        file_path = directory_path+source_texts[text_choice]+\" edited.txt\"\n",
    "        if os.path.isfile(file_path):\n",
    "            print (\"file found at \", file_path)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "        else:\n",
    "            print(\"file not found at \", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3be5dd1-b1c4-484d-a3f9-75d0dcd7b937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423406\n",
      "made 657 changes\n",
      "424295\n"
     ]
    }
   ],
   "source": [
    "print (len(text))\n",
    "text_1 = replace_strings_with_context(text, contractions, window=10, silent = True)\n",
    "print(len(text_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "973d797f-474a-4f01-861b-2089918fa692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    }
   ],
   "source": [
    "unhyphenated_alt = replace_hyphenated_words_alt(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "865e6cc2-e337-46a9-a4de-df1665fc9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words_0 = text_1.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "test_words_1 = text_1.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
    "unhyphenated = replace_hyphenated_words(text_1)\n",
    "test_words_2 = unhyphenated.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "test_words_3 = unhyphenated.translate(str.maketrans('', '', string.punctuation)).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0c8ad72-9191-4388-ac0d-dd6f75b540ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing at: 08:43:25\n",
      "Completed processing at: 09:02:23\n",
      "Time Taken: 0 hours, 18 minutes, 57 seconds\n",
      "1244 971 1144 871\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(f\"Starting processing at: {start_time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "# Find invalid words\n",
    "blob_set_0 = set()\n",
    "for word in test_words_0:\n",
    "    result = Word(word).spellcheck()\n",
    "    if result[0][1] < 1.0 or result[0][0] != word:\n",
    "        blob_set_0.add(word)\n",
    "\n",
    "blob_set_1 = set()\n",
    "for word in test_words_1:\n",
    "    result = Word(word).spellcheck()\n",
    "    if result[0][1] < 1.0 or result[0][0] != word:\n",
    "        blob_set_1.add(word)\n",
    "\n",
    "blob_set_2 = set()\n",
    "for word in test_words_2:\n",
    "    result = Word(word).spellcheck()\n",
    "    if result[0][1] < 1.0 or result[0][0] != word:\n",
    "        blob_set_2.add(word)\n",
    "\n",
    "blob_set_3 = set()\n",
    "for word in test_words_3:\n",
    "    result = Word(word).spellcheck()\n",
    "    if result[0][1] < 1.0 or result[0][0] != word:\n",
    "        blob_set_3.add(word)\n",
    "        \n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f\"Completed processing at: {end_time.strftime('%H:%M:%S')}\")\n",
    "time_taken(start_time, end_time)\n",
    "\n",
    "print(len(blob_set_0), len(blob_set_1), len(blob_set_2), len(blob_set_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3edcc35e-e56c-4f2a-adb2-94b52de56b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors found in base text: 1244\n",
      "errors found with case lowered: 971\n",
      "errors found with hyphens removed:  1144\n",
      "errors found with hyphens removed and case lowered: 871\n",
      "errors eliminated by removing hyphens:  124 or in lower case: 123\n",
      "errors introduced by removing hyphens:  24 or in lower case: 23\n",
      "errors eliminated by lowering case:  428 or without hyphens: 424\n",
      "errors introduced by lowering case:  155 or without hyphens: 151\n"
     ]
    }
   ],
   "source": [
    "print(f\"errors found in base text: {len(blob_set_0)}\")\n",
    "print(f\"errors found with case lowered: {len(blob_set_1)}\")\n",
    "print(f\"errors found with hyphens removed:  {len(blob_set_2)}\")     \n",
    "print(f\"errors found with hyphens removed and case lowered: {len(blob_set_3)}\")     \n",
    "print(f\"errors eliminated by removing hyphens:  {len(blob_set_0 - blob_set_2)} or in lower case: {len(blob_set_1 - blob_set_3)}\")\n",
    "print(f\"errors introduced by removing hyphens:  {len(blob_set_2 - blob_set_0)} or in lower case: {len(blob_set_3 - blob_set_1)}\")\n",
    "print(f\"errors eliminated by lowering case:  {len(blob_set_0 - blob_set_1)} or without hyphens: {len(blob_set_2 - blob_set_3)}\")\n",
    "print(f\"errors introduced by lowering case:  {len(blob_set_1 - blob_set_0)} or without hyphens: {len(blob_set_3 - blob_set_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c693f83-ba9e-49ed-9111-09327c773843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heinz Karl Semitic bores chock hog humouredness inwaiting jacketed longue loverStevens martialling matching mating newt ofhand pep sheeted sheetings slated sleights tiles ups vident\n"
     ]
    }
   ],
   "source": [
    "oddities = sorted(list(blob_set_2-blob_set_0))\n",
    "print(' '.join(oddities))\n",
    "#display_words_in_context(test_words_2, oddities, window = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8601021d-f700-4043-9c57-dc0e398880a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bores chock heinz hog humouredness inwaiting jacketed longue loverstevens martialling matching mating newt ofhand pep semitic sheeted sheetings slated sleights tiles ups vident\n"
     ]
    }
   ],
   "source": [
    "oddities_lower = sorted(list(blob_set_3-blob_set_1))\n",
    "print(' '.join(oddities_lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ac26a6f-6071-4d6a-a46a-46cf9a9f0e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "missed = [word for word in oddities_lower if word not in blob_set_3]\n",
    "print(' '.join(missed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c07d8cf-0b65-4ca0-acaf-51d07b9dd07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chaise-longue chaise longue\n",
      " down on a table, seated himself on the chaise-longue, and stretched out his legs\n",
      "\n",
      "\n",
      "dust-sheeted dust sheeted\n",
      "orridor up on the second floor would be dust-sheeted, leaving all the main ground\n",
      "\n",
      "\n",
      "good-humouredness good humouredness\n",
      " was participating in some way with the good-humouredness with which he was carry\n",
      "\n",
      "\n",
      "newt-mating newt mating\n",
      "e-ranging topics such as  falconing or newt-mating - attributes none of which my\n",
      "\n",
      "\n",
      "twelve-bores twelve bores\n",
      "ining room. Perhaps you will permit the twelve-bores to be used?\"  And according\n",
      "\n",
      "\n",
      "court-martialling court martialling\n",
      "ad been calls for the removal, even the court-martialling, of the general concern\n",
      "\n",
      "\n",
      "self-vident self vident\n",
      "ssing him as 'William' should have been self-vident to you.\" \"Mr Stevens, I may \n",
      "\n",
      "\n",
      "roof-tiles roof tiles\n",
      "o view from his small window other than roof-tiles and guttering. The oil lamp be\n",
      "\n",
      "\n",
      "Karl-Heinz Karl Heinz\n",
      "treaty, but by his friendship with Herr Karl-Heinz Bremann. Herr Bremann first v\n",
      "\n",
      "\n",
      "pep-talk pep talk\n",
      "I even gave the staff a military-style 'pep-talk', impressing upon them that, for\n",
      "\n",
      "\n",
      "chock-full chock full\n",
      "ase\" - he nudged it with his foot - \"is chock-full of notes on every possible ang\n",
      "\n",
      "\n",
      "dark-jacketed dark jacketed\n",
      "e room crammed full with so many stern, dark-jacketed gentlemen, sometimes sittin\n",
      "\n",
      "\n",
      "hog-wash hog wash\n",
      "matters they do not understand. So much hog-wash has been spoken here these past \n",
      "\n",
      "\n",
      "hog-wash hog wash\n",
      "matters they do not understand. So much hog-wash has been spoken here these past \n",
      "\n",
      "\n",
      "dust-sheeted dust sheeted\n",
      "orridor up on the second floor would be dust-sheeted, leaving all the main ground\n",
      "\n",
      "\n",
      "dust-sheeted dust sheeted\n",
      "orridor up on the second floor would be dust-sheeted, leaving all the main ground\n",
      "\n",
      "\n",
      "anti-Semitic anti Semitic\n",
      "it is to claim that Lord Darlington was anti-Semitic, or that he had close associ\n",
      "\n",
      "\n",
      "anti-Semitic anti Semitic\n",
      "it is to claim that Lord Darlington was anti-Semitic, or that he had close associ\n",
      "\n",
      "\n",
      "dark-slated dark slated\n",
      "eeple, and around about it, clusters of dark-slated roofs; here and there, wisps \n",
      "\n",
      "\n",
      "turn-ups turn ups\n",
      "st to the shoulder of my jacket and the turn-ups of my trousers. The last few fie\n",
      "\n",
      "\n",
      "turn-ups turn ups\n",
      "st to the shoulder of my jacket and the turn-ups of my trousers. The last few fie\n",
      "\n",
      "\n",
      "turn-ups turn ups\n",
      "st to the shoulder of my jacket and the turn-ups of my trousers. The last few fie\n",
      "\n",
      "\n",
      "pep-talks pep talks\n",
      " \"He is also rather fond of your staff 'pep-talks'. l must say, I have become qu\n",
      "\n",
      "\n",
      "ill-matching ill matching\n",
      "icated, I discovered a room filled with ill-matching armchairs and occasional tab\n",
      "\n",
      "\n",
      "dust-sheetings dust sheetings\n",
      "e house itself, the alterations and the dust-sheetings, as well as the present st\n",
      "\n",
      "\n",
      "sleights-of sleights of\n",
      "t out of staff, as well as the various 'sleights-of-hand' - the equivalent of a c\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_oddities(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d62cea13-8b4e-4666-8ede-a0706b934a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452 447 366 361\n"
     ]
    }
   ],
   "source": [
    "# Use spellchecker to validate words\n",
    "# Initialize spell checker\n",
    "spell = SpellChecker()\n",
    "\n",
    "\n",
    "# Find words not in the dictionary\n",
    "spell_set_0 = {word for word in test_words_0 if word not in spell}\n",
    "spell_set_1 = {word for word in test_words_1 if word not in spell}\n",
    "spell_set_2 = {word for word in test_words_2 if word not in spell}\n",
    "spell_set_3 = {word for word in test_words_3 if word not in spell}\n",
    "\n",
    "print(len(spell_set_0), len(spell_set_1), len(spell_set_2), len(spell_set_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2314cbe5-f120-431d-bc0e-ef601f5e43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_3 = spell_set_3 & blob_set_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52d8f88b-67be-4be6-accf-ef4389554cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n"
     ]
    }
   ],
   "source": [
    "print(len(both_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10ba8f53-49ee-4f56-8719-3a5868b7c5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In spell set 0\n",
      "In blob set 0\n",
      "that Lord Darlington was liaising covertly [witha] known enemy is just conveniently forgetting\n",
      "In spell set 1\n",
      "In blob set 1\n",
      "that lord darlington was liaising covertly [witha] known enemy is just conveniently forgetting\n"
     ]
    }
   ],
   "source": [
    "where_is(\"witha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be6683cf-40fb-4fac-8d93-222b596ae335",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_is(\"with-a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e7f5d6f-af68-4f2c-ba48-fbf71729ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_is(\"self-vident\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "30f735f3-3516-43aa-bfcb-075dff99738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_is(\"not-seek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f427cbb-352b-4411-a461-b561d413d684",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_is(\"be-that\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c612a4a9-fced-49ca-b3af-024d6f73f9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in text_1\n",
      "t Lord Darlington was liaising covertly with-a known enemy is just conveniently f\n",
      "not in unhyphenated\n",
      "not in test_words_0\n",
      "not in test_words_1\n",
      "not in test_words_2\n",
      "not in test_words_3\n"
     ]
    }
   ],
   "source": [
    "in_which_texts(\"with-a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "236d03ec-bf68-415c-98b6-4fe72261e99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in text_1\n",
      "ssing him as 'William' should have been self-vident to you.\" \"Mr Stevens, I may \n",
      "not in unhyphenated\n",
      "not in test_words_0\n",
      "not in test_words_1\n",
      "not in test_words_2\n",
      "not in test_words_3\n"
     ]
    }
   ],
   "source": [
    "in_which_texts(\"self-vident\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "07c7c9e0-7d5d-448a-b3f2-59ceeb892361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in text_1\n",
      "rs is no reason in itself why we should not-seek a more convenient arrangement fr\n",
      "not in unhyphenated\n",
      "not in test_words_0\n",
      "not in test_words_1\n",
      "not in test_words_2\n",
      "not in test_words_3\n"
     ]
    }
   ],
   "source": [
    "in_which_texts(\"not-seek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8c7ae310-6bb6-4a99-84d1-826a41643e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in text_1\n",
      "ou Englishmen\", Mr Lewis said, seems to be-that you do not really hate the German\n",
      "not in unhyphenated\n",
      "not in test_words_0\n",
      "not in test_words_1\n",
      "not in test_words_2\n",
      "not in test_words_3\n"
     ]
    }
   ],
   "source": [
    "in_which_texts(\"be-that\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264cccb2-ebb5-4a4d-a994-c8644c49f029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53897a45-fb3e-4395-a12b-a29cf5c8e57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In spell set 0\n",
      "In blob set 0\n",
      "him as William should have been [selfvident] to you Mr Stevens I may\n",
      "In spell set 1\n",
      "In blob set 1\n",
      "him as william should have been [selfvident] to you mr stevens i may\n"
     ]
    }
   ],
   "source": [
    "where_is(\"selfvident\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d0ebfb63-321f-43cd-a4f4-31202565f503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In spell set 0\n",
      "In blob set 0\n",
      "reason in itself why we should [notseek] a more convenient arrangement from here\n",
      "In spell set 1\n",
      "In blob set 1\n",
      "reason in itself why we should [notseek] a more convenient arrangement from here\n"
     ]
    }
   ],
   "source": [
    "where_is(\"notseek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "36dd4602-3dab-4d3d-9996-27b76c066e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In spell set 0\n",
      "In blob set 0\n",
      "Englishmen Mr Lewis said seems to [bethat] you do not really hate the\n",
      "In spell set 1\n",
      "In blob set 1\n",
      "englishmen mr lewis said seems to [bethat] you do not really hate the\n"
     ]
    }
   ],
   "source": [
    "where_is(\"bethat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "14bf637e-3faf-48c3-ae4b-9c6742db1ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In blob set 0\n",
      "father would have wished me to [carryon] just now Of course Mr Stevens\n",
      "In blob set 1\n",
      "father would have wished me to [carryon] just now of course mr stevens\n",
      "In blob  set 2\n",
      "father would have wished me to [carryon] just now Of course Mr Stevens\n",
      "In blob set 3\n",
      "father would have wished me to [carryon] just now of course mr stevens\n"
     ]
    }
   ],
   "source": [
    "where_is(\"carryon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "04a85a1f-382a-435e-8b16-c30439e172ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not in text_1\n",
      "not in unhyphenated\n",
      "in test_words_0\n",
      "that Lord Darlington was liaising covertly [witha] known enemy is just conveniently forgetting\n",
      "in test_words_1\n",
      "that lord darlington was liaising covertly [witha] known enemy is just conveniently forgetting\n",
      "not in test_words_2\n",
      "not in test_words_3\n"
     ]
    }
   ],
   "source": [
    "in_which_texts(\"witha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88f645db-fb91-4cfc-ae14-f4f2e7f5367a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In blob set 0\n",
      "matter we have been debating T [ell] me do you suppose the debt\n",
      "In blob set 1\n",
      "matter we have been debating t [ell] me do you suppose the debt\n",
      "In blob  set 2\n",
      "matter we have been debating T [ell] me do you suppose the debt\n",
      "In blob set 3\n",
      "matter we have been debating t [ell] me do you suppose the debt\n"
     ]
    }
   ],
   "source": [
    "where_is(\"ell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b209389c-cfac-4379-be65-e0e2081115d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in text_1\n",
      "t Lord Darlington was liaising covertly with-a known enemy is just conveniently f\n",
      "not in unhyphenated\n"
     ]
    }
   ],
   "source": [
    "in_which_texts(\"with-a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c804dd7c-5201-453f-9143-26262f3749d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_is(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca8a5e0-b9f2-45b1-8002-4aec58f97d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cee446b7-3e9d-43cd-b0f6-7ed4e242c21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reassurance failings comprised debased anysuch remiss jeopardize banqueting posit carolyn dismissing teas unorthodox hmm imputing motivated idealistic teapot tragically bolshevik throwaway diners badman obsessions facets heretical compton mantelshelf alerted swings confusions assignations driveway kernel benns uncertainly dorset saltash furthering gesturing crosby switching grounding matronly bemused undeniable helston roas oversee analysed contemplating thawed unimaginable yesterdays deterioration nonsensical duplicitous replacements overseeing ladys reversing exeter rapping crudeness reciprocate titled replenish eulogized unnerving trolleys valeting unforgettable ungrammatical advertises irredeemable distinguishedand poplars greyed adjoin begs frogmarched speculations al1 wallpaper bulrushes engagingly needlework investigating implications enthuse reginalds cue morphy canyons reiterate complicit practising inoffensive artistes ostentatious longue herman endearing inwaiting unrealistic inspections correspondents barnets chambermaids whiling avery dammit staffing bemoan insinuations underlining ell shamed mating marvellously besetting allhis briefed homogeneously salisbury trays skills mops foulest farradayscircle deteriorates queries columnist ignition dedication reinstitute applauded convivial intuitively demonstrably matching professionalized nostalgia timer mauvis disembarkation verypleased darlingtons telegrams nostalgic cradled moscombe farradays sightseeing propelling footwear thornley recreating pecking ked daniels observable ofthe crucially seagulls whats silverss posh loverstevens roughing todays dependable floral farraday illuminates meaningfully taylors redding carlisles biased stanbury saucers misguided rolands bareness 0f nuremberg breakages hardacres reminiscing ensured rhythms priorities nellie impractical defeatist unfamiliarity leant propensity corroborated armoury discreetly defensively pronouncement thornton reggie dickenson itinvolved overath manipulating detectable downs uniquely rhododendron inappropriateness camaraderie grahams hitlers encroaching feigning miraculously startseeing judgements conspicuously newt fifties hallway iarrived catherines israther interpreters seehe desks oversights farmyard conciseness ofhand replenishing cansee bridewood beyondsuch housekeepers rosemary martialling sullied comprises steadied glimpsing demise fascists contexts immaterial alcove interviewing promenading carryon cower scepticism untidily sceptical aspiring culpable inhibitions gent unrecognizably fingertip mistreat frustrating surfaced granchester evocative minstrel neighbourss reginald gloriously barbers outings radiator teapots balconies relented bookshelf mortimers flimsy brigid chump practicality objectively streaking compounded everyones permutation grumbles ritz toasted unflattering brigoon destinations weakest smallness procrastinate farmland jacketed thevery morgans bakery wishful bulbs steeply catastrophes niggle explicate zigzags falconing starkness ribbentrop gotto sunlit limelight glamorous civvy dispelling bothered manservants unsure wakeling truest languishing sombrely benn ketteridge chauffeur receptionist unwarranted summerhouse symonss signalling similes fluke mastermind indelible digressing highwayman options splendours accusingly stances finery mothering wer enamoured snobbish karlheinz alarmingly indisputable oswald endlessly wakefield vowel wariness achieving drizzle ruhr whittaker afflicting swallows mans unassaulted eleanor unhurried backbone grandchild hub everythings carlisle canbe respectfulness discounts mystique overstate prise unimagined criteria trespassing nil salacious scholarly neglectful exaggerating ensconced countrys playwright drunker ripple humphreys tankard vouch weightier sheetings snobbery disruptive finalized drunks scupper bolting racy speculate accommodating bremanns hankie unthinking geezer catastrophic humanly aint vintage isall profitably nazis perusing equanimity thickets platter brewed rayne subterfuge mannered harshest unrivalled untypical manoeuvres woken motored perimeter confidentiality plausibly duponts heinz ill1terest specializing inflexions confidences floorboards spencer chalmers excellently bores allocated pleasantries broth vastness alarmist ting dustpan leaven blair unequivocally pastries breakfasted mishap bereavement generational aunts slumped laval workloads diner continentals docrucially bereft abating bungling pantomime suspiciously infirm embodies helpings laundry owardst earful bodyguards documented retrospect puzzles flagstones recipes tractor pointless ifi landscapes unburden assaulting professionals charleville seamus breathtaking waterfalls flourishes pronouncements infact bartender butlers cardinals muggeridge usefully bolsheviks missus intransigent drizzly donalds signpost chock hedgerows giffen jewry divulge ups cornerstone analyses het chainbers sobriety parlous tosit unambiguously clementss banterings infelicity nottake confessing trevor liaisons inconvenienced unrevealing ingrained sloped lordships englands icings humbling driveways andthe unprepared unease climbs bentley gossipers perfected breadknives unswerving shortcoming trends pessimistic unsettling viscount davidson surreptitious hertfordshire debating eulogizing unjustified succinctly landings lindsay thelikes tablecloth eyeing spelt ot aforementioned circuitous pervading mursden eased barnet arbitrator pedigree demonstrativeness exhilaration immodest condolences wended hog wireless impromptu symbolize unvarnished womans londons ludicrousness pres britons pep knowingly briefcase cruelties sheeted tidily promontory chefs outnumbering canonly bygone ludicrously customarily assigning gestured allshot identities figuratively attentiveness chillier amvery seeping guv loughborough prematurely wilkinson eclectic industrialist davids attendances societys giffens blackshirts aspires simplyaccepting ohnothing predictably gentlemens formidably bypass flaked obscuring verged mystified imaginable emulate scheduled larder dh stridency inescapable woefully pavements nuance spoilt cleaners spotting residency studiously stuttered overawed commitments backgrounds jackpot steeple exemplify fop modicum symons hedgerow liaising steering irresponsibly sympathizes motivations hotting joness lewiss dorchester repercussions electrification manoeuvred mediocre fulcrum analysing hovering citys amateurs slated raggedly exhilaratingly embarking friendsand perspectives glimpsed impersonations sensed branbury preoccupy taunton touring leonard somebodys bernard broach polishing tankards rota unperturbed jamess marvelling ploy commiserations tiring resonated vexes celts ploughmans fracas chambermaid mandrake discernment lto stoked semitic disembark chinaman unambiguous tiredly tensions critically consorted wakefields downpour devon lookingback banquets congenia1 footbridge misspelt gentlemans unpredictable silvers bremann avoidable billiard attach vident noises largeness dupont underwent batmans solemnness herring terming grocery anybodys hindsight ribbentrops tavistock henderson humouredness contingency semitism charless oclock remotely mosley awesome allegations ican incongruously strategies sulkily footpath professionalism villagesir retrace colouring lotyou surpass libel frustrations chinamen irrelevance kentons inebriated reappraising encyclopedias remuneration istrue maynard inhibited unburdensome rhineland tiles headlines recollecting trimmings savour prongs amateurism motoring tj1e frau olympic viewpoints heres hates discomforting sandwiches mindless bestowing prerequisite icing conjurors outmoded celebratory focusing schoolboys presumed idealism putout interminably slovenliness keynes aspire latters acquaintanceship fancifully pressures clements reminisce trickster positioned poplar moorland agre dignitys witnessing confidentia1 underestimating anothers sleights preoccupying harrys vendetta pertinent attributable cockerel daunting circumvent camberley emptily specia1 teen dependability infuriatingly manoeuvring arec loc victorian floutings annexe contemplatin8 orchestrate insinuation pandemonium inhabits reconsidering shrubs monocle hitler saltman ineffectuality wetherby kenton mosleys\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(' '.join(word for word in blob_set_3))\n",
    "# display_words_in_context(test_words_2, spell_only_2 - spell_only_1, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a5d6e9f0-c4c1-4ec3-bc7f-617d8a803e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "0f agre al1 allhis allshot amvery andthe anysuch arec avery badman beyondsuch canbe canonly cansee carryon chainbers civvy confidentia1 congenia1 contemplatin8 dh disembarkation distinguishedand docrucially ell farradayscircle friendsand giffen gotto het iarrived ican ifi ill1terest infact inwaiting isall israther istrue itinvolved ked laval loc lookingback lotyou loverstevens lto mauvis mursden neighbourss nottake ofthe ohnothing ot overath owardst posit pres prise putout roas seehe simplyaccepting specia1 startseeing terming thelikes thevery ting tj1e tosit verypleased vident wakeling wer\n"
     ]
    }
   ],
   "source": [
    "#copy and extract the ones that could be real errors, paste them back here\n",
    "errors_raw = \"anysuch posit badman roas distinguishedand al1 inwaiting avery ell allhis farradayscircle mauvis disembarkation verypleased ked ofthe loverstevens 0f itinvolved overath startseeing iarrived israther seehe cansee beyondsuch carryon neighbourss thevery gotto civvy wakeling wer canbe prise isall ill1terest ting laval docrucially owardst ifi infact giffen het chainbers tosit nottake andthe thelikes ot mursden pres canonly allshot amvery simplyaccepting ohnothing dh friendsand lto lookingback congenia1 vident terming ican lotyou istrue tj1e putout agre confidentia1 specia1 arec loc contemplatin8\"\n",
    "errors_raw = errors_raw.split()\n",
    "errors_raw = sorted(errors_raw)\n",
    "print(len(errors_raw))\n",
    "print (' '.join(errors_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9b4aa277-d8bd-49f5-b316-87dbb578d997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "errors_found = (word for word in errors_raw if is_word_in_text(text_1, word))\n",
    "errors_found = sorted(errors_found)\n",
    "print(len(errors_found))\n",
    "errors_not_found = [word for word in errors_raw if word not in errors_found]\n",
    "print(len(errors_not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a1efa85a-e315-4c96-9a5b-b0275776e3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house in [allshot] oxfordshire clearly\n",
      "sir james [chainbers] a good\n",
      "relieved way [dh] mr stevens\n",
      "rich as [distinguishedand] in my\n",
      "now mr [farradayscircle] naturally being\n",
      "firm of [giffen] and co\n",
      "was that [iarrived] here at\n",
      "agreement but [ican] say for\n",
      "forgive me [ifi] were to\n",
      "this cottage [infact] as i\n",
      "of ladies [inwaiting] and footmen\n",
      "he put [itinvolved] in overseeing\n",
      "was m [laval] really intending\n",
      "rather a [lotyou] see it\n",
      "a nature [loverstevens] he said\n",
      "essential then [lto] keep ones\n",
      "sir reginald [mauvis] remarking that\n",
      "village of [mursden] perhaps mursden\n",
      "thirties mr [neighbourss] name seemed\n",
      "mr stevens [ohnothing] in particular\n",
      "stevens baron [overath] old friend\n",
      "from being [putout] i felt\n",
      "up at [tj1e] end of\n",
      "stature lord [wakeling] lord camberley\n"
     ]
    }
   ],
   "source": [
    "display_words_in_context(test_words_3, errors_not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b8f90671-5efe-4e64-a929-d636916a7063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allshot chainbers dh distinguishedand farradayscircle giffen iarrived ican ifi infact inwaiting itinvolved laval lotyou loverstevens mauvis mursden neighbourss ohnothing overath tj1e wakeling wer\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(errors_not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1339a2ee-2763-4ac3-8225-8a0c396cc3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allshot chainbers dh distinguishedand farradayscircle giffen iarrived ican ifi infact inwaiting itinvolved laval lotyou loverstevens lto mauvis mursden neighbourss ohnothing overath putout tj1e wakeling\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(errors_not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e2be6a7e-efd8-48e0-b70e-93ffdb7de480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "suggestions = \"Allshot Chainbers dh distinguished,and Farraday'scircle Giffen Iarrived Ican ifI in-fact in-waiting it,involved Laval lot,you lover,Stevens Mauvis Mursden Neighbours's oh,nothing Overath put,out Tj1e Wakeling\"\n",
    "suggestions = suggestions.split(' ')\n",
    "suggestions_found = (word for word in suggestions if is_word_in_text(text_1, word))\n",
    "suggestions_found = sorted(suggestions_found)\n",
    "print(len(suggestions_found))\n",
    "suggestions_not_found = [word for word in suggestions if word not in suggestions_found]\n",
    "print(len(suggestions_not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7cdd8431-547c-4c21-b65b-6709e96f7ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to raise the very topic for she said in something of a relieved way [dh] mr stevens it is just someone i knew once when i was at granchester\n",
      "the society did not regard the houses of businessmen or the newly rich as [distinguishedand] in my opinion this piece of out dated thinking crucially undermined any serious authority\n",
      "what else you could do at this hour the wife would never forgive me [ifi] were to let you away into the night thus it was that i came\n",
      "the whole village was aware of my mishap and subsequent arrival at this cottage [infact] as i was soon to discover this was very close to being the case\n",
      "little reason to be oh what things in particular do you mean mr stevens [ohnothing] in particular mrs benn oh mr stevens you really must tell me well for\n",
      "been initially so preoccupied with the peace treaty when it was drawn up at [tj1e] end of the great war and i think it is fair to say that\n",
      "mr marshall and mr lane have served only gentlemen of indisputable moral stature lord [wakeling] lord camberley sir leonard gray and one cannot help get the impression that they\n"
     ]
    }
   ],
   "source": [
    "for error, suggestion in zip(errors_not_found, suggestions):\n",
    "    if suggestion not in suggestions_found:\n",
    "        display_words_in_context(test_words_3, [error], window = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cafc94-4776-4689-9fd8-274c9bd0bc04",
   "metadata": {},
   "source": [
    "For the ones that can't be found, search for some of the text window, making sure it's a bit that won't have capitals or punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "956d7978-e324-4eb2-8675-b3478ab1512b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "said in something of a relieved way\n",
      "did not regard the houses of businessmen\n",
      "let you away into the night\n",
      "subsequent arrival at this cottage\n",
      "little reason to be\n",
      "indebted for the hospitality\n",
      "peace treaty when it was drawn up\n"
     ]
    }
   ],
   "source": [
    "search = list()\n",
    "search.append(\"said in something of a relieved way\")\n",
    "search.append(\"did not regard the houses of businessmen\")\n",
    "search.append(\"let you away into the night\")\n",
    "search.append(\"subsequent arrival at this cottage\")\n",
    "search.append(\"little reason to be\")\n",
    "search.append(\"indebted for the hospitality\")\n",
    "search.append(\"peace treaty when it was drawn up\")\n",
    "for snippet in search: print(snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4fdc5689-a242-4e21-93e4-3378f7488bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it was almost as though she had been long awaiting an opportunity to raise the very topic. For she said in something of a relieved way: \"Dh, Mr Stevens, it is just someone I knew once when I was at G\n",
      "f is far from sufficient to satisfy requirements.' It was made clear, furthermore, that the Society did not regard the houses of businessmen or the 'newly rich' as 'distinguished',and in my opinion thi\n",
      "r, I do not know what else you could do at this hour. The wife would never forgive me if'-I were to let you away into the night.\" Thus it was that I came to accept the kind hospitality of Mr and Mrs T\n",
      "ld stop by.\" The way he said this seemed to suggest the whole village was aware of my 'mishap' and subsequent arrival at this cottage. Infact, as I was soon to discover, this was very close to being t\n",
      "rtain things you wrote in your letter. I was a little worried when I read them, but I see now I had little reason to be.\" \"Oh? What things in particular do you mean, Mr Stevens?\" \"Oh,nothing in parti\n",
      "as he termed it. In any case, I replied with a smile that far from being 'putout', I felt extremely indebted for the hospitality I was receiving. By this I had of course been referring to Mr and Mrs Ta\n",
      " from some three years or so before. As I recall, he had not been initially so preoccupied with the peace treaty when it was drawn up at tJ1e end of the Great War, and I think it is fair to say that hi\n"
     ]
    }
   ],
   "source": [
    "for snippet in search:\n",
    "    display_text_in_context(text_1, [snippet], window = 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aabcc5a-cfc9-4d2b-b825-c6530bac25f0",
   "metadata": {},
   "source": [
    "Now redo the suggestions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "58ee9c14-2ccf-42aa-959d-ea170998458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dh', 'distinguished,and', 'ifI', 'in-fact', 'oh,nothing', 'put,out', 'Tj1e']\n"
     ]
    }
   ],
   "source": [
    "print(suggestions_not_found)\n",
    "#paste below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c8e69c0f-40b3-4148-a334-ba40d1334bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_suggestions = ['Dh', \"'distinguished',and\", \"if'-I\", 'Infact', 'Oh,nothing', \"'putout'\", 'tJ1e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "31464c06-fda9-49a2-8655-0805eccabdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for suggestion in new_suggestions:\n",
    "    if suggestion not in text_1:\n",
    "        print(suggestion, \" still not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2be1c07d-52d8-46d3-9abf-0394286cc9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "53 69\n",
      "76 76\n"
     ]
    }
   ],
   "source": [
    "errors = errors_found[:]\n",
    "print(len(errors_found), len(errors))\n",
    "\n",
    "\n",
    "errors.extend(suggestions_found)\n",
    "\n",
    "print(len(errors_found), len(errors))\n",
    "errors.extend(new_suggestions)\n",
    "\n",
    "print(len(errors_raw), len(errors))\n",
    "# These two should be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ebdfb1a6-b443-4059-ac70-779298cc5579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0f', 'agre', 'al1', 'allhis', 'amvery', 'andthe', 'anysuch', 'arec', 'avery', 'badman', 'beyondsuch', 'canbe', 'canonly', 'cansee', 'carryon', 'civvy', 'confidentia1', 'congenia1', 'contemplatin8', 'disembarkation', 'docrucially', 'ell', 'friendsand', 'gotto', 'het', 'ill1terest', 'isall', 'israther', 'istrue', 'ked', 'loc', 'lookingback', 'nottake', 'ofthe', 'ot', 'owardst', 'posit', 'pres', 'prise', 'roas', 'seehe', 'simplyaccepting', 'specia1', 'startseeing', 'terming', 'thelikes', 'thevery', 'ting', 'tosit', 'verypleased', 'vident', 'wer', 'Allshot', 'Chainbers', \"Farraday'scircle\", 'Giffen', 'Iarrived', 'Ican', 'Laval', 'Mauvis', 'Mursden', \"Neighbours's\", 'Overath', 'Wakeling', 'in-waiting', 'it,involved', 'lot,you', 'lover,Stevens', 'Dh', \"'distinguished',and\", \"if'-I\", 'Infact', '.lto', 'Oh,nothing', \"'putout'\", 'tJ1e']\n"
     ]
    }
   ],
   "source": [
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9640da30-ec4f-40b0-a6b6-4e9f130f33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paste the output below to make the corrections dictionary using the display as reference. If the word is ok, just delete the line instead instead of making a correction\n",
    "#We will do this in chunks to save having to do lots of scrolling\n",
    "\n",
    "def split_up(lst, chunk_size=10):\n",
    "    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bc742dc8-cf04-47d0-bc0c-c97944c65a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "eab2821e-38d4-4e18-8c7a-2b9cda70f48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chunks =  8  (including 0)\n"
     ]
    }
   ],
   "source": [
    "chunks = split_up(errors)\n",
    "print(\"number of chunks = \", len(chunks), \" (including 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d9292b31-b5ac-4632-84f1-b0fa5d92b2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrections[\"0f\"] = \"0f\"\n",
      "corrections[\"agre\"] = \"agre\"\n",
      "corrections[\"al1\"] = \"al1\"\n",
      "corrections[\"allhis\"] = \"allhis\"\n",
      "corrections[\"amvery\"] = \"amvery\"\n",
      "corrections[\"andthe\"] = \"andthe\"\n",
      "corrections[\"anysuch\"] = \"anysuch\"\n",
      "corrections[\"arec\"] = \"arec\"\n",
      "corrections[\"avery\"] = \"avery\"\n",
      "corrections[\"badman\"] = \"badman\"\n",
      "\n",
      "\n",
      " days when you could act put of your noble instincts are over. Except 0f course, you here in Europe do not yet seem to know it. Gentlemen like\n",
      "buting only statements such as, 'Of course, Mr Stevens,' or, 'I quite agre, Mr Stevens,' I finally said to her:\n",
      "\n",
      "\n",
      "\"I am sorry, Miss Kenton, but \n",
      " outlining just what this gentleman has been saying to me - about you al1. And with a most clumsy technique, the audacity and crudeness of whic\n",
      "oubt that a desire to see 'justice in this world' lay at the heart of allhis actions.\n",
      "\n",
      "It was not long after that evening there came the sad news \n",
      " Have a go, mate.\"\n",
      "\n",
      "\"Oh dear, no, thank you, it is quite all right. I amvery sorry, I am afraid the travelling has tired me. I am very sorry.\"\n",
      "\n",
      "\"Y\n",
      " of a whole series of such 'unofficial' meetings between Lord Halifax andthe German Ambassador of that time, Herr Ribbentrop. But on that first ni\n",
      "ns back in Berlin?\"\n",
      "\n",
      "\"I am sorry, sir, I am afraid I have not noticed anysuch development.\"\n",
      "\n",
      "\"But I suppose you would not, Stevens, because you are\n",
      "ld. If that is the 'professionalism' you refer to, sir, I do not much arec for it and have no wish to acquire it.\"\n",
      "\n",
      "This was met by the loudest \n",
      "man - I will merely call him 'M. Dupont' - to attend the gathering on avery strict 'off the record' basis, the date for the conference was set. T\n",
      "ched to him, mate.\"\n",
      "\n",
      "\"Lord Darlington was not a bad man. He was not a badman at all. And at least he had the privilege of being able to say at the\n"
     ]
    }
   ],
   "source": [
    "chunk = 0\n",
    "for error in chunks[chunk]:\n",
    "    print('corrections[\"'+error+'\"] = \"'+error+'\"')\n",
    "print(\"\\n\")\n",
    "for error in chunks[chunk]:\n",
    "    find_word_in_text(text_1, error, window=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "53fae1b8-23bf-44f1-95c0-6e39829ee442",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections[\"0f\"] = \"of\"\n",
    "corrections[\"agre,\"] = \"agree,\"\n",
    "corrections[\"al1\"] = \"all\"\n",
    "corrections[\"allhis\"] = \"all his\"\n",
    "corrections[\"amvery\"] = \"am very\"\n",
    "corrections[\"andthe\"] = \"and the\"\n",
    "corrections[\"anysuch\"] = \"any such\"\n",
    "corrections[\"arec\"] = \"care\"\n",
    "corrections[\"avery\"] = \"a very\"\n",
    "corrections[\"badman\"] = \"bad man\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4aee7c85-a40b-4d29-84de-a9eac5797045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrections[\"beyondsuch\"] = \"beyondsuch\"\n",
      "corrections[\"canbe\"] = \"canbe\"\n",
      "corrections[\"canonly\"] = \"canonly\"\n",
      "corrections[\"cansee\"] = \"cansee\"\n",
      "corrections[\"carryon\"] = \"carryon\"\n",
      "corrections[\"civvy\"] = \"civvy\"\n",
      "corrections[\"confidentia1\"] = \"confidentia1\"\n",
      "corrections[\"congenia1\"] = \"congenia1\"\n",
      "corrections[\"contemplatin8\"] = \"contemplatin8\"\n",
      "corrections[\"disembarkation\"] = \"disembarkation\"\n",
      "\n",
      "\n",
      "s suit and his shirt and run about screaming. In a word, 'dignity' is beyondsuch persons. We English have an important advantage over foreigners in th\n",
      "arry Smith that one's 'dignity' is conditional on being able to do so canbe seen for the nonsense it is. Let us establish this quite clearly: a b\n",
      "nguished household is a prerequisite of 'greatness'. A 'great' butler canonly be, surely, one who can point to his years of service and say that he\n",
      "ys, it is too misty and it is like it is vanished altogether. But you cansee for yourself, on a fine day like this, it is a nice sight. \"\n",
      "\n",
      "\"Deligh\n",
      "ust at this moment. You see, I know my father would have wished me to carryon just now.\"\n",
      "\n",
      "\"Of course, Mr Stevens.\"\n",
      "\n",
      "\"To do otherwise, I feel, would\n",
      "learnt any of that myself, you see. I am just a plain old batman gone civvy.\"\n",
      "\n",
      "He then asked me where it was I was employed, and when I told him \n",
      " this evening. Special?\"\n",
      "\n",
      "\"Afraid I cannot tell you, my boy. Strictly confidentia1.\"\n",
      "\n",
      "\"Oh dear. I suppose this means I should not sit in on it.\"\n",
      "\n",
      "\"Sit i\n",
      "So you found them an engaging bunch, eh?\"\n",
      "\n",
      "\"Indeed, Doctor. Extremely congenia1.\"\n",
      "\n",
      "\"So what were they all telling you about last night? Hope they did\n",
      "itting here on this bench. And so I have done for the past half-hour, contemplatin8 the progress of the various figures seated quietly with their fishing\n",
      "d not reply, but continued to stand there silently, neither demanding disembarkation nor offering any clue as to his desires or intentions. I can well ima\n"
     ]
    }
   ],
   "source": [
    "chunk = 1\n",
    "for error in chunks[chunk]:\n",
    "    print('corrections[\"'+error+'\"] = \"'+error+'\"')\n",
    "print(\"\\n\")\n",
    "for error in chunks[chunk]:\n",
    "    find_word_in_text(text_1, error, window=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "99d50325-f953-4e34-9c05-bde178c9d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections[\"beyondsuch\"] = \"beyond such\"\n",
    "corrections[\"canbe\"] = \"can be\"\n",
    "corrections[\"canonly\"] = \"can only\"\n",
    "corrections[\"cansee\"] = \"can see\"\n",
    "corrections[\"carryon\"] = \"carry on\"\n",
    "corrections[\"civvy\"] = \"civvy\"\n",
    "corrections[\"confidentia1\"] = \"confidential\"\n",
    "corrections[\"congenia1\"] = \"congenial\"\n",
    "corrections[\"contemplatin8\"] = \"contemplating\"\n",
    "corrections[\"disembarkation\"] = \"disembarkation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "aa0c0ac7-884f-4b17-af77-0b294db4d1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrections[\"docrucially\"] = \"docrucially\"\n",
      "corrections[\"ell\"] = \"ell\"\n",
      "corrections[\"friendsand\"] = \"friendsand\"\n",
      "corrections[\"gotto\"] = \"gotto\"\n",
      "corrections[\"het\"] = \"het\"\n",
      "corrections[\"ill1terest\"] = \"ill1terest\"\n",
      "corrections[\"isall\"] = \"isall\"\n",
      "corrections[\"israther\"] = \"israther\"\n",
      "corrections[\"istrue\"] = \"istrue\"\n",
      "corrections[\"ked\"] = \"ked\"\n",
      "\n",
      "\n",
      "f what true 'dignity' is. And let me now posit this: 'dignity' has to docrucially with a butler's ability not to abandon the professional being he inha\n",
      " you.\n",
      "\n",
      "We need your help on a certain matter we have been debating. T ell me, do you suppose the debt situation regarding America is a signific\n",
      "you are referring to.\"\n",
      "\n",
      "\"You do not understand, Stevens. Well, we are friendsand so I will put it to you frankly. Over the last few years, his lordshi\n",
      "ll as you used to. But it is the same for all of us, see? We have all gotto put our feet up at some point. Look at me. Been happy as a lark since\n",
      "ll you the truth, we do not miss it so much. There is a few houses in het village that is never had electricity at all. Oil gives a warmer ligh\n",
      "he better because he is sincere and honourable and does not recognize het true nature of what he is doing. During the last three years alone, h\n",
      "\" There was a murmur of .approval. M. Dupont went on: \"Many things of ill1terest have been said in this house over the\n",
      "\n",
      "\n",
      "past days. Many important thi\n",
      "yly, but went on:\n",
      "\n",
      "\"I am not talking politics. I am just saying, that isall. You cannot have dignity if you are a slave. But every Englishman can\n",
      "rst time in many a year, I am able to take my time and I must say, it israther an enjoyable experience. I am just motoring for the pleasure of it, y\n",
      "is merely a means of pre-empting any 'problems' before one arises. It istrue, these same trivial errors did cause me some anxiety at first, but on\n",
      ", that he said:\n",
      "\n",
      "\"You realize, Stevens, I do not expect you to be loc ked up here in this house all the time I am away. Why do not you take the\n"
     ]
    }
   ],
   "source": [
    "chunk = 2\n",
    "for error in chunks[chunk]:\n",
    "    print('corrections[\"'+error+'\"] = \"'+error+'\"')\n",
    "print(\"\\n\")\n",
    "for error in chunks[chunk]:\n",
    "    find_word_in_text(text_1, error, window=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "101abf2e-11eb-45e3-aa22-d1ca284d9cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections[\"docrucially\"] = \"do crucially\"\n",
    "corrections[\"T ell\"] = \"Tell\"\n",
    "corrections[\"friendsand\"] = \"friends and\"\n",
    "corrections[\"gotto\"] = \"got to\"\n",
    "corrections[\"het\"] = \"the\"\n",
    "corrections[\"ill1terest\"] = \"interest\"\n",
    "corrections[\"isall\"] = \"is all\"\n",
    "corrections[\"israther\"] = \"is rather\"\n",
    "corrections[\"istrue\"] = \"is true\"\n",
    "corrections[\"loc ked\"] = \"locked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6769a6d1-64f9-49a4-a6ff-d321106380b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrections[\"loc\"] = \"loc\"\n",
      "corrections[\"lookingback\"] = \"lookingback\"\n",
      "corrections[\"lto\"] = \"lto\"\n",
      "corrections[\"nottake\"] = \"nottake\"\n",
      "corrections[\"ofthe\"] = \"ofthe\"\n",
      "corrections[\"ot\"] = \"ot\"\n",
      "corrections[\"owardst\"] = \"owardst\"\n",
      "corrections[\"posit\"] = \"posit\"\n",
      "corrections[\"pres\"] = \"pres\"\n",
      "corrections[\"prise\"] = \"prise\"\n",
      "\n",
      "\n",
      "t me, that he said:\n",
      "\n",
      "\"You realize, Stevens, I do not expect you to be loc ked up here in this house all the time I am away. Why do not you take\n",
      "was, in the truest terms, 'attached to a distinguished household'. In lookingback over my career thus far, my chief satisfaction derives from what I ac\n",
      "w all that is best about service in England. It is essential, then,\n",
      "\n",
      ".lto keep one's attention focused on the present; to guard against any com\n",
      "nd rather rough.\n",
      "\n",
      "\"I am telling you, sir, you will be sorry if you do nottake a walk up there. And you never know. A couple more years and it might\n",
      "m - a venue chosen to accommodate the 'off the record' nature of many ofthe attendances. In fact, to my eyes, the appearance of informality had b\n",
      "erely went on: \"I mean it, Stevens. It is wrong that a man cannot get ot see around his own country. Take my advice, get out the house for a f\n",
      "teps separated, his lordship's going towards his study, Mr Cardinal's owardst the library.\n",
      "\n",
      "At almost precisely eight thirty, there came the sound \n",
      "n this story lay the kernel of what true 'dignity' is. And let me now posit this: 'dignity' has to docrucially with a butler's ability not to aba\n",
      " judgements of this sort. But should it be that anyone ever wished to posit that I have attained at least a little of that crucial quality of 'di\n",
      "terrible misunderstanding on the Prime Minister's part concerning the pres en t German regime.\"\n",
      "\n",
      "\"I cannot see what there is to object to in tha\n",
      "y at a somewhat unnatural angle. Miss Kenton continued very gently to prise the book away, practically one finger at a time. The process seemed t\n"
     ]
    }
   ],
   "source": [
    "chunk = 3\n",
    "for error in chunks[chunk]:\n",
    "    print('corrections[\"'+error+'\"] = \"'+error+'\"')\n",
    "print(\"\\n\")\n",
    "for error in chunks[chunk]:\n",
    "    find_word_in_text(text_1, error, window=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "67a26ad4-3fcc-4517-84a4-135dd754378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections[\"lookingback\"] = \"looking back\"\n",
    "corrections[\".lto\"] = \"to\"\n",
    "corrections[\"nottake\"] = \"not take\"\n",
    "corrections[\"ofthe\"] = \"of the\"\n",
    "corrections[\"ot\"] = \"to\"\n",
    "corrections[\"owardst\"] = \"towards\"\n",
    "corrections[\"posit\"] = \"posit\"\n",
    "corrections[\"pres en t\"] = \"present\"\n",
    "corrections[\"prise\"] = \"prise\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e520d058-121d-47f7-be8c-36fb14694dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to show all that is best about service in England. It is essential, then, .lto keep one's attention focused on the present; to guard against any compl\n"
     ]
    }
   ],
   "source": [
    "display_text_in_context(text_1, [\".lto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a441d5a8-1720-435d-a692-6c00699a6aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrections[\"putout\"] = \"putout\"\n",
      "corrections[\"roas\"] = \"roas\"\n",
      "corrections[\"seehe\"] = \"seehe\"\n",
      "corrections[\"simplyaccepting\"] = \"simplyaccepting\"\n",
      "corrections[\"specia1\"] = \"specia1\"\n",
      "corrections[\"startseeing\"] = \"startseeing\"\n",
      "corrections[\"terming\"] = \"terming\"\n",
      "corrections[\"thelikes\"] = \"thelikes\"\n",
      "corrections[\"thevery\"] = \"thevery\"\n",
      "corrections[\"ting\"] = \"ting\"\n",
      "\n",
      "\n",
      "e termed it. In any case, I replied with a smile that far from being 'putout', I felt extremely indebted for the hospitality I was receiving. By t\n",
      "Mortimer - or else her apron - the room was dominated by the smell of roas ting.\n",
      "\n",
      "Dr Meredith rose and said: \"My condolences, Stevens. He suffer\n",
      "d the grounds. He was clutching his attach case as usual and I could seehe was strolling slowly along the path that runs the outer perimeter of \n",
      "y intelligently bestowed. What is there 'undignified' in this? One is simplyaccepting an inescapable truth: that the likes of you and I will never be in a \n",
      "d. Oh no, that would not do at all.\"\n",
      "\n",
      "\"Oh, dear. This does sound very specia1.\"\n",
      "\n",
      "Mr Cardinal was watching his lordship very keenly, but the latter \n",
      " begins to search one's past for such 'turning points', one is apt to startseeing them everywhere. Not only\n",
      "\n",
      "\n",
      "my decision in respect of our evening mee\n",
      "o the problem at present besetting us at Darlington Hall. In fact, by terming it a 'problem', I perhaps overstate the matter. I am referring, after\n",
      "scussing the nature of 'greatness' by the fire of our servants' hall, thelikes of Mr Graham and I never considered this whole dimension to the quest\n",
      "urse, a member of Sir Oswald Mosley's 'blackshirts' organization, and thevery little contact his lordship ever had with Sir Oswald occurred during \n",
      "mer - or else her apron - the room was dominated by the smell of roas ting.\n",
      "\n",
      "Dr Meredith rose and said: \"My condolences, Stevens. He suffered a \n",
      "ot say for certain he will be able to call in before you would be wan ting to retire., sir.\"\n",
      "\n",
      "It was then that Mr Harry Smith, the little man wi\n"
     ]
    }
   ],
   "source": [
    "chunk = 4\n",
    "for error in chunks[chunk]:\n",
    "    print('corrections[\"'+error+'\"] = \"'+error+'\"')\n",
    "print(\"\\n\")\n",
    "for error in chunks[chunk]:\n",
    "    find_word_in_text(text_1, error, window=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "365f9f69-ca42-4069-a8e3-217865bd4dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections[\"putout\"] = \"put out\"\n",
    "corrections[\"roas ting\"] = \"roasting\"\n",
    "corrections[\"seehe\"] = \"see he\"\n",
    "corrections[\"simplyaccepting\"] = \"simply accepting\"\n",
    "corrections[\"specia1\"] = \"special\"\n",
    "corrections[\"startseeing\"] = \"start seeing\"\n",
    "corrections[\"terming\"] = \"terming\"\n",
    "corrections[\"thelikes\"] = \"the likes\"\n",
    "corrections[\"thevery\"] = \"the very\"\n",
    "corrections[\"ting\"] = \"ting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "96ac8717-131a-40f2-8000-4b29537854fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrections[\"tosit\"] = \"tosit\"\n",
      "corrections[\"verypleased\"] = \"verypleased\"\n",
      "corrections[\"vident\"] = \"vident\"\n",
      "corrections[\"Allshot\"] = \"Allshot\"\n",
      "corrections[\"Chainbers\"] = \"Chainbers\"\n",
      "corrections[\"Farraday'scircle\"] = \"Farraday'scircle\"\n",
      "corrections[\"Giffen\"] = \"Giffen\"\n",
      "corrections[\"Iarrived\"] = \"Iarrived\"\n",
      "corrections[\"Ican\"] = \"Ican\"\n",
      "corrections[\"Laval\"] = \"Laval\"\n",
      "\n",
      "\n",
      " the lights would be switched on 'fairly soon', and so I have decided tosit down here on this bench and await the event. I have a good view from \n",
      "worth speaking of.\"\n",
      "\n",
      "\"I am not disappointed at all, Miss Kenton. I am verypleased for you and for all of us. I will admit, you have had some modest suc\n",
      "ur age and standing addressing him as 'William' should have been self-vident to you.\"\n",
      "\n",
      "\"Mr Stevens, I may not have been a housekeeper for long, bu\n",
      "tler - to a Mr and Mrs Muggeridge in their relatively modest house in Allshot, Oxfordshire. Clearly the story meant much to him. My father's genera\n",
      " for I remember mentioning it to Mr Graham, valet-butler to Sir James Chainbers - a good colleague who, incidentally, I seem now to have lost touch w\n",
      "y because visitors from Lord Darlington's days are most rare now - Mr Farraday'scircle, naturally, being quite different from his lordship's - but also beca\n",
      "ute just to see the village. Mursden, Somerset, was where the firm of Giffen and Co. was once situated, and it was to Mursden one was required to \n",
      "s to Mursden one was required to dispatch one's order for a supply of Giffen's. dark candles of polish, 'to be flaked, mixed into wax and\n",
      "\n",
      "\n",
      "applie\n",
      " 'to be flaked, mixed into wax and\n",
      "\n",
      "\n",
      "applied by hand'. For some time, Giffen's. was undoubtedly the finest silver polish available, and it was onl\n",
      "earching, I found a signpost to 'Mortimer's Pond', and so it was that Iarrived here at this spot a little over half an hour ago.\n",
      "\n",
      "I now find myself \n",
      "e constitution of this 'dignity'. We never came to any agreement, but Ican say for my part that I developed fairly firm ideas of my own on the m\n",
      "gn policy. My good fellow, please come to our assistance. What was M. Laval really intending, by his recent speech on the situation in North Afri\n"
     ]
    }
   ],
   "source": [
    "chunk = 5\n",
    "for error in chunks[chunk]:\n",
    "    print('corrections[\"'+error+'\"] = \"'+error+'\"')\n",
    "print(\"\\n\")\n",
    "for error in chunks[chunk]:\n",
    "    find_word_in_text(text_1, error, window=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b561c5f5-62ee-4e81-a80d-f01ed48b3e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections[\"tosit\"] = \"to sit\"\n",
    "corrections[\"verypleased\"] = \"very pleased\"\n",
    "corrections[\"self-vident\"] = \"sel-evident\"\n",
    "corrections[\"Allshot\"] = \"Allshot\"\n",
    "corrections[\"Chainbers\"] = \"Chambers\"\n",
    "corrections[\"Farraday'scircle\"] = \"Farraday's circle\"\n",
    "corrections[\"Giffen\"] = \"Giffen\"\n",
    "corrections[\"Iarrived\"] = \"I arrived\"\n",
    "corrections[\"Ican\"] = \"I can\"\n",
    "corrections[\"Laval\"] = \"Laval\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "33938484-623c-4057-9517-03827b620618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrections[\"Mauvis\"] = \"Mauvis\"\n",
      "corrections[\"Mursden\"] = \"Mursden\"\n",
      "corrections[\"Neighbours's\"] = \"Neighbours's\"\n",
      "corrections[\"Overath\"] = \"Overath\"\n",
      "corrections[\"Wakeling\"] = \"Wakeling\"\n",
      "corrections[\"in-waiting\"] = \"in-waiting\"\n",
      "corrections[\"it,involved\"] = \"it,involved\"\n",
      "corrections[\"lot,you\"] = \"lot,you\"\n",
      "corrections[\"lover,Stevens\"] = \"lover,Stevens\"\n",
      "corrections[\"Dh\"] = \"Dh\"\n",
      "\n",
      "\n",
      "ears ago, Mr Rayne, who travelled to America as valet to Sir Reginald Mauvis, remarking that a taxi driver in New York regularly addressed his far\n",
      "eral nearby destinations. One of these destinations is the village of Mursden. Perhaps 'Mursden' will ring a bell for you, as it did for me upon my\n",
      "ations. One of these destinations is the village of Mursden. Perhaps 'Mursden' will ring a bell for you, as it did for me upon my first spotting it\n",
      "o make a slight detour from my planned route just to see the village. Mursden, Somerset, was where the firm of Giffen and Co. was once situated, an\n",
      "is was a typical case. For two or three years in the mid-thirties, Mr Neighbours's name seemed to dominate conversations in every servants' hall in the \n",
      "Hall too, many a visiting employee would bring the latest tales of Mr Neighbours's achievements, so that I and the likes of Mr Graham would have to shar\n",
      " reminder.\"\n",
      "\n",
      "\"Yes, sir.\"\n",
      "\n",
      "\n",
      "\"Last time I was in Berlin, Stevens, Baron Overath, old friend of my father, came up and said: 'Why do you do this to us\n",
      " Lane have served only gentlemen of indisputable moral stature - Lord Wakeling, Lord Camberley, Sir Leonard Gray - and one cannot help get the impre\n",
      "rast in their backgrounds - bringing with them a large team of ladies-in-waiting and footmen, as well as a great many trunks. Then in the afternoon, a\n",
      " the main, I tried to convey to him some of the 'know-how', as he put it,involved in overseeing large events of the sort we used often to have. Indeed,\n",
      " unseemly. I suspect I am over-tired. I have been travelling rather a lot,you see.\"\n",
      "\n",
      "It is now some twenty minutes since the man left, but I have r\n",
      "d held out his glass.\n",
      "\n",
      "\"I think it is admirable that you are a nature-lover,Stevens,\" he said, as I served him. \"And I dare say it is a great advantage t\n",
      " raise the very topic. For she said in something of a relieved way:\n",
      "\n",
      "\"Dh, Mr Stevens, it is just someone I knew once when I was at Granchester\n"
     ]
    }
   ],
   "source": [
    "chunk = 6\n",
    "for error in chunks[chunk]:\n",
    "    print('corrections[\"'+error+'\"] = \"'+error+'\"')\n",
    "print(\"\\n\")\n",
    "for error in chunks[chunk]:\n",
    "    find_word_in_text(text_1, error, window=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5f809e65-ffac-4302-8004-7124b0d4988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections[\"Mauvis\"] = \"Mauvis\"\n",
    "corrections[\"Mursden\"] = \"Mursden\"\n",
    "corrections[\"Neighbours's\"] = \"Neighbours's\"\n",
    "corrections[\"Overath\"] = \"Overath\"\n",
    "corrections[\"Wakeling\"] = \"Wakeling\"\n",
    "corrections[\"in-waiting\"] = \"in-waiting\"\n",
    "corrections[\"it,involved\"] = \"it, involved\"\n",
    "corrections[\"lot,you\"] = \"lot, you\"\n",
    "corrections[\"lover,Stevens\"] = \"lover, Stevens\"\n",
    "corrections[\"Dh\"] = \"Oh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c1f7cebb-2fc9-48f8-a308-0e2c86f0d715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrections[\"'distinguished',and\"] = \"'distinguished',and\"\n",
      "corrections[\"if'-I\"] = \"if'-I\"\n",
      "corrections[\"Infact\"] = \"Infact\"\n",
      "corrections[\"Oh,nothing\"] = \"Oh,nothing\"\n",
      "corrections[\"'putout'\"] = \"'putout'\"\n",
      "corrections[\"tJ1e\"] = \"tJ1e\"\n",
      "\n",
      "\n",
      "ciety did not regard the houses of businessmen or the 'newly rich' as 'distinguished',and in my opinion this piece of out-dated thinking crucially undermined a\n",
      " what else you could do at this hour. The wife would never forgive me if'-I were to let you away into the night.\"\n",
      "\n",
      "Thus it was that I came to acc\n",
      "lage was aware of my 'mishap' and subsequent arrival at this cottage. Infact, as I was soon to discover, this was very close to being the case; I \n",
      "n to be.\"\n",
      "\n",
      "\"Oh? What things in particular do you mean, Mr Stevens?\"\n",
      "\n",
      "\"Oh,nothing in particular, Mrs Benn.\"\n",
      "\n",
      "\"Oh, Mr Stevens, you really must tell me.\"\n",
      "he termed it. In any case, I replied with a smile that far from being 'putout', I felt extremely indebted for the hospitality I was receiving. By th\n",
      "nitially so preoccupied with the peace treaty when it was drawn up at tJ1e end of the Great War, and I think it is fair to say that his interest\n"
     ]
    }
   ],
   "source": [
    "chunk = 7\n",
    "for error in chunks[chunk]:\n",
    "    print('corrections[\"'+error+'\"] = \"'+error+'\"')\n",
    "print(\"\\n\")\n",
    "for error in chunks[chunk]:\n",
    "    find_word_in_text(text_1, error, window=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e2d6f3ce-9ec3-48be-aa4a-a41839043207",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections[\"'distinguished',and\"] = \"'distinguished', and\"\n",
    "corrections[\"if'-I\"] = \"if I\"\n",
    "corrections[\"Infact\"] = \"In fact\"\n",
    "corrections[\"Oh,nothing\"] = \"Oh, nothing\"\n",
    "corrections[\"'putout'\"] = \"'put out'\"\n",
    "corrections[\"tJ1e\"] = \"the\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ef951b73-7f8e-4856-945e-49017d5dfd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any others that were spotted but not yet included\n",
    "corrections[\"notseek\"] = \"not seek\"\n",
    "corrections[\"witha\"] = \"with a\"\n",
    "corrections[\"bethat\"] = \"be that\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "5eefed03-a151-4e35-84a5-066438ebc5e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (1354065872.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[229], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    #print(key)\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# check for potentially erroneous overwrites\n",
    "for key in corrections:\n",
    "    occurrences = is_word_in_text(text_1, key)#print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c54e6ab-1c25-4204-a61d-2ec247912423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5s\n",
      "ons and none of us, not even the Senior 5s, dared make a sound. There was a real\n",
      "becausethey\n",
      "ble about us having sex with each other becausethey would then want to have sex w\n",
      "betweenthem\n",
      " The idea the guardians had differences betweenthem, that never occurred to us.\" \n",
      "bric\n",
      "ut, he put the mags down on top of some bricks stacked outside the boiler hut-som\n",
      "canunzip\n",
      " it is right on the elbow like that, it canunzip. All you have to do is bend your\n",
      "carefulwho\n",
      "y and began telling us how we had to be carefulwho we had sex with. Not just beca\n",
      "coupleshinting\n",
      "of snogging and touching up, maybe; and coupleshinting they were having proper se\n",
      "definitelyhad\n",
      " that two of the girls I was closest to definitelyhad done it. Laura with Rob D.,\n",
      "doi\n",
      "o completing and so that is what he was doing: getting me to describe things to h\n",
      "fromme\n",
      "you do not do it that way! Just take it fromme, you do not do it that way! You de\n",
      "howshe\n",
      "ago. \"None of us stopped to think about howshe felt , Miss Lucy herself. We never\n",
      "itis\n",
      "ardians were not supposed to show favouritism, but there were little displays of \n",
      "itshould\n",
      " old enough,\" Tommy said. \"By that age, itshould have occurred to us. But it did \n",
      "mag\n",
      " was still sitting behind the wheel, rummaging in her briefcase. Eventually she e\n",
      "moulding\n",
      "ou had.\" Ruth had been picking at some moulding flakes of wood on the bench besi\n",
      "neurone\n",
      "friends, did not die from cancer, motor neurone disease, heart disease. So for a \n",
      "reallyfit\n",
      "y: \"But I will be all right, Miss. I am reallyfit, I know how to look after mysel\n",
      "rway\n",
      "rs and loitered just inside the main doorway. We could see out into the bright co\n",
      "saidhello\n",
      "so I did not talk with him long. I just saidhello, that I hoped he would feel bet\n",
      "sostupid\n",
      " I burst out, saying: \"Tommy, you look sostupid, laughing like that! If you want\n",
      "thatwe\n",
      " even though they knew, intellectually, thatwe could not have babies, they still \n",
      "theevening\n",
      "found out first. It was around eight in theevening, I was coming down the main st\n",
      "thendo\n",
      "ou truly wish to share this experience, thendo not!\" But around the spring of the\n",
      "therewas\n",
      "e their faces and their backs. And when therewas a useful scene, it was difficult\n",
      "toomuch\n",
      "e first with a boy I did not care about toomuch. Then later on, if I was with som\n",
      "wasshe\n",
      "ura said that what Annette really meant wasshe wanted to have sex with Mr. Chris.\n",
      "wewere\n",
      "omeone had commandeered all the easels, wewere having to work with our boards pro\n",
      "whatwas\n",
      "in those days, but it was clear by then whatwas a real proposition and what was t\n",
      "whoeverwas\n",
      "ed I was his carer. I looked about, but whoeverwas his carer was not even around.\n",
      "youknow\n",
      " Lucy at all. Not even after that time, youknow, when you saw her.\" I knew strai\n"
     ]
    }
   ],
   "source": [
    "for word in errors_found:\n",
    "    print(word)\n",
    "    display_text_in_context(text_1, [word], window = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed04105a-7a21-4efb-af5c-7d1622d6e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(errors_not_found_2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f42a310-f59c-4958-bade-448cd52686e7",
   "metadata": {},
   "source": [
    "Copy these below and adjust to guess how it would be in the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557a668-694e-4675-b828-f11584e18ee7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527abd3e-b4d9-4ff2-80ee-e2828cb6e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "suggestions = ['alost', 'coupleand', 'cwho', 'itbut', 'Iwould', 'Jeansruth', 'jwho', 'Keffers', 'Kefferss', 'kshed', 'Lauras', 'LPs', 'Metchley', 'Portway', 'shapei', 'virginmeaning', 'Wainright', 'Walkman', 'Walkmans', 'wavecrest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e5c67-6d16-4739-aa28-d1f1b6c043be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(suggestions))\n",
    "suggestions_found = (word for word in suggestions if word in text)\n",
    "suggestions_found = sorted(suggestions_found)\n",
    "print(len(suggestions_found))\n",
    "suggestions_not_found = [word for word in suggestions if word not in suggestions_found]\n",
    "print(len(suggestions_not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724b993a-7fee-4d4b-af9b-900b50500bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(suggestions_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d5566-e830-419e-8505-e53964d369c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22720c25-bb6f-4882-9115-584737dff018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69702a87-b46d-432c-8195-a2d0a2453a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b35bbcd-085f-4e77-a4ec-03437b57a68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb681ce-1a04-40a7-9974-3cb73f317363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffdbcd9-fd40-45fb-9dc5-fab5ba276b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3150d1-1dfe-473e-9324-73614bcdbef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1fe36-5eda-4f7c-935a-74be091c28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = ['0f', 'agre', 'al1', 'allhis', 'andthe', 'anysuch', 'arec', 'avery', 'be-that', 'beyondsuch', 'canbe', 'canonly', 'cansee', 'carryon', 'Chainbers', 'confidentia1', 'contemplatin8', 'Dh', \"'distinguished',and\", 'docrucially', \"don'ttake\", 'T ell', \"Farraday'scircle\", 'friendsand', 'gotto', 'het', 'Iarrived', 'Ican', \"if'-I\", 'ill1terest', \"I'mvery\", 'Infact', 'istrue', 'it,involved', \"it'srather\", 'loc ked', 'lookingback', 'lot,you', 'lover,Stevens', 'lto', 'not-seek', 'ofthe', 'Oh,nothing', 'ot', 'owardst', 'putout', 'roas ting', 'seehe', 'self-vident', 'simplyaccepting', 'startseeing', \"that'sall\", 'thelikes', 'thevery', 'tJ1e', 'tosit', 'verypleased', 'village,sir', 'wer', 'with-a']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849252c9-d58e-47e8-866e-6b76e280fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce82d10c-1a4e-4082-a4c6-d2ab2284c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"distinguishedand\" in errors_raw)\n",
    "print(\"distinguishedand\" in errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f880158-9c22-4145-ac51-934cf1c030d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_tt == errors_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e946ebd0-75f3-4083-a3a9-7bc4838484e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = ['of', 'agree', 'all', 'all his', 'and the', 'any such', 'care', 'a very', 'be that', 'beyond such', 'can be', 'can only', 'can see', 'carry on', 'Chambers', 'confidential', 'contemplating', 'Oh', \"'distinguished', and\", 'do crucially', \"don't take\", 'Tell', 'Farradays Circle', 'friends and', 'got to', 'the', 'I arrived', 'I can', 'if I', 'interest', \"I'm very\", 'In fact', 'is true', 'it involved', \"its rather\", 'locked', 'looking back', 'lot, you', 'lover, Stevens', 'to', 'not seek', 'of the', 'Oh, nothing', 'to', 'towards', 'put out', 'roasting', 'see he', 'self-evident', 'simply accepting', 'start seeing', \"that's all\", 'the likes', 'the very', 'the', 'to sit', 'very pleased', 'village, sir', 'were', 'with a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85f2e9-3c4e-42b8-bef6-115f9bde36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_1 = set(errors_tt)\n",
    "set_2 = set(errors)\n",
    "print(len(set_1), len(set_2))\n",
    "print(set_1 - set_2)\n",
    "print(set_2 - set_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675990c1-ceac-44b5-8265-475c9c1225ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_spell_1 = 0\n",
    "counter_spell_2 = 0\n",
    "counter_spell_3 = 0\n",
    "counter_blob_1 = 0\n",
    "counter_blob_2 = 0\n",
    "counter_blob_3 = 0\n",
    "\n",
    "for word in errors_tt:\n",
    "    if word in spell_set_1: counter_spell_1 += 1 \n",
    "    if word in spell_set_2: counter_spell_2 += 1\n",
    "    if word in spell_set_3: counter_spell_3 += 1\n",
    "    if word in blob_set_1: counter_blob_1 += 1\n",
    "    if word in blob_set_2: counter_blob_2 += 1\n",
    "    if word in blob_set_3: counter_blob_3 += 1\n",
    "print (counter_spell_1, counter_spell_2, counter_spell_3)\n",
    "print (counter_blob_1, counter_blob_2, counter_blob_3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585b2c0-381e-430d-ae1c-9ecd431b7eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in errors_tt:\n",
    "    if word not in blob_set_3: print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce725f-7094-4cba-9323-19ae8198fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_spell_1 = 0\n",
    "counter_spell_2 = 0\n",
    "counter_spell_3 = 0\n",
    "counter_blob_1 = 0\n",
    "counter_blob_2 = 0\n",
    "counter_blob_3 = 0\n",
    "\n",
    "for word in errors:\n",
    "    if word in spell_set_1: counter_spell_1 += 1 \n",
    "    if word in spell_set_2: counter_spell_2 += 1\n",
    "    if word in spell_set_3: counter_spell_3 += 1\n",
    "    if word in blob_set_1: counter_blob_1 += 1\n",
    "    if word in blob_set_2: counter_blob_2 += 1\n",
    "    if word in blob_set_3: counter_blob_3 += 1\n",
    "print (counter_spell_1, counter_spell_2, counter_spell_3)\n",
    "print (counter_blob_1, counter_blob_2, counter_blob_3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5700764-b25f-4aa7-a2da-a01a80437a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(errors_raw), len(errors), len(corrections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e3787-ea20-41dc-9f62-9c52bac4de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(corrections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb6328-63c2-4fdb-a2aa-035c0c21aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for error, correction in zip(errors, corrections):\n",
    "    if error == correction:\n",
    "        display_words_in_context(test_words_3, [error], False, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b90b91-cb83-4a82-8cfd-7530e5b1e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in errors:\n",
    "    if word not in text:\n",
    "        display_words_in_context(test_words_3, [word], False, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7319fa11-3b46-49b0-aa44-fd3cb74b62ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_text_in_context(text, [\"never forgive me\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bdd1cb-bb9b-46b8-ad5a-0f59c55dd11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([word in blob_set_3 for word in errors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b3ecf-0cb8-4c0f-a405-964c1627d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_is(\"bethat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862b4c56-a27d-4a8b-9e7a-818b58ea0acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"be that\" in corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e443ecc-2096-4217-8b15-74f54e935e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"allshot\" in both_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac2a16-7bd1-4897-ba5a-7577905fa458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d72464-2574-40df-9f36-ffb4b7a10957",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_text_in_context(text,[\"ell\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472945e-1b91-4232-b84f-b0475f868997",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {error: correction for error, correction in zip (errors, corrections)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee09f4-ed5a-4c5f-b4af-69068856abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(replacements[\"with-a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eec50fa-f189-4614-9c82-7ae26dfffef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(word for word in (blob_only_2 - blob_only_1)))\n",
    "display_words_in_context(test_words_2, blob_only_2 - blob_only_1, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce6245-245f-4485-a247-9c51944a1c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(word for word in (spell_only_3 - spell_only_2 - spell_only_1)))\n",
    "display_words_in_context(test_words_3, spell_only_3 - spell_only_2 - spell_only_1, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a20f68-d116-4d08-8742-47a8861c7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(word for word in (blob_only_3 - blob_only_2 - blob_only_1)))\n",
    "display_words_in_context(test_words_3, blob_only_3 - blob_only_2 - blob_only_1, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c5c1a-765d-4437-9779-ad2e660470f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf4cf3b-7ae6-4e23-a7a0-31697822a7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc6279f-1709-454e-ac5b-7ac43b78c086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57df1d8-6fcc-4357-9728-f5db60e255c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec8f3a-dde0-4ada-8a9a-53d314943e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd26866-fded-4a8d-bdad-6a0fb5331212",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for word in blob_set_2:\n",
    "    if word.lower() in blob_set_3:\n",
    "        print(f\"{word} in both\")\n",
    "        print(Word(word).spellcheck())\n",
    "        if word != word.lower():\n",
    "            print(Word(word.lower()).spellcheck())\n",
    "    else:\n",
    "        print (f\"{word} in 2 but not in 3\")\n",
    "        print(Word(word).spellcheck())\n",
    "    print(\"\\n\")    \n",
    "    counter = counter + 1\n",
    "    if counter > 15: break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed2fbb-f5a0-4bb1-b393-16de31da9166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da527b-568f-4896-8e01-68b7ed48a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = \"istrue canbe im tj1e overath laval itsrather wer silverss gotto thelikes ifi 0f prise ritz ofthe andthe lto lookingback al1 verypleased het thevery agre bethat seehe ot selfvident sleightsofhand cansee thatsall distinguishedand villagesir docrucially arec farradayscircle witha canonly barnets redding tosit clementss newtmating ill1terest anysuch dh lewiss donttake allhis contemplatin8 startseeing symons owardst imvery simplyaccepting selftraining wellcontented evercourteous donttake allhis lastminute civvy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0454a-fb4a-4054-94ac-24de224ee2da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d7a7e-1d51-498e-ab10-07a65049dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words=[\"ohnothing\", \"iarrived\", \"friendsand\", \"allshot\"]\n",
    "for word in bad_words:\n",
    "    print(word in errors_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cadc7-565c-497d-8a01-72d61ed4fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions_split = suggestions.split(' ')\n",
    "suggestions_sorted = sorted(suggestions_split)\n",
    "print(suggestions_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09427cc1-f405-4464-b6be-7fc259bd2fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_sorted = sorted(errors_split)\n",
    "print (errors_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d103da-705d-42d8-8f44-317d466de1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in bad_words:\n",
    "    errors_split.append(word)\n",
    "print(errors_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65371496-ddd5-4dc9-b53e-54a08b580303",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff9a19-380e-4acc-9650-a975353dca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_split = ['istrue', 'canbe', 'im', 'tj1e', 'overath', 'laval', 'itsrather', 'wer', 'silverss', 'gotto', 'thelikes', 'ifi', '0f', 'prise', 'ritz', 'ofthe', 'andthe', 'lto', 'lookingback', 'al1', 'verypleased', 'het', 'thevery', 'agre', 'bethat', 'seehe', 'ot', 'selfvident', 'sleightsofhand', 'cansee', 'thatsall', 'distinguishedand', 'villagesir', 'docrucially', 'arec', 'farradayscircle', 'witha', 'canonly', 'barnets', 'redding', 'tosit', 'clementss', 'newtmating', 'ill1terest', 'anysuch', 'dh', 'lewiss', 'donttake', 'allhis', 'contemplatin8', 'startseeing', 'symons', 'owardst', 'imvery', 'simplyaccepting', 'selftraining', 'wellcontented', 'evercourteous', 'donttake', 'allhis', 'lastminute', 'civvy', 'ohnothing', 'iarrived', 'friendsand', 'allshot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f858ade-6194-4520-9ae3-a0230103701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for bad_word in bad_words:\n",
    "    ind = text.find(bad_word)\n",
    "    if ind == -1:\n",
    "        print(f\"{bad_word} not found\")\n",
    "    else:\n",
    "        window = text[ind-50:ind+50]\n",
    "        window = window.replace(\"\\n\", \" \")\n",
    "        window = window.replace(\"\\t\", \" \")\n",
    "        print(window)\n",
    "    #test_result = (Word(test_word).spellcheck())\n",
    "    #print(test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a541d2-64e9-4cdf-8cfc-c1a076ff7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = text.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
    "bad_words=[\"ohnothing\", \"iarrived\", \"friendsand\", \"allshot\"]\n",
    "bad_words = [\"ell\", \"ting\"]\n",
    "for bad_word in bad_words:\n",
    "    try:\n",
    "        ind = test_words.index(bad_word)\n",
    "        print(f\"The index of '{bad_word}' is: {ind}\")\n",
    "        print(' '.join(test_words[ind - 10:ind + 10]))\n",
    "    except ValueError:\n",
    "        print(f\"'{item_to_find}' not found in the list.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b0c707-02c7-4573-b08d-bba3262278ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(blob_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b8c3c-6402-404f-8e3a-267bacf42033",
   "metadata": {},
   "outputs": [],
   "source": [
    "both = spell_set & blob_set\n",
    "print(len(both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de333e45-7126-47bb-9447-b42f1ece6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(word for word in both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f25e8a-925c-417d-a81f-bd1ca37c6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_errors = \"istrue canbe im tj1e overath laval itsrather wer silverss gotto thelikes ifi 0f prise ritz ofthe andthe lto lookingback al1 verypleased het thevery agre bethat seehe ot selfvident sleightsofhand cansee thatsall distinguishedand villagesir docrucially arec farradayscircle witha canonly barnets redding tosit clementss newtmating ill1terest anysuch dh lewiss donttake allhis contemplatin8 startseeing symons owardst imvery simplyaccepting selftraining wellcontented evercourteous donttake allhis lastminute civvy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b9ea58-49af-4e8f-9be7-779830d8eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_errors_split = set(original_errors.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a546bee2-8dbc-4329-b1bb-892c2e7bc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "missed = {word for word in original_errors_split if word not in errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c805622-08b7-4460-ba37-84e56269439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ([(word, word in blob_set_3) for word in missed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aab8b65-c34e-4b31-9649-038e934bfe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ([(word, word in both_3) for word in missed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd97c339-224d-428e-a557-ec3b9d6be1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ([(word, word in spell_set_3) for word in missed])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ab175-8e0c-45ad-9513-1d67321fe30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in errors_split:\n",
    "    if word not in text:\n",
    "        if word not in cleaned_suggestions:\n",
    "            print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcdea9a-50b8-49a3-846a-597e6c2e4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_is(\"distinguishedand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fbc744-436d-42d4-af84-d7197cadbb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([word for word in blob_set_3 if word not in blob_only])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655e006-5bfb-4dbf-808d-141d92766b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions = \"Overath Laval 1e with-a it'srather Silvers's Farraday'scircle Barnet's Clements's newt-mating Lewis's don'ttake I'mvery self-training well-contented ever-courteous don'ttake last-minute Ritz Redding self-vident sleights-of-hand be-that that'sall d-h Symons\"\n",
    "cleaned_suggestions = suggestions.translate(str.maketrans('', '', string.punctuation)).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8efe08-4c67-4fc7-9d9f-b34d928f9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in suggestions.split(' '):\n",
    "    if word not in text:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8498acb-31a9-4857-b72c-f83224304ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in errors_split:\n",
    "    if word not in cleaned_suggestions:`\n",
    "        if word not in test_words:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946ef07-9113-43ca-8aaf-d9a743a9b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" prise \" in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce07e4-5c13-4648-8f81-b3401fc9beb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
